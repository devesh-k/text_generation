{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58a70838",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference https://huggingface.co/learn/nlp-course/en/chapter7/6?fw=pt#training-a-causal-language-model-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49be6269",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0eec0940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing some libraries\n",
    "#!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b89c3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig,AutoModelForCausalLM, AutoConfig,GPT2Config,GPT2Tokenizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch.cuda.amp import autocast\n",
    "from torch import cuda\n",
    "import datetime\n",
    "import warnings,itertools\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import json\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pip install transformers bitsandbytes>=0.39.0 -q\n",
    "import zipfile,logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42fac022",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cb8cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fb04e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "model\n"
     ]
    }
   ],
   "source": [
    "#global params for training\n",
    "\n",
    "B,T = 32,1024\n",
    "epoch = 100\n",
    "random_init_wts = True\n",
    "min_text_len = 0\n",
    "# hard coded com\n",
    "comp_ratio = 3\n",
    "# train_loss_list = []\n",
    "# val_loss_list =[]\n",
    "if cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "#print(device)\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "#os.environ[\"MKL_DEBUG_CPU_TYPE\"] = \"5\"\n",
    "\n",
    "#print(global_tr_loss)\n",
    "model_path = os.path.join(\"model\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e39c002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/unzip_text_10M'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join('.','data','unzip_text_10M')  # Replace with your directory path\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daedd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(directory):\n",
    "    directory = os.path.join('.','data','unzip_text_10M',str(directory))  # Replace with your directory path\n",
    "    print(f\"directory :{directory}\")\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    print(f\"files:{files}\")\n",
    "    text_content = []\n",
    "    # Read each file\n",
    "    total_lines = 0\n",
    "    for filenum,filename in enumerate(files):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            #first_line = file.read()\n",
    "            #print(f\"filename :{filename}->first few lines {first_line}\")\n",
    "            #continue\n",
    "            #lines_list = [line.strip() for line in open(file_path, 'r')]\n",
    "            text = file.read()\n",
    "            text_content.append(text)\n",
    "            print(f\"the file:{filename} has been appeneded to the uber list and its length is {len(text_content)} \")\n",
    "            #total_lines+=len(lines_list)\n",
    "            #text_content.append(lines_list)\n",
    "    \n",
    "    flattened_list = ''.join(text_content)\n",
    "    assert (len(flattened_list) == total_lines , f\"Expected {len(flattened_list)} to be equal to {total_lines}\" )\n",
    "    \n",
    "    return flattened_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc99a93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/train_10M\n",
      "files:['switchboard.train', 'simple_wiki.train', 'open_subtitles.train', 'gutenberg.train', 'childes.train', 'bnc_spoken.train']\n",
      "the file:switchboard.train has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.train has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.train has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.train has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.train has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.train has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "train_list = read_text(\"train_10M\")\n",
    "#print(train_dict)\n",
    "#val_list = read_text(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aeb6b3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54215049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "350c9c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654\n"
     ]
    }
   ],
   "source": [
    "chunks = len(train_list)//(B*T)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886ebc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4ee3267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b00e9bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/dev\n",
      "files:['switchboard.dev', 'simple_wiki.dev', 'open_subtitles.dev', 'gutenberg.dev', 'childes.dev', 'bnc_spoken.dev']\n",
      "the file:switchboard.dev has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.dev has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.dev has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.dev has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.dev has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.dev has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "val_list = read_text(\"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe8b9f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50256\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a66c3f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6033372386529069"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e622021",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = train_list[500:750]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1e22d07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aska.\\nA:\\tI like to hunt,\\nA:\\tand, uh, so, I thought that if I had a good hunting dog like Thumper that, boy, I could just go out and get all kinds of game\\nB:\\tDid it work?\\nA:\\tYeah,\\nA:\\texcept we live in Plano, Texas now\\nB:\\tNo,\\nB:\\tright.\\nA:\\tso\\nB:\\tI, um, '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5acfa057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_list(text_list , B= B, T = T, val= False):\n",
    "    chunk_size = B*T*comp_ratio\n",
    "        \n",
    "    # Step 3: Split the list into chunks and pad the last chunk if necessary\n",
    "    chunks_inp = [text_list[i:i + chunk_size] for i in range(0, len(text_list), chunk_size)]\n",
    "    df = pd.DataFrame({'original_text': chunks_inp})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3f82eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = get_df_from_list(train_list)\n",
    "df_val = get_df_from_list(val_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89abe5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d8826f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_synonyms(word, pos):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word, pos=pos):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name() != word:\n",
    "                synonyms.append((lemma.name(), syn.wup_similarity(syn)))\n",
    "    \n",
    "    # Sort synonyms by similarity score in descending order\n",
    "    ranked_synonyms = sorted(set(synonyms), key=lambda x: x[1] if x[1] is not None else 0, reverse=True)\n",
    "    return [syn for syn, _ in ranked_synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "390675e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def replace_verbs_with_synonyms(text):\n",
    "    words = word_tokenize(text)\n",
    "    tagged = pos_tag(words)\n",
    "    result = []\n",
    "    for word, pos in tagged:\n",
    "        if pos =='VB':\n",
    "            wordnet_pos = get_wordnet_pos(pos)\n",
    "            lemma = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "            synonyms = get_ranked_synonyms(lemma, wordnet_pos)\n",
    "            if synonyms:\n",
    "                replacement = random.choice(synonyms)  # Choose from top 3 synonyms\n",
    "                #print(f\"word = {word}|replacement = {replacement}\")\n",
    "                result.append(replacement)\n",
    "            else:\n",
    "                result.append(word)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "114a8e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A:\\tI'm sure they are.\\nA:\\tThat's right,\\nA:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be cleaned\\nB:\\tUh-huh.\\nA:\\tthis needs to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and actually selling and dealing, you know, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like you would when you're up north.\\nA:\\tUh-h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nt outlook towards you guys.\\nB:\\tRight.\\nB:\\t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text\n",
       "0  A:\\tI'm sure they are.\\nA:\\tThat's right,\\nA:\\...\n",
       "1   be cleaned\\nB:\\tUh-huh.\\nA:\\tthis needs to be...\n",
       "2   and actually selling and dealing, you know, o...\n",
       "3  like you would when you're up north.\\nA:\\tUh-h...\n",
       "4  nt outlook towards you guys.\\nB:\\tRight.\\nB:\\t..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8405689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augment_col(row_index , index_to_augment):\n",
    "    #print(f\"row = {row_index}\")\n",
    "    if row_index in index_to_augment:\n",
    "        #print(f\"returning 1 for {row_index}\")\n",
    "        return 1\n",
    "    else:\n",
    "        \n",
    "        return 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe565197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_text(row):\n",
    "    #print(f\"row = {row_index}\")\n",
    "    if row['augmented'] == 1:\n",
    "        print(f\"augmenting index {row.name}\")\n",
    "        text = row['original_text']\n",
    "        augmented_text = replace_verbs_with_synonyms(text)\n",
    "        return augmented_text\n",
    "    else:\n",
    "        \n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "084f33f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(df_train)*.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "848c3a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file is present in the file system. Loading the pre augmented data\n"
     ]
    }
   ],
   "source": [
    "file_name = 'Augmented_data.csv'\n",
    "if os.path.isfile(file_name):\n",
    "    print(f\"file is present in the file system. Loading the pre augmented data\")\n",
    "    df_train = pd.read_csv(file_name)\n",
    "else:\n",
    "    index_to_augment = random.sample(range(0, len(df_train)), (int(len(df_train)*.3)))\n",
    "    df_train['augmented'] = df_train.apply(lambda row: get_augment_col(row.name, index_to_augment), axis=1)\n",
    "    df_train['augmented_text'] = df_train.apply(lambda row: augment_text(row ), axis=1)\n",
    "    df_train.to_csv('Augmented_data.csv', index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d95ba7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>augmented</th>\n",
       "      <th>augmented_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A:\\tI'm sure they are.\\nA:\\tThat's right,\\nA:\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>be cleaned\\nB:\\tUh-huh.\\nA:\\tthis needs to be...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>and actually selling and dealing, you know, o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like you would when you're up north.\\nA:\\tUh-h...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nt outlook towards you guys.\\nB:\\tRight.\\nB:\\t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  augmented augmented_text\n",
       "0  A:\\tI'm sure they are.\\nA:\\tThat's right,\\nA:\\...          0            NaN\n",
       "1   be cleaned\\nB:\\tUh-huh.\\nA:\\tthis needs to be...          0            NaN\n",
       "2   and actually selling and dealing, you know, o...          0            NaN\n",
       "3  like you would when you're up north.\\nA:\\tUh-h...          0            NaN\n",
       "4  nt outlook towards you guys.\\nB:\\tRight.\\nB:\\t...          0            NaN"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6eac53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7585066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40cd941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5bff9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(token_ids_list, max_length = B*T, tokenizer = tokenizer):\n",
    "    padded_sequences = tokenizer.pad(\n",
    "        {\"input_ids\": token_ids_list},\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72d396ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text (text,tokenizer = tokenizer,max_length = B*T):\n",
    "    #print(f\"inside tokenize_text\")\n",
    "    enc = tokenizer(text,padding='max_length',truncation=True,max_length=max_length,return_tensors=\"pt\",return_attention_mask=True)\n",
    "    input_id = enc['input_ids']\n",
    "    att_mask = enc['attention_mask']\n",
    "    \n",
    "    # now concatenate these lists to B*T\n",
    "    input_id = torch.squeeze(input_id, dim = 0).to(dtype = torch.long)\n",
    "    att_mask = torch.squeeze(att_mask, dim = 0).to(dtype = torch.bool)\n",
    "\n",
    "    return input_id,att_mask\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da0ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "48e4894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the tokenizer:\n",
    "model_name = 'distilgpt2'\n",
    "if random_init_wts:\n",
    "    config = AutoConfig.from_pretrained(model_name, vocab_size = 50304)\n",
    "    # Initialize the model with random weights\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "else:\n",
    "    #model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    \n",
    "#model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3ba463",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d35b07a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_train(Dataset):\n",
    "    def __init__(self, df, B = B, T = T, tokenizer = tokenizer, comp_ratio = comp_ratio,prob = .5):\n",
    "        #self.text_list = text_list\n",
    "        #print(f\"Value of B {B}\")\n",
    "        self.df = df\n",
    "                                        \n",
    "    def __getitem__(self, idx):\n",
    "        #words_list[start_index:start_index + n]\n",
    "        augment_flag = self.df.iloc[idx]['augmented']\n",
    "        if augment_flag == 1:\n",
    "            # extract the augmented_chunk\n",
    "            text = self.df.iloc[idx]['augmented_text']\n",
    "            label_text = self.df.iloc[idx]['original_text'] \n",
    "            inp,att = tokenize_text(text)\n",
    "            label_enc,_ = tokenize_text(label_text)\n",
    "            label = label_enc\n",
    "        else:\n",
    "            text = self.df.iloc[idx]['original_text']\n",
    "            inp,att = tokenize_text(text, tokenizer)\n",
    "            label_enc = inp.clone()\n",
    "        \n",
    "        input_id = inp.view(B,T)\n",
    "        attention_mask = att.view(B,T)\n",
    "        label = label_enc.view(B,T)\n",
    "        #print(f\"shape of input_id = {input_id.shape}| shape of attention = {attention_mask.shape}\")\n",
    "        \n",
    "        return input_id,attention_mask,label\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2d6ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_val(Dataset):\n",
    "    def __init__(self, df, B = B, T = T, tokenizer = tokenizer, comp_ratio = comp_ratio):\n",
    "        self.df = df\n",
    "        #print(f\"Value of B {B}\")\n",
    "                                                \n",
    "    def __getitem__(self, idx):\n",
    "        # extract the augmented_chunk\n",
    "        text = self.df.iloc[idx]['original_text']\n",
    "        inp,att = tokenize_text(text, tokenizer)\n",
    "        label_enc = inp.clone()\n",
    "        input_id = inp.view(B,T)\n",
    "        attention_mask = att.view(B,T)\n",
    "        label = label_enc.view(B,T)\n",
    "        #print(f\"shape of input_id = {input_id.shape}| shape of attention = {attention_mask.shape}\")\n",
    "        \n",
    "        return input_id,attention_mask,label\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e917577",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = dataset_pyt(filtered_df,tokenizer = tokenizer)\n",
    "train_dataset = dataset_pyt_train(df_train)\n",
    "val_dataset = dataset_pyt_val(df_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = 1, shuffle = True , num_workers = 4, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = 1, shuffle = True , num_workers = 4, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "95b056e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 50258\n",
      "EOS token ID: 50256\n",
      "PAD token ID: 50257\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "print(f\"PAD token ID: {tokenizer.pad_token_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c544f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23688fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(log_message, model_name = \"GPT2\" ,random_init_wts = random_init_wts ):\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    # Extract date and time components\n",
    "    current_date = str(current_datetime.date())\n",
    "    log_file = model_name +'_nll_loss_static_aug'+'random_init_wts'+ '_'+str(random_init_wts)+'_' +current_date+'.log'\n",
    "    print(f\"*****LOGGING INFO IN {log_file}*********\")\n",
    "    filepath = os.path.join(\"model\",log_file)\n",
    "    logging.basicConfig(filename=filepath, \n",
    "                    filemode='a',  # Overwrite the log file each time\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    level=logging.DEBUG)\n",
    "    logger = logging.getLogger()\n",
    "    logger.info(log_message)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b0cdc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train loader is 552\n",
      "Length of the val loader is 576\n",
      "num_tokens= 18087936\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the train loader is {len(train_loader)}\")\n",
    "print(f\"Length of the val loader is {len(val_loader)}\")\n",
    "print(f\"num_tokens= {B*T*len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "416733d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb,att,inp = train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "500d6672",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_train_metrics:\n",
    "    def __init__(self, patience=25, min_delta=0 , B = T, T = T,best_loss = torch.inf,early_stop = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = best_loss\n",
    "        self.early_stop = early_stop\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.improvement = None\n",
    "\n",
    "    def __call__(self, loss, epoch , epoch_durn, norm , current_lr, num_token):\n",
    "        if self.best_loss - loss > self.min_delta:\n",
    "            \n",
    "            print(f\"training loss has decreased---> reducing the best loss from {self.best_loss:.2f} to {loss:.2f} | throughput = {int(num_token/epoch_durn)} tokens/second | norm = {norm:.4f} | learning rate = {current_lr:.5e}\")\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            self.improvement = True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.improvement = False\n",
    "            print(f\"No improvement in training  loss-->epoch= {epoch} and best loss is {self.best_loss:.2f}|current_loss = {loss}|counter = {self.counter}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1dde2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_val_metrics:\n",
    "    def __init__(self, patience=25, min_delta=0, best_loss = torch.inf,early_stop = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = best_loss\n",
    "        self.early_stop = early_stop\n",
    "        \n",
    "\n",
    "    def __call__(self, loss, epoch , model, tokenizer):\n",
    "        if self.best_loss - loss > self.min_delta:\n",
    "            print(f\"Val loss has decreased -->reducing the global validation loss from {self.best_loss:.2f} to {loss:.2f}\")\n",
    "            s1 = (f\"Val loss has decreased -->reducing the global validation loss from {self.best_loss:.2f} to {loss:.2f}\")\n",
    "            print(f\" validation loss for epoch = {epoch} is {loss:.4f}\")\n",
    "            self.best_loss = loss\n",
    "            s2 = f\" validation loss for epoch = {epoch} is {loss:.4f}\"\n",
    "            print(f\" epoch= {epoch} :  val loss is {loss:.4f} \")\n",
    "            s3 = f\" epoch= {epoch} :  val loss is {loss:.4f} \"\n",
    "            #save the model\n",
    "            # Get the current date and time\n",
    "            current_datetime = datetime.datetime.now()\n",
    "            # Extract date and time components\n",
    "            current_date = str(current_datetime.date())\n",
    "            current_time = str(current_datetime.time()).split('.')[0]\n",
    "            file_name = 'model'+ current_date+current_time+'.pth'\n",
    "            path = os.path.join(\"model\",file_name)\n",
    "            print(f\"saving the model {file_name}\")\n",
    "            s4 = f\"saving the model {file_name}\"\n",
    "            #torch.save(model.state_dict(), path)\n",
    "            model.save_pretrained(path)\n",
    "            tokenizer.save_pretrained(path)\n",
    "            log_message = s1+s2+s3+s4\n",
    "            write_file(log_message)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"No improvement in validation loss-->epoch= {epoch} and best val loss is {self.best_loss:.2f}|current_Val loss = {loss}|counter = {self.counter}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c79e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output = model(input_ids = inp ,attention_mask = att, labels = inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a6bc7224",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "\n",
    "def eval_model(val_loader, model, epoch , device = device,tokenizer = tokenizer):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    e = epoch+1\n",
    "    val_loss_accum = 0.0\n",
    "    print(f\"inside validation data for epoch {e}\")\n",
    "    for ind,(input_id,attention_mask,label) in enumerate(val_loader):\n",
    "        ids = input_id.to(device=device, non_blocking=True)\n",
    "        ids = torch.squeeze(ids, dim = 0)\n",
    "        att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "        att_mask =  torch.squeeze(att_mask, dim = 0)\n",
    "        labels = torch.squeeze(label, dim = 0)\n",
    "        labels = labels.to(device=device, non_blocking=True)\n",
    "        with autocast(dtype = torch.bfloat16):\n",
    "            model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "            total_loss = model_output.loss\n",
    "    \n",
    "    \n",
    "    \n",
    "        val_loss_accum+= total_loss.detach().item()\n",
    "        del att_mask,labels,model_output,total_loss,ids\n",
    "    return val_loss_accum        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c2b40704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(train_loader,val_loader,model,num_epoch = 100,device = device,tokenizer = tokenizer):\n",
    "    #model.train()\n",
    "    device = device\n",
    "    lr_custom = 5e-5\n",
    "    print(f\"inside train model. Device = {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(params =  model.parameters(), lr= lr_custom,fused = True ,weight_decay = .1)\n",
    "      \n",
    "    extra_train = .1*num_epoch\n",
    "    max_train_steps = int(num_epoch +extra_train )\n",
    "    import time\n",
    "    from transformers import get_linear_schedule_with_warmup\n",
    "    total_steps = len(train_loader) * num_epoch\n",
    "    scheduler_cos = transformers.get_cosine_schedule_with_warmup( optimizer= optimizer, num_warmup_steps =int(total_steps * 0.1) ,num_training_steps= total_steps )\n",
    "        \n",
    "    epoch_train_log = []\n",
    "    epoch_val_log = []\n",
    "    validate_val_metric = check_val_metrics()\n",
    "    validate_train_metric = check_train_metrics()\n",
    "    for i in range (max_train_steps):\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # we use 2 schedulers - the first LR scheduler uses a cosine decay for 100 epochs the second scheduler takes the last LR from cosine scheduler and then maintains that LR for the next 10 epochs\n",
    "        if i >= num_epoch:\n",
    "            optimizer_reduced_lr = torch.optim.AdamW(params =  model.parameters(), lr= current_lr ,fused = True , weight_decay=.1)\n",
    "            scheduler_constant = transformers.get_constant_schedule_with_warmup( optimizer = optimizer_reduced_lr ,num_warmup_steps = 0, last_epoch = -1 )\n",
    "        \n",
    "        epoch_train_loss = 0       \n",
    "        for ind,(input_id,attention_mask,label) in enumerate(train_loader):\n",
    "            if ind == int(len(train_loader)/2):\n",
    "                batch_time = time.time()\n",
    "                duration = batch_time - epoch_start_time\n",
    "                print(f\"executing epoch:{i+1}, it took {duration/60} mins from beginning of epoch till batch#{ind}\")\n",
    "            \n",
    "            ids = input_id.to(device=device, non_blocking=True)\n",
    "            ids = torch.squeeze(ids, dim = 0)\n",
    "            att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "            att_mask =  torch.squeeze(att_mask, dim = 0)\n",
    "            labels = torch.squeeze(label, dim = 0)\n",
    "            labels = labels.to(device=device, non_blocking=True)\n",
    "                        \n",
    "            with autocast(dtype = torch.bfloat16):\n",
    "                model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "                total_loss = model_output.loss\n",
    "                \n",
    "                               \n",
    "            total_loss.backward()\n",
    "            epoch_train_loss += total_loss.detach().item()\n",
    "            norm = torch.nn.utils.clip_grad_norm(model.parameters() , 1.0)\n",
    "            if i <= num_epoch:\n",
    "                optimizer.step()\n",
    "                scheduler_cos.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            else:\n",
    "                optimizer_reduced_lr.step()\n",
    "                optimizer_reduced_lr.zero_grad(set_to_none=True)\n",
    "                scheduler_constant.step()\n",
    "                \n",
    "                         \n",
    "            del att_mask,labels,model_output,ids\n",
    "            \n",
    "        #batch processing complete \n",
    "        #print(f\"batch processing complete , lambda = {lambda_val} |total_loss for batch= {total_loss}\")\n",
    "        \n",
    "        if i <= num_epoch:\n",
    "            current_lr = scheduler_cos.get_last_lr()[0]\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_durn = (epoch_end_time - epoch_start_time)\n",
    "        num_token = B*T*len(train_loader)\n",
    "        epoch_train_log.append(epoch_train_loss)\n",
    "        validate_train_metric(epoch_train_loss, i , epoch_durn, norm , current_lr, num_token)\n",
    "        \n",
    "        if validate_train_metric.improvement:\n",
    "            val_loss= eval_model(val_loader, model, epoch = i, device = device,tokenizer = tokenizer)\n",
    "            epoch_val_log.append(val_loss)\n",
    "            validate_val_metric(val_loss, i , model, tokenizer)\n",
    "            if validate_train_metric.early_stop or validate_val_metric.early_stop :\n",
    "                print(f\"early stopping trigerred either from training data or val data | train_counter = {validate_train_metric.counter}|val_counter = {validate_val_metric.counter}\")\n",
    "                break\n",
    "        else:\n",
    "            if validate_val_metric.early_stop:\n",
    "                print(f\"early stopping trigerred from validation data\")\n",
    "                break\n",
    "              \n",
    "    \n",
    "    return model,epoch_train_log,epoch_val_log\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ae005a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train model. Device = cuda:0\n",
      "executing epoch:1, it took 2.0656187534332275 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from inf to 4367.07 | throughput = 73041 tokens/second | norm = 3.7881 | learning rate = 5.00000e-06\n",
      "inside validation data for epoch 1\n",
      "Val loss has decreased -->reducing the global validation loss from inf to 3508.58\n",
      " validation loss for epoch = 0 is 3508.5825\n",
      " epoch= 0 :  val loss is 3508.5825 \n",
      "saving the model model2024-08-0205:17:02.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:2, it took 1.982552138964335 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 4367.07 to 3086.14 | throughput = 76208 tokens/second | norm = 5.7755 | learning rate = 1.00000e-05\n",
      "inside validation data for epoch 2\n",
      "Val loss has decreased -->reducing the global validation loss from 3508.58 to 2782.69\n",
      " validation loss for epoch = 1 is 2782.6877\n",
      " epoch= 1 :  val loss is 2782.6877 \n",
      "saving the model model2024-08-0205:22:39.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:3, it took 1.9819187959035238 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 3086.14 to 2680.83 | throughput = 76092 tokens/second | norm = 1.8242 | learning rate = 1.50000e-05\n",
      "inside validation data for epoch 3\n",
      "Val loss has decreased -->reducing the global validation loss from 2782.69 to 2537.63\n",
      " validation loss for epoch = 2 is 2537.6304\n",
      " epoch= 2 :  val loss is 2537.6304 \n",
      "saving the model model2024-08-0205:28:17.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:4, it took 1.9847759405771892 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2680.83 to 2522.32 | throughput = 76067 tokens/second | norm = 2.9561 | learning rate = 2.00000e-05\n",
      "inside validation data for epoch 4\n",
      "Val loss has decreased -->reducing the global validation loss from 2537.63 to 2412.93\n",
      " validation loss for epoch = 3 is 2412.9331\n",
      " epoch= 3 :  val loss is 2412.9331 \n",
      "saving the model model2024-08-0205:33:56.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:5, it took 1.9834760864575705 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2522.32 to 2422.65 | throughput = 76093 tokens/second | norm = 1.1692 | learning rate = 2.50000e-05\n",
      "inside validation data for epoch 5\n",
      "Val loss has decreased -->reducing the global validation loss from 2412.93 to 2298.62\n",
      " validation loss for epoch = 4 is 2298.6216\n",
      " epoch= 4 :  val loss is 2298.6216 \n",
      "saving the model model2024-08-0205:39:33.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:6, it took 1.9832587361335754 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2422.65 to 2359.43 | throughput = 76066 tokens/second | norm = 4.4457 | learning rate = 3.00000e-05\n",
      "inside validation data for epoch 6\n",
      "Val loss has decreased -->reducing the global validation loss from 2298.62 to 2254.14\n",
      " validation loss for epoch = 5 is 2254.1405\n",
      " epoch= 5 :  val loss is 2254.1405 \n",
      "saving the model model2024-08-0205:45:12.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:7, it took 1.9850461721420287 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2359.43 to 2308.06 | throughput = 76015 tokens/second | norm = 2.6852 | learning rate = 3.50000e-05\n",
      "inside validation data for epoch 7\n",
      "Val loss has decreased -->reducing the global validation loss from 2254.14 to 2190.51\n",
      " validation loss for epoch = 6 is 2190.5096\n",
      " epoch= 6 :  val loss is 2190.5096 \n",
      "saving the model model2024-08-0205:50:50.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:8, it took 1.9827714006106059 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2308.06 to 2268.25 | throughput = 76057 tokens/second | norm = 0.8404 | learning rate = 4.00000e-05\n",
      "inside validation data for epoch 8\n",
      "Val loss has decreased -->reducing the global validation loss from 2190.51 to 2160.33\n",
      " validation loss for epoch = 7 is 2160.3264\n",
      " epoch= 7 :  val loss is 2160.3264 \n",
      "saving the model model2024-08-0205:56:28.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:9, it took 1.9827968994776408 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2268.25 to 2236.44 | throughput = 76049 tokens/second | norm = 3.9090 | learning rate = 4.50000e-05\n",
      "inside validation data for epoch 9\n",
      "Val loss has decreased -->reducing the global validation loss from 2160.33 to 2138.64\n",
      " validation loss for epoch = 8 is 2138.6430\n",
      " epoch= 8 :  val loss is 2138.6430 \n",
      "saving the model model2024-08-0206:02:06.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:10, it took 1.9849520444869995 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2236.44 to 2211.37 | throughput = 76019 tokens/second | norm = 5.2918 | learning rate = 5.00000e-05\n",
      "inside validation data for epoch 10\n",
      "Val loss has decreased -->reducing the global validation loss from 2138.64 to 2099.05\n",
      " validation loss for epoch = 9 is 2099.0531\n",
      " epoch= 9 :  val loss is 2099.0531 \n",
      "saving the model model2024-08-0206:07:44.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:11, it took 1.9822338740030925 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2211.37 to 2181.79 | throughput = 76076 tokens/second | norm = 1.2421 | learning rate = 4.99848e-05\n",
      "inside validation data for epoch 11\n",
      "Val loss has decreased -->reducing the global validation loss from 2099.05 to 2087.79\n",
      " validation loss for epoch = 10 is 2087.7854\n",
      " epoch= 10 :  val loss is 2087.7854 \n",
      "saving the model model2024-08-0206:13:22.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:12, it took 1.9865528742472331 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2181.79 to 2152.29 | throughput = 75988 tokens/second | norm = 1.3942 | learning rate = 4.99391e-05\n",
      "inside validation data for epoch 12\n",
      "Val loss has decreased -->reducing the global validation loss from 2087.79 to 2064.21\n",
      " validation loss for epoch = 11 is 2064.2095\n",
      " epoch= 11 :  val loss is 2064.2095 \n",
      "saving the model model2024-08-0206:19:01.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:13, it took 1.9834863940874736 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2152.29 to 2127.84 | throughput = 76043 tokens/second | norm = 1.1288 | learning rate = 4.98630e-05\n",
      "inside validation data for epoch 13\n",
      "Val loss has decreased -->reducing the global validation loss from 2064.21 to 2048.76\n",
      " validation loss for epoch = 12 is 2048.7595\n",
      " epoch= 12 :  val loss is 2048.7595 \n",
      "saving the model model2024-08-0206:24:39.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:14, it took 1.983825437227885 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2127.84 to 2103.83 | throughput = 76048 tokens/second | norm = 0.8700 | learning rate = 4.97567e-05\n",
      "inside validation data for epoch 14\n",
      "Val loss has decreased -->reducing the global validation loss from 2048.76 to 2031.08\n",
      " validation loss for epoch = 13 is 2031.0804\n",
      " epoch= 13 :  val loss is 2031.0804 \n",
      "saving the model model2024-08-0206:30:17.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:15, it took 1.9834646781285603 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2103.83 to 2082.44 | throughput = 76058 tokens/second | norm = 0.9441 | learning rate = 4.96202e-05\n",
      "inside validation data for epoch 15\n",
      "Val loss has decreased -->reducing the global validation loss from 2031.08 to 2015.16\n",
      " validation loss for epoch = 14 is 2015.1569\n",
      " epoch= 14 :  val loss is 2015.1569 \n",
      "saving the model model2024-08-0206:35:56.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:16, it took 1.9841879566510519 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2082.44 to 2058.55 | throughput = 76013 tokens/second | norm = 1.7401 | learning rate = 4.94537e-05\n",
      "inside validation data for epoch 16\n",
      "Val loss has decreased -->reducing the global validation loss from 2015.16 to 2005.48\n",
      " validation loss for epoch = 15 is 2005.4811\n",
      " epoch= 15 :  val loss is 2005.4811 \n",
      "saving the model model2024-08-0206:41:34.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:17, it took 1.9826372424761454 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2058.55 to 2038.70 | throughput = 76057 tokens/second | norm = 0.8822 | learning rate = 4.92574e-05\n",
      "inside validation data for epoch 17\n",
      "Val loss has decreased -->reducing the global validation loss from 2005.48 to 1991.86\n",
      " validation loss for epoch = 16 is 1991.8565\n",
      " epoch= 16 :  val loss is 1991.8565 \n",
      "saving the model model2024-08-0206:47:12.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:18, it took 1.983663018544515 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2038.70 to 2016.04 | throughput = 76019 tokens/second | norm = 0.9063 | learning rate = 4.90315e-05\n",
      "inside validation data for epoch 18\n",
      "Val loss has decreased -->reducing the global validation loss from 1991.86 to 1976.88\n",
      " validation loss for epoch = 17 is 1976.8788\n",
      " epoch= 17 :  val loss is 1976.8788 \n",
      "saving the model model2024-08-0206:52:51.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:19, it took 1.9836982250213624 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 2016.04 to 1993.88 | throughput = 76060 tokens/second | norm = 1.3271 | learning rate = 4.87764e-05\n",
      "inside validation data for epoch 19\n",
      "Val loss has decreased -->reducing the global validation loss from 1976.88 to 1966.98\n",
      " validation loss for epoch = 18 is 1966.9775\n",
      " epoch= 18 :  val loss is 1966.9775 \n",
      "saving the model model2024-08-0206:58:28.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:20, it took 1.983530374368032 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1993.88 to 1970.06 | throughput = 76037 tokens/second | norm = 1.0823 | learning rate = 4.84923e-05\n",
      "inside validation data for epoch 20\n",
      "Val loss has decreased -->reducing the global validation loss from 1966.98 to 1962.76\n",
      " validation loss for epoch = 19 is 1962.7646\n",
      " epoch= 19 :  val loss is 1962.7646 \n",
      "saving the model model2024-08-0207:04:07.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:21, it took 1.9855987310409546 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1970.06 to 1949.54 | throughput = 75996 tokens/second | norm = 1.5641 | learning rate = 4.81796e-05\n",
      "inside validation data for epoch 21\n",
      "Val loss has decreased -->reducing the global validation loss from 1962.76 to 1952.41\n",
      " validation loss for epoch = 20 is 1952.4064\n",
      " epoch= 20 :  val loss is 1952.4064 \n",
      "saving the model model2024-08-0207:09:45.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:22, it took 1.9810501058896384 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1949.54 to 1926.97 | throughput = 76188 tokens/second | norm = 2.1901 | learning rate = 4.78386e-05\n",
      "inside validation data for epoch 22\n",
      "Val loss has decreased -->reducing the global validation loss from 1952.41 to 1945.35\n",
      " validation loss for epoch = 21 is 1945.3461\n",
      " epoch= 21 :  val loss is 1945.3461 \n",
      "saving the model model2024-08-0207:15:22.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:23, it took 1.9823055545488992 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1926.97 to 1904.69 | throughput = 76073 tokens/second | norm = 1.1396 | learning rate = 4.74699e-05\n",
      "inside validation data for epoch 23\n",
      "Val loss has decreased -->reducing the global validation loss from 1945.35 to 1933.68\n",
      " validation loss for epoch = 22 is 1933.6848\n",
      " epoch= 22 :  val loss is 1933.6848 \n",
      "saving the model model2024-08-0207:21:01.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:24, it took 1.984029523531596 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1904.69 to 1883.68 | throughput = 76040 tokens/second | norm = 1.4914 | learning rate = 4.70737e-05\n",
      "inside validation data for epoch 24\n",
      "No improvement in validation loss-->epoch= 23 and best val loss is 1933.68|current_Val loss = 1935.9182155132294|counter = 1\n",
      "executing epoch:25, it took 1.9831122756004333 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1883.68 to 1862.40 | throughput = 76057 tokens/second | norm = 1.3432 | learning rate = 4.66506e-05\n",
      "inside validation data for epoch 25\n",
      "No improvement in validation loss-->epoch= 24 and best val loss is 1933.68|current_Val loss = 1934.5269565582275|counter = 2\n",
      "executing epoch:26, it took 1.981707501411438 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1862.40 to 1840.26 | throughput = 76103 tokens/second | norm = 1.3174 | learning rate = 4.62012e-05\n",
      "inside validation data for epoch 26\n",
      "Val loss has decreased -->reducing the global validation loss from 1933.68 to 1930.61\n",
      " validation loss for epoch = 25 is 1930.6129\n",
      " epoch= 25 :  val loss is 1930.6129 \n",
      "saving the model model2024-08-0207:37:52.pth\n",
      "*****LOGGING INFO IN GPT2_nll_loss_static_augrandom_init_wts_True_2024-08-02.log*********\n",
      "executing epoch:27, it took 1.9830771843592325 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1840.26 to 1821.15 | throughput = 76111 tokens/second | norm = 1.2837 | learning rate = 4.57259e-05\n",
      "inside validation data for epoch 27\n",
      "No improvement in validation loss-->epoch= 26 and best val loss is 1930.61|current_Val loss = 1948.6989905834198|counter = 1\n",
      "executing epoch:28, it took 1.985235619544983 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1821.15 to 1799.15 | throughput = 76066 tokens/second | norm = 1.4367 | learning rate = 4.52254e-05\n",
      "inside validation data for epoch 28\n",
      "No improvement in validation loss-->epoch= 27 and best val loss is 1930.61|current_Val loss = 1946.4097529649734|counter = 2\n",
      "executing epoch:29, it took 1.981502644220988 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1799.15 to 1778.17 | throughput = 76167 tokens/second | norm = 1.8124 | learning rate = 4.47003e-05\n",
      "inside validation data for epoch 29\n",
      "No improvement in validation loss-->epoch= 28 and best val loss is 1930.61|current_Val loss = 1948.7868247032166|counter = 3\n",
      "executing epoch:30, it took 1.9810512026151021 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1778.17 to 1756.52 | throughput = 76148 tokens/second | norm = 1.3305 | learning rate = 4.41511e-05\n",
      "inside validation data for epoch 30\n",
      "No improvement in validation loss-->epoch= 29 and best val loss is 1930.61|current_Val loss = 1960.965087890625|counter = 4\n",
      "executing epoch:31, it took 1.9805950125058491 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1756.52 to 1735.56 | throughput = 76176 tokens/second | norm = 1.3860 | learning rate = 4.35786e-05\n",
      "inside validation data for epoch 31\n",
      "No improvement in validation loss-->epoch= 30 and best val loss is 1930.61|current_Val loss = 1978.1082549095154|counter = 5\n",
      "executing epoch:32, it took 1.981433355808258 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1735.56 to 1713.54 | throughput = 76166 tokens/second | norm = 2.1418 | learning rate = 4.29835e-05\n",
      "inside validation data for epoch 32\n",
      "No improvement in validation loss-->epoch= 31 and best val loss is 1930.61|current_Val loss = 2001.5121684074402|counter = 6\n",
      "executing epoch:33, it took 1.9806588371594747 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1713.54 to 1691.90 | throughput = 76186 tokens/second | norm = 2.0596 | learning rate = 4.23665e-05\n",
      "inside validation data for epoch 33\n",
      "No improvement in validation loss-->epoch= 32 and best val loss is 1930.61|current_Val loss = 2008.1601649522781|counter = 7\n",
      "executing epoch:34, it took 1.9837384859720866 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1691.90 to 1670.38 | throughput = 76112 tokens/second | norm = 1.3900 | learning rate = 4.17283e-05\n",
      "inside validation data for epoch 34\n",
      "No improvement in validation loss-->epoch= 33 and best val loss is 1930.61|current_Val loss = 2029.7524062395096|counter = 8\n",
      "executing epoch:35, it took 1.9808398723602294 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1670.38 to 1648.30 | throughput = 76170 tokens/second | norm = 1.4662 | learning rate = 4.10697e-05\n",
      "inside validation data for epoch 35\n",
      "No improvement in validation loss-->epoch= 34 and best val loss is 1930.61|current_Val loss = 2044.7535691261292|counter = 9\n",
      "executing epoch:36, it took 1.9810710509618124 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1648.30 to 1626.03 | throughput = 76167 tokens/second | norm = 2.0916 | learning rate = 4.03915e-05\n",
      "inside validation data for epoch 36\n",
      "No improvement in validation loss-->epoch= 35 and best val loss is 1930.61|current_Val loss = 2063.3729701042175|counter = 10\n",
      "executing epoch:37, it took 1.9803918838500976 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1626.03 to 1604.74 | throughput = 76186 tokens/second | norm = 2.4313 | learning rate = 3.96946e-05\n",
      "inside validation data for epoch 37\n",
      "No improvement in validation loss-->epoch= 36 and best val loss is 1930.61|current_Val loss = 2095.1803599596024|counter = 11\n",
      "executing epoch:38, it took 1.982978351910909 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1604.74 to 1582.74 | throughput = 76064 tokens/second | norm = 2.3254 | learning rate = 3.89798e-05\n",
      "inside validation data for epoch 38\n",
      "No improvement in validation loss-->epoch= 37 and best val loss is 1930.61|current_Val loss = 2114.168405532837|counter = 12\n",
      "executing epoch:39, it took 1.984336495399475 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1582.74 to 1559.31 | throughput = 76032 tokens/second | norm = 1.8442 | learning rate = 3.82480e-05\n",
      "inside validation data for epoch 39\n",
      "No improvement in validation loss-->epoch= 38 and best val loss is 1930.61|current_Val loss = 2160.1251254081726|counter = 13\n",
      "executing epoch:40, it took 1.9819100936253866 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1559.31 to 1537.15 | throughput = 76119 tokens/second | norm = 1.5287 | learning rate = 3.75000e-05\n",
      "inside validation data for epoch 40\n",
      "No improvement in validation loss-->epoch= 39 and best val loss is 1930.61|current_Val loss = 2183.455550432205|counter = 14\n",
      "executing epoch:41, it took 1.982047426700592 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1537.15 to 1516.55 | throughput = 76171 tokens/second | norm = 2.5653 | learning rate = 3.67368e-05\n",
      "inside validation data for epoch 41\n",
      "No improvement in validation loss-->epoch= 40 and best val loss is 1930.61|current_Val loss = 2219.903235912323|counter = 15\n",
      "executing epoch:42, it took 1.978925343354543 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1516.55 to 1495.10 | throughput = 76260 tokens/second | norm = 3.5860 | learning rate = 3.59593e-05\n",
      "inside validation data for epoch 42\n",
      "No improvement in validation loss-->epoch= 41 and best val loss is 1930.61|current_Val loss = 2249.265383720398|counter = 16\n",
      "executing epoch:43, it took 1.976973291238149 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1495.10 to 1473.20 | throughput = 76296 tokens/second | norm = 2.8694 | learning rate = 3.51684e-05\n",
      "inside validation data for epoch 43\n",
      "No improvement in validation loss-->epoch= 42 and best val loss is 1930.61|current_Val loss = 2273.9184217453003|counter = 17\n",
      "executing epoch:44, it took 1.9773277799288431 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1473.20 to 1452.43 | throughput = 76283 tokens/second | norm = 2.8812 | learning rate = 3.43652e-05\n",
      "inside validation data for epoch 44\n",
      "No improvement in validation loss-->epoch= 43 and best val loss is 1930.61|current_Val loss = 2315.5899528265|counter = 18\n",
      "executing epoch:45, it took 1.9773576577504477 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1452.43 to 1429.97 | throughput = 76290 tokens/second | norm = 2.9266 | learning rate = 3.35505e-05\n",
      "inside validation data for epoch 45\n",
      "No improvement in validation loss-->epoch= 44 and best val loss is 1930.61|current_Val loss = 2345.0513948202133|counter = 19\n",
      "executing epoch:46, it took 1.983625058333079 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1429.97 to 1410.93 | throughput = 76143 tokens/second | norm = 3.1563 | learning rate = 3.27254e-05\n",
      "inside validation data for epoch 46\n",
      "No improvement in validation loss-->epoch= 45 and best val loss is 1930.61|current_Val loss = 2377.1661373376846|counter = 20\n",
      "executing epoch:47, it took 1.9768735766410828 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1410.93 to 1388.38 | throughput = 76346 tokens/second | norm = 2.1214 | learning rate = 3.18909e-05\n",
      "inside validation data for epoch 47\n",
      "No improvement in validation loss-->epoch= 46 and best val loss is 1930.61|current_Val loss = 2421.7746918201447|counter = 21\n",
      "executing epoch:48, it took 1.9760742386182149 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1388.38 to 1369.31 | throughput = 76356 tokens/second | norm = 3.0500 | learning rate = 3.10480e-05\n",
      "inside validation data for epoch 48\n",
      "No improvement in validation loss-->epoch= 47 and best val loss is 1930.61|current_Val loss = 2450.7411131858826|counter = 22\n",
      "executing epoch:49, it took 1.9771146297454834 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1369.31 to 1349.41 | throughput = 76300 tokens/second | norm = 4.0042 | learning rate = 3.01978e-05\n",
      "inside validation data for epoch 49\n",
      "No improvement in validation loss-->epoch= 48 and best val loss is 1930.61|current_Val loss = 2501.278610110283|counter = 23\n",
      "executing epoch:50, it took 1.9777062972386679 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1349.41 to 1328.71 | throughput = 76276 tokens/second | norm = 2.8014 | learning rate = 2.93412e-05\n",
      "inside validation data for epoch 50\n",
      "No improvement in validation loss-->epoch= 49 and best val loss is 1930.61|current_Val loss = 2531.343934774399|counter = 24\n",
      "executing epoch:51, it took 1.9778348644574484 mins from beginning of epoch till batch#276\n",
      "training loss has decreased---> reducing the best loss from 1328.71 to 1309.21 | throughput = 76255 tokens/second | norm = 3.6580 | learning rate = 2.84793e-05\n",
      "inside validation data for epoch 51\n",
      "No improvement in validation loss-->epoch= 50 and best val loss is 1930.61|current_Val loss = 2579.6955275535583|counter = 25\n",
      "early stopping trigerred either from training data or val data | train_counter = 0|val_counter = 25\n"
     ]
    }
   ],
   "source": [
    "tr_model,epoch_train_log,epoch_val_log = train_model(train_loader, val_loader,model=model,tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70810de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4367.0650153160095, 3086.137818336487, 2680.8257400989532, 2522.318494796753, 2422.6491887569427, 2359.4269827604294, 2308.0571731328964, 2268.245314359665, 2236.435079097748, 2211.3677003383636, 2181.785642504692, 2152.291970729828, 2127.8368096351624, 2103.831349492073, 2082.4433518648148, 2058.5548424720764, 2038.697742342949, 2016.0415506362915, 1993.882748246193, 1970.0551278591156, 1949.5445507764816, 1926.9680379629135, 1904.6944737434387, 1883.6754550933838, 1862.4009667634964, 1840.258231639862, 1821.147509932518, 1799.1452996730804, 1778.1678807735443, 1756.5166845321655, 1735.556303858757, 1713.5408223867416, 1691.901624917984, 1670.3813278079033, 1648.2989045977592, 1626.0301373004913, 1604.743586719036, 1582.74426227808, 1559.3134363293648, 1537.1503121852875, 1516.5487267374992, 1495.101655304432, 1473.2034606933594, 1452.4306051135063, 1429.9655669927597, 1410.928172647953, 1388.3816065192223, 1369.3061600327492, 1349.4121717214584, 1328.70652872324, 1309.2064368724823]\n"
     ]
    }
   ],
   "source": [
    "print(epoch_train_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4743879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json , os\n",
    "# path_var_train_log = os.path.join(\".\",\"Tokenizers_and_loss_vals\",\"epoch_train_plain_loss.json\")\n",
    "# path_var_val_log = os.path.join(\".\",\"Tokenizers_and_loss_vals\",\"epoch_val_val_loss_.json\")\n",
    "\n",
    "# #print(path_var)\n",
    "# #Write the list to a JSON file\n",
    "# with open(path_var_train_log, \"w\") as file:\n",
    "#     json.dump(epoch_train_log, file)\n",
    "\n",
    "# with open(path_var_val_log, \"w\") as file:\n",
    "#     json.dump(epoch_val_log, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab431b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path_var_train_log, \"r\") as file:\n",
    "#     train_loss = json.load(file)\n",
    "# with open(path_var_val_log, \"r\") as file:\n",
    "#     val_loss = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e2d23df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f920bf93160>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAi2UlEQVR4nO3deXSV13nv8e+jEQmEzpEQIGtATDYGbCMQeEzt0Abj4YZkdVhOk9ZJ3Ov2Xid1V3ObxFm9TZPWbdp7G8e5bXIXiZ3YaRqHm6QJddM6joe6SWyDhMTsQQYJISaBBmaBpOf+8W4JQRgEHHHgvL/PWmdxzn7fc87ey8fPu/Xs4TV3R0RE4iEr3RUQEZFLR0FfRCRGFPRFRGJEQV9EJEYU9EVEYkRBX0QkRkYc9M0s28wazezZ8PqbZrbVzJrCY14oNzP7spk1m9k6M5s/7DPuN7O3w+P+lLdGRETOKuc8zn0Y2AyMH1b2J+7+vVPOuwuYGR43Al8FbjSzEuCzQB3gQIOZrXT3rgutvIiInJ8RBX0zqwTuAR4F/vgcpy8DnvZo1ddrZpYws3LgDuB5d+8Mn/k8sBT4zpk+aMKECV5TUzOSKoqISNDQ0LDX3ctOd2ykPf0vAZ8Eik4pf9TM/gx4Afi0u/cCFUDbsHO2h7IzlZ9RTU0N9fX1I6yiiIgAmFnrmY6dM6dvZvcCe9y94ZRDjwCzgIVACfCpi6nksO970Mzqzay+o6MjFR8pIiLBSAZybwXea2YtwDPAYjP7R3ff6ZFe4BvAonB+O1A17P2VoexM5Sdx9+XuXufudWVlp/3rRERELtA5g767P+Lule5eA9wHvOjuHwp5eszMgPcBG8JbVgK/G2bx3AT0uPtO4DlgiZklzSwJLAllIiJyiZzP7J1TfdvMygADmoA/COU/Bu4GmoHDwEcA3L3TzP4CWB3O+/zgoK6IiFwadjlvrVxXV+cayBUROT9m1uDudac7phW5IiIxoqAvIhIjGRn09x89zmPPv0VTW3e6qyIiclnJyKA/MOA8/sLbNLRqhwcRkeEyMuiPH5NLlkH34WPproqIyGUlI4N+VpZRXJBLl4K+iMhJMjLoAyQK8+g+fDzd1RARuaxkcNDPVdAXETlFxgb9ZGGe0jsiIqfI2KCvnr6IyC/L2KCvnr6IyC/L4KCfy+Fj/fT29ae7KiIil42MDfrFhXkA9CjFIyIyJGODfrIwF4AuBX0RkSEZHPSjnr7y+iIiJ2Rs0E+Enr62YhAROSFjg/6Jnr7SOyIigzI+6GuuvojICRkb9MfkZpGXk6X0jojIMBkb9M2MZKF22hQRGS5jgz4MrspVekdEZFBGB/1o/x319EVEBmV00FdPX0TkZBkd9LXTpojIyUYc9M0s28wazezZ8Hqqmb1uZs1m9l0zywvl+eF1czheM+wzHgnlb5rZnSlvzSmiu2cdw91H+6tERK4I59PTfxjYPOz13wCPufsMoAt4IJQ/AHSF8sfCeZjZbOA+YA6wFPiKmWVfXPXPLlmYS9+Ac7C3bzS/RkTkijGioG9mlcA9wNfDawMWA98LpzwFvC88XxZeE47/ajh/GfCMu/e6+1agGViUgjacUUILtERETjLSnv6XgE8CA+F1KdDt7oNd6O1ARXheAbQBhOM94fyh8tO8Z4iZPWhm9WZW39HRMfKWnIY2XRMROdk5g76Z3QvscfeGS1Af3H25u9e5e11ZWdlFfZa2VxYROVnOCM65FXivmd0NjAHGA48DCTPLCb35SqA9nN8OVAHbzSwHKAb2DSsfNPw9o0I7bYqInOycPX13f8TdK929hmgg9kV3/yDwEvAb4bT7gR+F5yvDa8LxFz2aPrMSuC/M7pkKzARWpawlp6GcvojIyUbS0z+TTwHPmNlfAo3AE6H8CeBbZtYMdBJdKHD3jWa2AtgE9AEPufuo3sA2UTCY3lFPX0QEzjPou/vLwMvh+RZOM/vG3Y8Cv3mG9z8KPHq+lbxQOdlZFI3JUU9fRCTI6BW5MLgVg3r6IiIQi6Cfq9k7IiJBxgf94sI8etTTFxEBYhD01dMXETkhBkFfOX0RkUEZH/QThbkcONpHX//AuU8WEclwGR/0B/ff6T6iFI+ISMYH/RNbMSjoi4jEIOgPbsWgvL6ISMYHfe20KSJyQgyCvvbUFxEZlPFBX9sri4ickPFBf1x+DjlZpvSOiAgxCPpmRqIwT7N3RESIQdCHKMWj9I6ISEyCfrT/joK+iEgsgr7SOyIikVgEffX0RUQiMQn6eXQdPk50f3YRkfiKRdAvLszlWN8AR49rp00RibdYBH2tyhURicQk6A/uv6OgLyLxFougf2KnTc3gEZF4O2fQN7MxZrbKzNaa2UYz+1wo/6aZbTWzpvCYF8rNzL5sZs1mts7M5g/7rPvN7O3wuH/UWnUKpXdERCI5IzinF1js7gfNLBf4mZn9Wzj2J+7+vVPOvwuYGR43Al8FbjSzEuCzQB3gQIOZrXT3rlQ05Gy0vbKISOScPX2PHAwvc8PjbHMflwFPh/e9BiTMrBy4E3je3TtDoH8eWHpx1R+Z4hD0e9TTF5GYG1FO38yyzawJ2EMUuF8Phx4NKZzHzCw/lFUAbcPevj2Unan81O960Mzqzay+o6Pj/FpzBvk52RTmZaunLyKxN6Kg7+797j4PqAQWmdlc4BFgFrAQKAE+lYoKuftyd69z97qysrJUfCQwuEBLPX0Ribfzmr3j7t3AS8BSd98ZUji9wDeAReG0dqBq2NsqQ9mZyi+JaKdN9fRFJN5GMnunzMwS4XkB8B7gjZCnx8wMeB+wIbxlJfC7YRbPTUCPu+8EngOWmFnSzJLAklB2SainLyIystk75cBTZpZNdJFY4e7PmtmLZlYGGNAE/EE4/8fA3UAzcBj4CIC7d5rZXwCrw3mfd/fOlLXkHBKFubR3H7lUXyciclk6Z9B393VA7WnKF5/hfAceOsOxJ4Enz7OOKaEbqYiIxGRFLkTpnZ4jxxkY0E6bIhJfsQn6icI8Bhz2H9VgrojEV2yCvlbliojEKuhr/x0RkdgE/UTo6WswV0TiLEZBX9sri4jEJugrpy8iEqOgP35MLlmm9I6IxFtsgn5WllFckKuBXBGJtdgEfRjcf0fpHRGJr1gF/eLCXHoU9EUkxmIV9LXTpojEXayCvvbUF5G4i1XQV09fROIuZkE/l8PH+unt6093VURE0iJWQV+rckUk7mIW9Af331HQF5F4ilXQ106bIhJ3sQr62mlTROIuVkH/RE9f6R0RiaeYBn319EUknmIV9AvyspkwLo/mPQfTXRURkbSIVdAHmF+dpL6lK93VEBFJi3MGfTMbY2arzGytmW00s8+F8qlm9rqZNZvZd80sL5Tnh9fN4XjNsM96JJS/aWZ3jlqrzmJhTQnbOg+zZ//RdHy9iEhajaSn3wssdvcbgHnAUjO7Cfgb4DF3nwF0AQ+E8x8AukL5Y+E8zGw2cB8wB1gKfMXMslPYlhGpq0kCUN+q3r6IxM85g75HBpPgueHhwGLge6H8KeB94fmy8Jpw/FfNzEL5M+7e6+5bgWZgUSoacT7mXFVMfk6WUjwiEksjyumbWbaZNQF7gOeBd4Bud+8Lp2wHKsLzCqANIBzvAUqHl5/mPZdMXk4W86oS1Ld2XuqvFhFJuxEFfXfvd/d5QCVR73zWaFXIzB40s3ozq+/o6BiV76irSbJxx34OH+s798kiIhnkvGbvuHs38BJwM5Aws5xwqBJoD8/bgSqAcLwY2De8/DTvGf4dy929zt3rysrKzqd6I1ZXU0L/gNO0rXtUPl9E5HI1ktk7ZWaWCM8LgPcAm4mC/2+E0+4HfhSerwyvCcdfdHcP5feF2T1TgZnAqhS147zMr05ipsFcEYmfnHOfQjnwVJhpkwWscPdnzWwT8IyZ/SXQCDwRzn8C+JaZNQOdRDN2cPeNZrYC2AT0AQ+5e1o2ti8uyOWaSUWsblFeX0Ti5ZxB393XAbWnKd/CaWbfuPtR4DfP8FmPAo+efzVTb8GUJD9q2kH/gJOdZemujojIJRG7FbmDFtaUcLC3jzd27U93VURELpnYBv0FU6JFWg3K64tIjMQ26FcmC5g8fgyrtUhLRGIktkHfzFhQk6RBg7kiEiOxDfoAC6ck2dFzlPbuI+muiojIJRHroF9XUwJAvXr7IhITsQ76syYXMTYvW4O5IhIbsQ76OdlZ1FYnNZgrIrER66AP0eZrb+7az/6julm6iGQ+Bf0pJQw4NGrzNRGJgdgH/XnVCbKzTFM3RSQWYh/0x+XncG15kfL6IhILsQ/6EKV4mtq6Od4/kO6qiIiMKgV9osHcI8f72bRDm6+JSGZT0Cfq6QPaX19EMp6CPjC5eAxXTxrHP63axrE+pXhEJHMp6AeP3HUtWzoO8Y2fb013VURERo2CfvDuWRP5tWsn8uUX3mZXz9F0V0dEZFQo6A/zZ/fO4fiA89f/tjndVRERGRUK+sNUlxbyB7dP50dNO3h9y750V0dEJOUU9E/x326fTkWigM+u3Eif5u2LSIZR0D9FQV42//Pe2byx6wD/+FpruqsjIpJSCvqnceecSbxr5gT+7vm32HuwN93VERFJmXMGfTOrMrOXzGyTmW00s4dD+Z+bWbuZNYXH3cPe84iZNZvZm2Z257DypaGs2cw+PTpNunhmxp+/dw5Hj/fzt//+RrqrIyKSMiPp6fcBn3D32cBNwENmNjsce8zd54XHjwHCsfuAOcBS4Ctmlm1m2cA/AHcBs4EPDPucy870snF89LaprKjfTuM2bcYmIpnhnEHf3Xe6+5rw/ACwGag4y1uWAc+4e6+7bwWagUXh0ezuW9z9GPBMOPey9fHFM5k0Pp+Hn2li937N3ReRK9955fTNrAaoBV4PRR8zs3Vm9qSZJUNZBdA27G3bQ9mZyi9b4/JzWP47dew72MuHvv46nYeOpbtKIiIXZcRB38zGAd8H/sjd9wNfBaYD84CdwN+lokJm9qCZ1ZtZfUdHRyo+8qLcUJXgiQ8vZFvnYe5/cpVuqygiV7QRBX0zyyUK+N929x8AuPtud+939wHga0TpG4B2oGrY2ytD2ZnKT+Luy929zt3rysrKzrc9o+KmaaX83w8tYPPO/TzwzdUcOdaf7iqJiFyQkczeMeAJYLO7f3FYefmw094PbAjPVwL3mVm+mU0FZgKrgNXATDObamZ5RIO9K1PTjNH37lkTefy+Whpau3jwW/X09inwi8iVJ2cE59wK/A6w3syaQtlniGbfzAMcaAF+H8DdN5rZCmAT0cyfh9y9H8DMPgY8B2QDT7r7xpS15BK45/pyDvVezye/v46Hv9PE3/92LTnZWuogIlcOc/d01+GM6urqvL6+Pt3V+CVP/mwrn392E0vnTOYLv34dicK8dFdJRGSImTW4e93pjqmbegE+ettU/vSea/np5t2857FX+Omm3emukojIiCjoX6Dfe9c0fvjQrZSOzeP3nq7nEyvW0nNEM3tE5PKmoH8R5lYUs/Jjt/GHi2fww6Z2ljz2H7z0xp50V0tE5IwU9C9SXk4Wf7zkGn7432+luCCXj3xzNX+8oomdPUfSXTURkV+ioJ8i11UW8y8fv42H3j2dZ9fu5I7/9TJ/++9vaDGXiFxWFPRTKD8nmz+5cxYvfOJ27po7ma+8/A63/+1LfOPnWznWpxuyiEj6KeiPgqqSQr50Xy3Pfvw2Zl81ns/9yyZ+7Yv/wQ8b2zmuu3GJSBppnv4oc3deeXsvf/3jzbyx6wATi/L54I1T+MCNVUwsGpPu6olIBjrbPH0F/UtkYMB5+a09PPWLVv7jrQ5ys4275pZz/y1TmF+dJNrtQkTk4p0t6I9kGwZJgawsY/GsSSyeNYmtew/xrVdb+X/1baxcu4Nry8ezbN5V3HNdOVUlhemuqohkMPX00+hQbx8/bGpnRf121rZ1A9FWzvdeV84915dzVaIgvRUUkSuS0jtXgLbOw/zr+p08u24HG9r3A1BbneBXZpZx28wJzKtKkKvN3URkBBT0rzAtew/xr+t38pONu1jX3oM7jM3L5sZppdw6YwLvmjmBmRPHaRxARE5LQf8K1nP4OK9u2cvPmvfy8+Z9bN17CIDqkkKWzJ7EnXMnM786SXaWLgAiElHQzyDbuw7zylt7+cmmXfyieR/H+gcoHZvHr107iTvnTuKW6RMYk5ud7mqKSBop6GeoA0eP8/KbHTy3cRcvv9nBwd4+xuZlc8c1E1kyZxJ3XDOR4oLcdFdTRC4xBf0Y6O3r5xfv7OMnG3fz/Kbd7D3YS06WcfP0UpbMnsSvXF1GdUmhxgFEYkBBP2YGBpzGtm5+smkXP9m4e2gcoCJRwC3To8Hgm6eXMmm8VgSLZCIF/Rhzd7bsPcTPm/fyi+Z9vLpl39DNXmZMHMfN00q5ZXopN04rpWSsbvsokgkU9GVI/4Czeed+fvFONBtodUsnh4/1AzBrchG3TI/+ClhYk9S9f0WuUAr6ckbH+wdYt72bV9+J/gqob+miN2wDPWPiOBZUJ1kwJcmCmiTTJozVmIDIFUBBX0ast6+fxm3dNLR2saa1i4ZtXXQfjtJBicJc6qaUcPP0Um6eVsqsyUVkaX2AyGVHG67JiOXnZHPTtFJumlYKRIPCW/YeYk1rF/Wtnby+tZOfbt4NQLIwlxunloZ0UAlXTxpHjraKELmsKejLWWVlGTMmjmPGxHH81sIqAHZ0HxlKB736zj7+feMuAApys5lbMZ4bKhPcUJVgXlWCymSBUkIil5FzpnfMrAp4GpgEOLDc3R83sxLgu0AN0AL8lrt3WfR/+OPA3cBh4MPuviZ81v3An4aP/kt3f+ps3630zpWhrfMwa7Z10dTWzdq2bjbs2D90e8gJ4/JYWFPCoqnRY9bk8doyQmSUXVRO38zKgXJ3X2NmRUAD8D7gw0Cnu3/BzD4NJN39U2Z2N/BxoqB/I/C4u98YLhL1QB3RxaMBWODuXWf6bgX9K9OxvgHe2n2AxrZu1rR2sWprJ+3dRwAoys+hribJwqklLKwp4frKYvJztG2ESCpdVE7f3XcCO8PzA2a2GagAlgF3hNOeAl4GPhXKn/boavKamSXCheMO4Hl37wyVeh5YCnznglsml6W8nCzmVhQzt6KY37lpChDtGbS6pZNVW7tYtXUfL73ZMXTuDZXF1NWUsLAmyYLqEooLtXWEyGg5r5y+mdUAtcDrwKRwQQDYRZT+geiC0DbsbdtD2ZnKT/2OB4EHAaqrq8+nenIZq0wWUpks5P21lQDsO9hLQ2sX9eEvga+9soWvvuyYwezy8dw8LQwQTy1h/BhdBERSZcRB38zGAd8H/sjd9w8fnHN3N7OUzP109+XAcojSO6n4TLn8lI7LZ8mcySyZMxmAI8f6aWrrZtXWTl7dspenX2vl6z/bSpbB3IpibppWyvzqBLXVSW0fIXIRRhT0zSyXKOB/291/EIp3m1m5u+8M6Zs9obwdqBr29spQ1s6JdNBg+csXXnXJJAV52dH8/+mlPMxMjh7vZ822Ll57Zx+vbenkmz9vYfkr0eDwVcVjqK1OUludoLY6wdwKjQuIjNQ5g36YjfMEsNndvzjs0ErgfuAL4d8fDSv/mJk9QzSQ2xMuDM8Bf2VmyXDeEuCR1DRDMs2Y3GxumT6BW6ZPAODo8X427dxP47Zumtq6adzWxb+uj7KL+TlZzKtKDM0Qml+dZGy+ZiOLnM5IZu/cBvwnsB4YCMWfIcrrrwCqgVaiKZud4SLx90SDtIeBj7h7ffisj4b3Ajzq7t8423dr9o6czZ4DR1nT2s3qlk5Wt3Syccd++gec7CxjzlXjWVgTzRCqq0kyYVx+uqsrcsloGwaJhYO9faxp7QqzhDppause2kdoWtlYFk4pYeHUEuZXJ5iqfYQkgynoSyz19vWzoX0/q1s6qW/pZHVL19C20iVj86itSjB/SjQ2cENlQikhyRjae0diKT8nO9ohdEoSbp/OwIDz9p6DrNkWbSa3ZlsXL7wRzT/IMri2fPzQ+fOrk9pCQjKSevoSa92Hjw2tHF6zrYumbd0cCvcXmFiUP3QRWFhTwuyrxpOrDeXkCqCevsgZJArzePc1E3n3NRMB6Osf4M3dB8JFoJv61k7+bcOJDeVqqxPU1ZSwqKaEG6qKKdLCMbnCqKcvcg679x+lvqVraJbQ5p37GQj/20wrG8v1FcVcV5ng+spiZpeP19iApJ0GckVS6MDR4zRui3YUXdfew4b2Hnb2HAXADK6ZVBRtKldTQl1NCRWJgjTXWOJGQV9klO05cJQN7T2sbesZGigeHBsoLx5DXU0JdWGAeFZ5kcYGZFQppy8yyiYWjWHxrDEsnhXtO9jXP8Abuw7QMLRuYB//snYHAGNys7i+MjE0S2h+dYJSLR6TS0Q9fZFLwN1p7z7Cmm3RTKHGbV1s3LGfvjA4MHXCWBZMSVI3JUldTZJpE8bp/sNywdTTF0kzMxvaXvq9N1wFRPsJrW/voaG1i4bWLl58Yw/fa9gORDehH/wrYH51khuqtHhMUkO/IpE0GZObPbQ/EER/DWzde4j61q5wI/roQgDR4rFrJo8fuggsrCmhqkSLx+T8Kb0jchnrOXycxrZozUBjWDx2oLcPiBaPLawpGVo8dm15ETkaIBaU3hG5YhUX5nLHNRO5IyweGxhw3tpzgPqWrqH9hAa3mC7My2ZeVYK6KUkW1JRQW53QXcfkl6inL3KF29F9hPrW6CLQ0No1tHhs+JqBaJC4RPsJxYTm6YvEyMHePprCFhINrSevGSgryo/+EgiPOVcVk5ejlFCmUXpHJEbG5edw28wJ3DYzuutY/4Dz5q4DNISLQH1r19B+QmNyo7uODa4enl+d0H5CGU49fZEYGtxPqL61k/qWLjbu6GHAo1lCsyaPZ2FNkoVTo5lFuhH9lUfpHRE5q8GU0OCmco3bujlyPEoJVZcUUleTZFG49aQWjl3+lN4RkbM6NSV0vH+ATTv2D10EXn6zgx+saQeguCCX+dVhG4kpSd117Aqjnr6InJO7807HoaHN5Bpau3h7z0EAsrOM2eGuY4M3oldKKL2U3hGRlOs5fJw1bWH1cEsXjW1dHD0e3Yi+qqSAhVNKWDS1hJumlTKltFBTRS8hpXdEJOWKC3NPuuvY8JRQfUsXr7zdwQ8ao5TQpPH53DStdOhRo4tA2qinLyKjwt3ZsvcQr23Zx2tbOnltyz46DvQC0XqBhTXRgrFFU0uYNVlbSKTSRfX0zexJ4F5gj7vPDWV/DvxXoCOc9hl3/3E49gjwANAP/KG7PxfKlwKPA9nA1939CxfTKBG5vJkZ08vGMb1sHB+8ccrQhnKvbtlHfUsXq7Z28uP10XqBsXnZzA8Lxmqrk8yrTFBcqPUCo+GcPX0z+xXgIPD0KUH/oLv/71POnQ18B1gEXAX8FLg6HH4LeA+wHVgNfMDdN53tu9XTF8lsO7qPDKWDVrd08ubuAwyGpOllY6mtTlIbdha9elIR2ZoqOiIX1dN391fMrGaE37UMeMbde4GtZtZMdAEAaHb3LaFCz4Rzzxr0RSSzXZUoYNm8CpbNqwCi+w+v295D47YuGrd1n3SPgXH5OdSGqaILpiSZV6XVwxfiYgZyP2ZmvwvUA59w9y6gAnht2DnbQxlA2ynlN17Ed4tIBioak8utMyZw64xovYC707rvMI1t0TTR+pYuHn/hbXzYhnKD00R1E/qRudCg/1XgLwAP//4d8NFUVMjMHgQeBKiurk7FR4rIFcrMqJkwlpoJY3l/bSUQ/TXQ1NY9dMexH6zZzrdeawV0E/qRuKCg7+67B5+b2deAZ8PLdqBq2KmVoYyzlJ/62cuB5RDl9C+kfiKSuYrG5PKumWW8a2YZcOIm9PUtndS3dv3yTegrEtRWJ6gNt5+cGPOFYxcU9M2s3N13hpfvBzaE5yuBfzKzLxIN5M4EVgEGzDSzqUTB/j7gty+m4iIiADnZWcytKGZuRTEfvnXq0E3oG7d1syaMDTz5860cf2ULAFNKC1lYU8KimhIWTi2J3ZqBkUzZ/A5wBzDBzLYDnwXuMLN5ROmdFuD3Adx9o5mtIBqg7QMecvf+8DkfA54jmrL5pLtvTHVjRESG34T+vwy7Cf3GHftZ09rFqpZOXti8e2iAuKwon0U1JVxfWcx1ldHFI5PvOKbFWSISOwMDzjsdB1nV0snqrVFaaHvXkaHj0yaMZW5FMddXFrNgSpK5FcVX1NiA9t4RETmHzkPHWN/ew/rt3azb3sOG9h529BwFoCA3m9rqBIumRmmh2uokBXnZaa7xmWnvHRGRcygZm8ftV5dx+9VlQ2V7DhwdWj28amvn0HTRnCzjmslFUUqoIsH1lcVcPanoirj1pHr6IiIj1HPkOGtao9XD69t7WLe9h54jxwHIy87i2vIirq9McENVgnlVxWm74YzSOyIio8Ddaes8wrr2btZvjy4C69t7ONjbB0BRfg7XVRYzryrBvKpo2mhZUf6o10vpHRGRUWBmVJcWUl1ayL3XRzOFBgeJm9q6Wbu9m7VtPSx/ZQt9A1EHuzJZMLRmoLY6ybXlReTnXLrxAQV9EZEUysoyZk4qYuakIn6zLlqTGk0Z7aFxWzeN27qpb+kcWkCWl53FrPIibqiMxgZuqEowvWzcqG0up/SOiEga7OyJFpCtDX8RbGjfP5QWGpuXzeJrJ/F/PlB7QZ+t9I6IyGWmvLiA8usKuPu6ciBKC23Ze5C1bT2s2949ajebV9AXEbkMZGUZMyYWMWNiEb++oHL0vmfUPllERC47CvoiIjGioC8iEiMK+iIiMaKgLyISIwr6IiIxoqAvIhIjCvoiIjFyWW/DYGYdQOtFfMQEYG+KqnOliFub49ZeUJvj4mLaPMXdy0534LIO+hfLzOrPtP9Epopbm+PWXlCb42K02qz0johIjCjoi4jESKYH/eXprkAaxK3NcWsvqM1xMSptzuicvoiInCzTe/oiIjJMRgZ9M1tqZm+aWbOZfTrd9RkNZvakme0xsw3DykrM7Hkzezv8m0xnHVPNzKrM7CUz22RmG83s4VCese02szFmtsrM1oY2fy6UTzWz18Nv/LtmlpfuuqaSmWWbWaOZPRteZ3R7AcysxczWm1mTmdWHspT/tjMu6JtZNvAPwF3AbOADZjY7vbUaFd8Elp5S9mngBXefCbwQXmeSPuAT7j4buAl4KPy3zeR29wKL3f0GYB6w1MxuAv4GeMzdZwBdwAPpq+KoeBjYPOx1prd30Lvdfd6wqZop/21nXNAHFgHN7r7F3Y8BzwDL0lynlHP3V4DOU4qXAU+F508B77uUdRpt7r7T3deE5weIgkIFGdxujxwML3PDw4HFwPdCeUa12cwqgXuAr4fXRga39xxS/tvOxKBfAbQNe709lMXBJHffGZ7vAialszKjycxqgFrgdTK83SHV0QTsAZ4H3gG63b0vnJJpv/EvAZ8EBsLrUjK7vYMc+ImZNZjZg6Es5b9t3SM3Q7m7m1lGTs0ys3HA94E/cvf9UUcwkontdvd+YJ6ZJYB/Bmalt0ajx8zuBfa4e4OZ3ZHm6lxqt7l7u5lNBJ43szeGH0zVbzsTe/rtQNWw15WhLA52m1k5QPh3T5rrk3JmlksU8L/t7j8IxRnfbgB37wZeAm4GEmY22GnLpN/4rcB7zayFKDW7GHiczG3vEHdvD//uIbq4L2IUftuZGPRXAzPDaH8ecB+wMs11ulRWAveH5/cDP0pjXVIu5HafADa7+xeHHcrYdptZWejhY2YFwHuIxjJeAn4jnJYxbXb3R9y90t1riP7ffdHdP0iGtneQmY01s6LB58ASYAOj8NvOyMVZZnY3UV4wG3jS3R9Nb41Sz8y+A9xBtBPfbuCzwA+BFUA10e6kv+Xupw72XrHM7DbgP4H1nMj3foYor5+R7Taz64kG8LKJOmkr3P3zZjaNqCdcAjQCH3L33vTVNPVCeud/uPu9md7e0L5/Di9zgH9y90fNrJQU/7YzMuiLiMjpZWJ6R0REzkBBX0QkRhT0RURiREFfRCRGFPRFRGJEQV9EJEYU9EVEYkRBX0QkRv4/AJvxehtSOxEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_values = range(len(epoch_train_log))\n",
    "plt.plot(x_values, epoch_train_log, label='Train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3ea30945",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f920bf5a190>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#epoch_val_log= [t.detach().cpu().numpy() for t in epoch_val_log]\n",
    "x_values_val = range(len(epoch_val_log))\n",
    "plt.plot(x_values_val, epoch_val_log, label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ac42d84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f920bf4c130>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_length = min(len(epoch_train_log), len(epoch_val_log))\n",
    "list1 = epoch_train_log[:min_length]\n",
    "list2 = epoch_val_log[:min_length]\n",
    "\n",
    "# Create x-axis values\n",
    "x_values = range(min_length)\n",
    "\n",
    "# Plot the lists\n",
    "plt.plot(x_values, list1, label='Train_loss')\n",
    "plt.plot(x_values, list2, label='Val_loss')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Train Loss and Val_Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fac2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bd0934",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0053dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9f7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488a61ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4a548f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
