{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124544ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference https://huggingface.co/learn/nlp-course/en/chapter7/6?fw=pt#training-a-causal-language-model-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de065847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80723cac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.20.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2024.5.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.2->datasets) (2021.10.8)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.4)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.1)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: bitsandbytes in /opt/conda/lib/python3.8/site-packages (0.43.1)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (from bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from bitsandbytes) (1.21.4)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (2024.5.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (3.0.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (3.4.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (2.20.5)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (10.3.2.106)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (2.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (11.0.2.54)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch->bitsandbytes) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch->bitsandbytes) (2.0.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.8/site-packages (0.31.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.8/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.8/site-packages (from accelerate) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.8/site-packages (from accelerate) (0.23.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from accelerate) (1.21.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from accelerate) (5.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->accelerate) (3.0.6)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.4.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2024.5.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub->accelerate) (2.0.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing some libraries\n",
    "!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "!pip install bitsandbytes\n",
    "!pip install accelerate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e621ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig,AutoModelForCausalLM, AutoConfig\n",
    "from accelerate import Accelerator\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch import cuda\n",
    "import datetime\n",
    "import warnings,itertools\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pip install transformers bitsandbytes>=0.39.0 -q\n",
    "import zipfile,logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23853bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "model\n"
     ]
    }
   ],
   "source": [
    "# global params for training\n",
    "\n",
    "B,T = 8,1024\n",
    "epoch = 200\n",
    "random_init_wts = False\n",
    "min_text_len = 0\n",
    "# train_loss_list = []\n",
    "# val_loss_list =[]\n",
    "if cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "#print(device)\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "#os.environ[\"MKL_DEBUG_CPU_TYPE\"] = \"5\"\n",
    "context_length = None\n",
    "global_tr_loss = torch.inf\n",
    "global_val_loss = torch.inf\n",
    "#print(global_tr_loss)\n",
    "model_path = os.path.join(\"model\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28476508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/unzip_text_10M'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join('.','data','unzip_text_10M')  # Replace with your directory path\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7161724",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(directory):\n",
    "    directory = os.path.join('.','data','unzip_text_10M',str(directory))  # Replace with your directory path\n",
    "    print(f\"directory :{directory}\")\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    print(f\"files:{files}\")\n",
    "    text_content = []\n",
    "    # Read each file\n",
    "    total_lines = 0\n",
    "    for filenum,filename in enumerate(files):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            #first_line = file.read()\n",
    "            #print(f\"filename :{filename}->first few lines {first_line}\")\n",
    "            #continue\n",
    "            #lines_list = [line.strip() for line in open(file_path, 'r')]\n",
    "            text = file.read()\n",
    "            text_content.append(text)\n",
    "            print(f\"the file:{filename} has been appeneded to the uber list and its length is {len(text_content)} \")\n",
    "            #total_lines+=len(lines_list)\n",
    "            #text_content.append(lines_list)\n",
    "    \n",
    "    flattened_list = ''.join(text_content)\n",
    "    assert (len(flattened_list) == total_lines , f\"Expected {len(flattened_list)} to be equal to {total_lines}\" )\n",
    "    \n",
    "    return flattened_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83086d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/train_10M\n",
      "files:['switchboard.train', 'simple_wiki.train', 'open_subtitles.train', 'gutenberg.train', 'childes.train', 'bnc_spoken.train']\n",
      "the file:switchboard.train has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.train has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.train has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.train has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.train has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.train has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "train_list = read_text(\"train_10M\")\n",
    "#print(train_dict)\n",
    "#val_list = read_text(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef2bdac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54215049"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fce91223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6618\n"
     ]
    }
   ],
   "source": [
    "chunks = len(train_list)//(B*T)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2864e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B*T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54f2b773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (51426 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2-large\",return_tensors = \"pt\" , truncate = True, return_overflowing_tokens=True , padding = False,)\n",
    "enc_train = tokenizer(train_list[:50000*3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db2e6650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054.2342200443356"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_ratio = len(train_list)/len(enc_train['input_ids'])\n",
    "comp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cb7f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/dev\n",
      "files:['switchboard.dev', 'simple_wiki.dev', 'open_subtitles.dev', 'gutenberg.dev', 'childes.dev', 'bnc_spoken.dev']\n",
      "the file:switchboard.dev has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.dev has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.dev has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.dev has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.dev has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.dev has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "val_list = read_text(\"dev\")\n",
    "enc_val = tokenizer(val_list[:20000*5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14b3b59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49002e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_list(enc , B= B, T = T, val= False):\n",
    "    chunk_size = B*T\n",
    "    if val:\n",
    "        chunk_size = 2*B*T\n",
    "        \n",
    "    long_list_inp = enc['input_ids']\n",
    "    long_list_attention = enc['attention_mask']\n",
    "\n",
    "    # Step 3: Split the list into chunks and pad the last chunk if necessary\n",
    "    chunks_inp = [long_list_inp[i:i + chunk_size] for i in range(0, len(long_list_inp), chunk_size)]\n",
    "    chunks_att = [long_list_attention[i:i + chunk_size] for i in range(0, len(long_list_attention), chunk_size)]\n",
    "    df = pd.DataFrame({'input_ids': chunks_inp,'attention_mask':chunks_att})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66ccd045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataframe is = 7\n"
     ]
    }
   ],
   "source": [
    "df_train_temp = get_df_from_list(enc_train)\n",
    "# Display the DataFrame\n",
    "df_train_temp.head()\n",
    "print(f\"Length of the dataframe is = {len(df_train_temp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ee50c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the VALDATION dataframe is = 3\n"
     ]
    }
   ],
   "source": [
    "df_val_temp = get_df_from_list(enc_val , val = True)\n",
    "# Display the DataFrame\n",
    "df_val_temp.head()\n",
    "print(f\"Length of the VALDATION dataframe is = {len(df_val_temp)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f27b4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_df(df,eos_char = tokenizer.eos_token_id,B = B, T = T,val = False):\n",
    "    if val:\n",
    "        B = 2*B\n",
    "    for ind,row in df.iterrows():\n",
    "        if len(row['input_ids']) != B*T :\n",
    "            print(f\"row = {ind} and input_id length = {len(row['input_ids'])}\")\n",
    "            print(f\"row = {ind} and attention length = {len(row['attention_mask'])}\")\n",
    "            pad_len = B*T - len(row['input_ids'])\n",
    "            print(f\"padding the row index {ind} with {pad_len} character\")\n",
    "            row['input_ids'] = row['input_ids']+ [eos_char] * pad_len\n",
    "            #attention mask should be padded to 0\n",
    "            row['attention_mask'] = row['attention_mask']+ [0] * pad_len\n",
    "            print(\"#### POST CONCAT####\")\n",
    "            print(f\"row = {ind} and input_id length = {len(row['input_ids'])}\")\n",
    "            print(f\"row = {ind} and attention length ={len(row['attention_mask'])}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def verify_len(df,val = False, B= B):\n",
    "    row_ind = []\n",
    "    if val:\n",
    "        B = 2*B\n",
    "    for ind,row in df.iterrows():\n",
    "        if len(row['input_ids']) != B*T :\n",
    "            row_ind.append(ind)\n",
    "        else:\n",
    "            continue\n",
    "    if len(row_ind) !=0:\n",
    "        print(\"CONCATENATION Did not work\")\n",
    "    else:\n",
    "        print(\"CONCATENATION worked\")\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fdeba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = 6 and input_id length = 2274\n",
      "row = 6 and attention length = 2274\n",
      "padding the row index 6 with 5918 character\n",
      "#### POST CONCAT####\n",
      "row = 6 and input_id length = 8192\n",
      "row = 6 and attention length =8192\n",
      "CONCATENATION worked\n"
     ]
    }
   ],
   "source": [
    "df_train  = pad_df(df_train_temp)\n",
    "verify_len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db7395cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = 2 and input_id length = 1980\n",
      "row = 2 and attention length = 1980\n",
      "padding the row index 2 with 14404 character\n",
      "#### POST CONCAT####\n",
      "row = 2 and input_id length = 16384\n",
      "row = 2 and attention length =16384\n",
      "CONCATENATION worked\n"
     ]
    }
   ],
   "source": [
    "df_val  = pad_df(df_val_temp, val = True)\n",
    "verify_len(df_val, val = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72b45337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[32, 25, 197, 40, 1101, 1654, 484, 389, 13, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4398, 470, 1775, 326, 13, 198, 32, 25, 197, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[290, 1243, 588, 326, 198, 33, 25, 197, 392, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[198, 33, 25, 197, 5779, 11, 1682, 11, 21480, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[6510, 11, 14104, 290, 27913, 13, 198, 32, 25,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [32, 25, 197, 40, 1101, 1654, 484, 389, 13, 19...   \n",
       "1  [4398, 470, 1775, 326, 13, 198, 32, 25, 197, 4...   \n",
       "2  [290, 1243, 588, 326, 198, 33, 25, 197, 392, 1...   \n",
       "3  [198, 33, 25, 197, 5779, 11, 1682, 11, 21480, ...   \n",
       "4  [6510, 11, 14104, 290, 27913, 13, 198, 32, 25,...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808236f8",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "268dc45e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: peft in /opt/conda/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.8/site-packages (from peft) (0.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from peft) (4.66.4)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from peft) (0.4.3)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (from peft) (4.42.0.dev0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from peft) (6.0)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from peft) (2.3.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.8/site-packages (from peft) (0.23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from peft) (5.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from peft) (1.21.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from peft) (21.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (4.11.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (2024.5.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->peft) (3.0.6)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.0.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (2.20.5)\n",
      "Requirement already satisfied: triton==2.3.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (2.3.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (3.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (1.12)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft) (12.4.127)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft) (2.0.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->huggingface-hub>=0.17.0->peft) (2.0.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers->peft) (2021.11.10)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.8/site-packages (from transformers->peft) (0.19.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c3171bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "target_modules = [\"c_attn\",\"q_proj\", \"k_proj\", \"v_proj\", \"out_proj\", \"fc_in\", \"fc_out\", \"wte\"]\n",
    "peft_config = LoraConfig(r=4, lora_alpha=16, target_modules=target_modules, lora_dropout=0.1, bias=\"none\", task_type=\"CAUSAL_LM\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d90b0120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 943,428 || all params: 774,973,508 || trainable%: 0.1217\n"
     ]
    }
   ],
   "source": [
    "# Test the tokenizer:\n",
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import get_peft_model\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=\"float16\",\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")\n",
    "\n",
    "\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "    \"gpt2-large\",\n",
    "    quantization_config=bnb_config, \n",
    "    )\n",
    "#model_4bit_c = torch.compile(model_4bit)\n",
    "model_4bit = get_peft_model(model_4bit, peft_config)\n",
    "model_4bit.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "692ef7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accelerator = Accelerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e2751cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model size is 527.487184MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model size is {model_4bit.get_memory_footprint()/1e6}MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7683488",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "743fd7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_val(Dataset):\n",
    "    def __init__(self, df, B = B, T = T ):\n",
    "        self.df = df\n",
    "        print(f\"Value of B {B}\")\n",
    "                                        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(f\"inside loader...idx ->{idx}\")\n",
    "        input_id_temp = torch.tensor(self.df.iloc[idx]['input_ids'],dtype = torch.long)\n",
    "        #print(f\"length of text ->{len(text)}\")\n",
    "        #print(f\"text ->{text}\")\n",
    "        #encodings = tokenizer(text, truncation=True, max_length= self.max_length, return_overflowing_tokens=True, padding = 'max_length',return_tensors='pt')\n",
    "        att_mask = torch.tensor(self.df.iloc[idx]['attention_mask'],dtype = torch.long)\n",
    "        \n",
    "        \n",
    "        # check the length of the encoded list\n",
    "        \n",
    "        #x_dict['input_id'] = input_ids_list\n",
    "        #x_dict['attention_mask'] = input_ids_list\n",
    "                \n",
    "        #print(f\"x_dict = {x_dict}\")             \n",
    "#       print(f\"inside the loader and input_id = {input_ids} and its shape is {input_ids.shape}\")\n",
    "        #labels = input_id_list\n",
    "        #input_ids = torch.tensor(input_id_list)\n",
    "        #attention_mask = torch.tensor(attention_mask_list)\n",
    "        #labels = torch.tensor(labels)\n",
    "        #print(f\"inside the loader and input_id shape= {input_ids.shape} attention_mask_shape is {attention_mask.shape} and label shape is {labels.shape}\")\n",
    "        #print(f\"encoding = {encodings}\")\n",
    "        input_id =   input_id_temp.view(B,T)    \n",
    "        attention_mask = att_mask.view(B,T)   \n",
    "        \n",
    "        return input_id, attention_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c0c039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_train(Dataset):\n",
    "    def __init__(self, df, B = B, T = T ):\n",
    "        self.df = df\n",
    "                                        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(f\"inside loader...idx ->{idx}\")\n",
    "        input_id_temp = torch.tensor(self.df.iloc[idx]['input_ids'],dtype = torch.long)\n",
    "        #input_id_temp = input_id_temp.to(torch.int)\n",
    "        \n",
    "        #print(f\"length of text ->{len(text)}\")\n",
    "        #print(f\"text ->{text}\")\n",
    "        #encodings = tokenizer(text, truncation=True, max_length= self.max_length, return_overflowing_tokens=True, padding = 'max_length',return_tensors='pt')\n",
    "        att_mask = torch.tensor(self.df.iloc[idx]['attention_mask'],dtype = torch.long)\n",
    "        #att_mask = att_mask.to(torch.int)\n",
    "        \n",
    "        # check the length of the encoded list\n",
    "        \n",
    "        #x_dict['input_id'] = input_ids_list\n",
    "        #x_dict['attention_mask'] = input_ids_list\n",
    "                \n",
    "        #print(f\"x_dict = {x_dict}\")             \n",
    "#       print(f\"inside the loader and input_id = {input_ids} and its shape is {input_ids.shape}\")\n",
    "        #labels = input_id_list\n",
    "        #input_ids = torch.tensor(input_id_list)\n",
    "        #attention_mask = torch.tensor(attention_mask_list)\n",
    "        #labels = torch.tensor(labels)\n",
    "        #print(f\"inside the loader and input_id shape= {input_ids.shape} attention_mask_shape is {attention_mask.shape} and label shape is {labels.shape}\")\n",
    "        #print(f\"encoding = {encodings}\")\n",
    "        input_id =   input_id_temp.view(B,T)    \n",
    "        attention_mask = att_mask.view(B,T)   \n",
    "        \n",
    "        return input_id, attention_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "649698e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of B 8\n"
     ]
    }
   ],
   "source": [
    "#train_dataset = dataset_pyt(filtered_df,tokenizer = tokenizer)\n",
    "train_dataset = dataset_pyt_train(df_train)\n",
    "val_dataset = dataset_pyt_val(df_val)\n",
    "#test_dataset = dataset_pyt(df_test,tokenizer = tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = 1, shuffle = True , num_workers = 4, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = 1, shuffle = True , num_workers = 4, pin_memory = True)\n",
    "#test_loader = DataLoader(test_dataset,batch_size = batch_size, shuffle = False, collate_fn = custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5b1f805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp1 = torch.randint(low=0, high=50257, size=(B, T), dtype=torch.long)\n",
    "# inp1.shape\n",
    "# att1 = torch.randint(low=0, high=1, size=(B, T), dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06558dd",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "92b63458",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = os.path.join(\".\",\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2752c847",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97322632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9385757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f4238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10712fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76322b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f942cc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef02c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a956a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e79e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372af41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24653c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inp , att = train_dataset[0]\n",
    "# inp_g = inp.to(device)\n",
    "# att_g = att.to(device)\n",
    "\n",
    "# print(inp_g.dtype,att_g.dtype)\n",
    "# print(inp_g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30d90ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_o = model_4bit(input_ids = inp_g ,attention_mask = att_g, labels = inp_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1e56767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train loader is 2099\n",
      "Length of the val loader is 1063\n",
      "num_tokens= 17195008\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the train loader is {len(train_loader)}\")\n",
    "print(f\"Length of the val loader is {len(val_loader)}\")\n",
    "print(f\"num_tokens= {B*T*len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7626220b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output = model(input_ids = inp ,attention_mask = att, labels = inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8435b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(log_message, model_name = \"GPT2-L\" ,random_init_wts = random_init_wts ):\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    # Extract date and time components\n",
    "    current_date = str(current_datetime.date())\n",
    "    log_file = model_name +'_'+'Quantized'+ '_'+current_date+'.log'\n",
    "    print(f\"*****LOGGING INFO IN {log_file}*********\")\n",
    "    filepath = os.path.join(\"model\",log_file)\n",
    "    logging.basicConfig(filename=filepath, \n",
    "                    filemode='a',  # Overwrite the log file each time\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    level=logging.DEBUG)\n",
    "    logger = logging.getLogger()\n",
    "    logger.info(log_message)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "edb8c942",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def eval_model(val_loader, model, epoch , device = device,tokenizer = tokenizer):\n",
    "    global global_val_loss\n",
    "    #m = nn.Softmax()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    e = epoch+1\n",
    "    val_loss_accum = 0.0\n",
    "    #criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    print(f\"inside validation data for epoch {e}\")\n",
    "    #y_hat_val_list = []\n",
    "    #y_val_list = []\n",
    "    with torch.no_grad():\n",
    "        for ind,(input_id,attention_mask) in enumerate(val_loader):\n",
    "        #print(f\"id_list{id_list}\")\n",
    "            ids = input_id.to(device=device, non_blocking=True)\n",
    "            att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "            labels = ids\n",
    "        #predictions\n",
    "        #print(f\"input_ids device = {input_ids.device}\")\n",
    "            #with autocast(dtype = torch.bfloat16):\n",
    "            model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "            act_loss = model_output.loss\n",
    "        \n",
    "        val_loss_accum+=act_loss.detach().item()\n",
    "        del ids,att_mask,labels,act_loss\n",
    "    \n",
    "    if val_loss_accum < global_val_loss:\n",
    "        print(f\"Val loss has decreased -->reducing the global validation loss from {global_val_loss:.2f} to {val_loss_accum:.2f}\")\n",
    "        s1 = f\"Val loss has decreased -->reducing the global validation loss from {global_val_loss:.2f} to {val_loss_accum:.2f}\"\n",
    "        global_val_loss = val_loss_accum\n",
    "        print(f\" validation loss for epoch = {e} is {val_loss_accum:.4f}\")\n",
    "        s2 = f\" validation loss for epoch = {e} is {val_loss_accum:.4f}\"\n",
    "        #print metrics and save the model\n",
    "        #y_hat_val = torch.cat(y_hat_val_list)\n",
    "        #y_val = torch.cat(y_val_list)\n",
    "        #acc_val = accuracy_score(y_val.cpu().numpy(), y_hat_val.cpu().numpy())\n",
    "        #f1_val = f1_score(y_val.cpu().numpy(), y_hat_val.cpu().numpy(), average='micro')\n",
    "        print(f\" epoch= {e} :  val loss is {val_loss_accum:.4f} \")\n",
    "        s3 = f\" epoch= {e} :  val loss is {val_loss_accum:.4f} \"\n",
    "        #save the model\n",
    "        \n",
    "        # Get the current date and time\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        # Extract date and time components\n",
    "        current_date = str(current_datetime.date())\n",
    "        current_time = str(current_datetime.time()).split('.')[0]\n",
    "        file_name = 'model'+ current_date+current_time+'.pth'\n",
    "        path = os.path.join(\"model\",file_name)\n",
    "        print(f\"saving the model {file_name}\")\n",
    "        s4 = f\"saving the model {file_name}\"\n",
    "        #torch.save(model.state_dict(), path)\n",
    "        model.save_pretrained(path)\n",
    "        tokenizer.save_pretrained(path)\n",
    "        log_message = s1+s2+s3+s4\n",
    "        write_file(log_message)\n",
    "        \n",
    "        #plot_confusion_matrix(y_val.cpu().numpy(), y_hat_val.cpu().numpy(), labels)\n",
    "    else:\n",
    "        print(f\"No improvement in validation loss-->epoch= {e} and global val loss is {global_val_loss:.2f}\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1e203fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,val_loader,model,num_epoch = 200,device = device,tokenizer = tokenizer):\n",
    "    global global_tr_loss\n",
    "    model.train()\n",
    "    device = device\n",
    "    lr_custom = 2e-4\n",
    "    print(f\"inside train model. Device = {device}\")\n",
    "    #adding betas params per the paper\n",
    "    #model.to(device)\n",
    "    optimizer = torch.optim.AdamW(params =  model.parameters(), lr= lr_custom,betas = (.9,.95) ,weight_decay = .1)\n",
    "    total_batch_size = 2**19\n",
    "    grad_accum_step = total_batch_size//(B*T)\n",
    "    from accelerate import Accelerator\n",
    "\n",
    "    \n",
    "    extra_train = .1*num_epoch\n",
    "    #m = nn.Softmax()\n",
    "    max_train_steps = int(num_epoch +extra_train )\n",
    "    import time\n",
    "    from transformers import get_linear_schedule_with_warmup\n",
    "    scheduler_cos = transformers.get_cosine_schedule_with_warmup( optimizer= optimizer, num_warmup_steps =num_epoch*.1 ,num_training_steps= num_epoch-1 ,last_epoch = -1 )\n",
    "    model, optimizer, train_loader, val_loader, lr_scheduler = accelerator.prepare( model, optimizer, train_loader, val_loader, scheduler_cos)\n",
    "        \n",
    "    for i in range (max_train_steps):\n",
    "        epoch_start_time = time.time()\n",
    "        epoch_train_loss = 0.0\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        batch_loss = 0.0\n",
    "        for ind,(input_id,attention_mask) in enumerate(train_loader):\n",
    "            if ind == int(len(train_loader)/2):\n",
    "                batch_time = time.time()\n",
    "                duration = batch_time - epoch_start_time\n",
    "                print(f\"executing epoch:{i+1}, it took {duration/60} mins from beginning of epoch till batch#{ind}\")\n",
    "            \n",
    "            ids = input_id.to(device=device, non_blocking=True)\n",
    "            att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "            labels = ids\n",
    "            \n",
    "            #with autocast(dtype = torch.bfloat16):\n",
    "            model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "            act_loss = model_output.loss\n",
    "            #print(f\"inside batch_processing. ind = {ind}|loss for ind = {act_loss} |batch_loss ={batch_loss} | epoch_train_loss = {epoch_train_loss}\")\n",
    "            batch_loss +=act_loss.detach().item()\n",
    "            #print(f\"incrementing batch_loss. ind = {ind}|loss for ind = {act_loss} |batch_loss ={batch_loss} | epoch_train_loss = {epoch_train_loss}\")\n",
    "            act_loss = act_loss/grad_accum_step\n",
    "            accelerator.backward(act_loss)\n",
    "            epoch_train_loss += act_loss.detach().item()\n",
    "            \n",
    "            if (ind + 1)% grad_accum_step == 0:\n",
    "                #print(f\"Gradient accum step = {ind}|batch_loss before averaging ={batch_loss} | epoch_train_loss = {epoch_train_loss}\")\n",
    "                norm = torch.nn.utils.clip_grad_norm(model.parameters() , 1.0)\n",
    "                if i <= num_epoch:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                else:\n",
    "                    optimizer_reduced_lr.step()\n",
    "                    optimizer_reduced_lr.zero_grad(set_to_none=True)\n",
    "                #print(f\"Gradient accum step = {ind}|batch_loss after averaging ={batch_loss} | epoch_train_loss = {epoch_train_loss}\")\n",
    "                #print(f\"Gradient accum step = {ind}|batch_loss after averaging ={batch_loss} | epoch_train_loss = {epoch_train_loss}\")\n",
    "                                \n",
    "            del ids,att_mask,labels\n",
    "            \n",
    "        \n",
    "        \n",
    "        #batch processing complete \n",
    "        if i <= num_epoch:\n",
    "            current_lr = scheduler_cos.get_last_lr()[0]\n",
    "            scheduler_cos.step()\n",
    "        if i >= num_epoch:\n",
    "            optimizer_reduced_lr = torch.optim.AdamW(params =  model.parameters(), lr= current_lr ,betas = (.9,.95), weight_decay=.1)\n",
    "            scheduler_constant = transformers.get_constant_schedule_with_warmup( optimizer = optimizer_reduced_lr ,num_warmup_steps = 0, last_epoch = -1 )\n",
    "            model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare( model, optimizer_reduced_lr, train_dataloader, val_dataloader, scheduler_constant)\n",
    "            optimizer_reduced_lr.zero_grad(set_to_none=True)\n",
    "            \n",
    "            scheduler_constant.step()\n",
    "                      \n",
    "        #mean_loss = torch.mean(torch.tensor(epoch_train_loss))\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_durn = (epoch_end_time - epoch_start_time)\n",
    "        num_token = B*T*len(train_loader)\n",
    "        if (epoch_train_loss < global_tr_loss) :\n",
    "            print(f\"training loss has decreased---> reducing the global loss from {global_tr_loss:.2f} to {epoch_train_loss:.2f} | throughput = {int(num_token/epoch_durn)} tokens/second | norm = {norm:.4f} | learning rate = {current_lr:.5e}\")\n",
    "            global_tr_loss = epoch_train_loss\n",
    "            print(f\" epoch= {i+1} and  train loss is {epoch_train_loss:.2f}\")\n",
    "            #printing training metrices\n",
    "            #y_hat = torch.cat(y_hat_list)\n",
    "            #y = torch.cat(label_list)\n",
    "            #acc = accuracy_score(y.cpu().numpy(), y_hat.cpu().numpy())\n",
    "            #f1 = f1_score(y.cpu().numpy(), y_hat.cpu().numpy(), average='micro')\n",
    "            #checking validation metrices\n",
    "            if (i%4 == 0):\n",
    "                eval_model(val_loader, model, epoch = i , device = device,tokenizer = tokenizer)\n",
    "            \n",
    "        else:\n",
    "            print(f\"No improvement in training loss..the global training loss is -->{global_tr_loss:.2f} \")\n",
    "            print(f\" epoch= {i+1} and mean train loss is {epoch_train_loss:.2f}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    return model\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "995fca6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train model. Device = cuda:0\n",
      "executing epoch:1, it took 11.394673649470011 mins from beginning of epoch till batch#1049\n",
      "No improvement in training loss..the global training loss is -->inf \n",
      " epoch= 1 and mean train loss is nan\n",
      "executing epoch:2, it took 11.377593251069387 mins from beginning of epoch till batch#1049\n",
      "No improvement in training loss..the global training loss is -->inf \n",
      " epoch= 2 and mean train loss is nan\n",
      "executing epoch:3, it took 11.383647147814433 mins from beginning of epoch till batch#1049\n",
      "No improvement in training loss..the global training loss is -->inf \n",
      " epoch= 3 and mean train loss is nan\n",
      "executing epoch:4, it took 11.390172771612804 mins from beginning of epoch till batch#1049\n",
      "No improvement in training loss..the global training loss is -->inf \n",
      " epoch= 4 and mean train loss is nan\n",
      "executing epoch:5, it took 11.405706361929576 mins from beginning of epoch till batch#1049\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7361/3629111946.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mmodel_4bit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7361/3987252857.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(train_loader, val_loader, model, num_epoch, device, tokenizer)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mact_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mact_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mgrad_accum_step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0maccelerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mepoch_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mact_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m \u001b[0mgrad_accum_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr_model = train_model(train_loader, val_loader, model =  model_4bit,tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d48a28d",
   "metadata": {},
   "source": [
    "## Use this section if you want a model with Random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932bc69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, AutoConfig\n",
    "# Define the model name\n",
    "model_name = \"distilgpt2\"\n",
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Load the model configuration\n",
    "config = AutoConfig.from_pretrained(model_name)\n",
    "\n",
    "# Initialize the model with random weights\n",
    "model = AutoModelForCausalLM.from_config(config)\n",
    "\n",
    "# Check the model\n",
    "#print(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc5052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6834dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(df_train.iloc[178]['input_ids'], dtype = torch.long)\n",
    "att = torch.tensor(df_train.iloc[178]['attention_mask'], dtype = torch.long)\n",
    "random_out = model(input_ids = x.view(B,T) , attention_mask = att.view(B,T), labels =   x.view(B,T) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b3af7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd78d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d29399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f60be1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38046b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb37397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1047344b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c366c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf45ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd89757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bdaa151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c8d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
