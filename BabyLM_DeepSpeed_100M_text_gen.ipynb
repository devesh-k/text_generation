{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eae153",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference https://huggingface.co/learn/nlp-course/en/chapter7/6?fw=pt#training-a-causal-language-model-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4daa5930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.0), only 1.0.0 is known to be compatible\n"
     ]
    }
   ],
   "source": [
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee54687d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.19.2)\n",
      "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2024.3.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.62.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.23.0)\n",
      "Requirement already satisfied: requests>=2.32.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.1->datasets) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.1->datasets) (2.0.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.1->datasets) (3.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.32.1->datasets) (1.26.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.4)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.46)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.1)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing some libraries\n",
    "!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5fb9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig,AutoModelForCausalLM\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch import cuda\n",
    "import datetime \n",
    "import warnings,itertools\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pip install transformers bitsandbytes>=0.39.0 -q\n",
    "import zipfile\n",
    "import deepspeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef6b95a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "model\n"
     ]
    }
   ],
   "source": [
    "#global params for training\n",
    "\n",
    "batch_size = 32\n",
    "epoch = 15\n",
    "min_text_len = 0\n",
    "# train_loss_list = []\n",
    "# val_loss_list =[]\n",
    "if cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "#print(device)\n",
    "import os\n",
    "#os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "#os.environ[\"MKL_DEBUG_CPU_TYPE\"] = \"5\"\n",
    "context_length = None\n",
    "global_tr_loss = torch.inf\n",
    "global_val_loss = torch.inf\n",
    "#print(global_tr_loss)\n",
    "model_path = os.path.join(\"model\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4aa9dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deepspeed_config(loader,batch_size = batch_size , num_epoch = epoch):\n",
    "    \n",
    "    ds_config = {\n",
    "    \"train_batch_size\": batch_size ,  # batch_size * gradient_accumulation_steps * num_GPUs\n",
    "    \"gradient_accumulation_steps\": 4,\n",
    "    \"fp16\": {\"enabled\": True},\n",
    "    \"zero_optimization\": {\"stage\": 2},\n",
    "    \"optimizer\": {\"type\": \"Adam\",\"params\": {\"lr\": 5e-5} },\n",
    "    \"scheduler\": {\"type\": \"WarmupCosineLR\",\n",
    "                  \"params\": {\"warmup_num_steps\": len(loader)*num_epoch*.1, \"total_num_steps\": len(loader)*num_epoch }\n",
    "                 },\n",
    "    \n",
    "}\n",
    "    return ds_config\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb7eef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/unzip_text_100M'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join('.','data','unzip_text_100M')  # Replace with your directory path\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c2639a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(directory):\n",
    "    directory = os.path.join('.','data','unzip_text_100M',str(directory))  # Replace with your directory path\n",
    "    print(f\"directory :{directory}\")\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    print(f\"files:{files}\")\n",
    "    text_content = []\n",
    "    # Read each file\n",
    "    total_lines = 0\n",
    "    for filenum,filename in enumerate(files):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            #first_line = file.read()\n",
    "            #print(f\"filename :{filename}->first few lines {first_line}\")\n",
    "            #continue\n",
    "            lines_list = [line.strip() for line in open(file_path, 'r')]\n",
    "            print(f\"the file:{filename} added {len(lines_list)} rows to the list\")\n",
    "            total_lines+=len(lines_list)\n",
    "            text_content.append(lines_list)\n",
    "    \n",
    "    flattened_list = list(itertools.chain(*text_content))\n",
    "    assert (len(flattened_list) == total_lines , f\"Expected {len(flattened_list)} to be equal to {total_lines}\" )\n",
    "    \n",
    "    return flattened_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d2fadbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_100M/train_100M\n",
      "files:['switchboard.train', 'simple_wiki.train', 'open_subtitles.train', 'gutenberg.train', 'childes.train', 'bnc_spoken.train']\n",
      "the file:switchboard.train added 161740 rows to the list\n",
      "the file:simple_wiki.train added 646969 rows to the list\n",
      "the file:open_subtitles.train added 3495000 rows to the list\n",
      "the file:gutenberg.train added 676014 rows to the list\n",
      "the file:childes.train added 5790000 rows to the list\n",
      "the file:bnc_spoken.train added 818961 rows to the list\n"
     ]
    }
   ],
   "source": [
    "train_list = read_text(\"train_100M\")\n",
    "#print(train_dict)\n",
    "#val_list = read_text(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46080b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f19f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59d4ffcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A:\\tOkay.',\n",
       " 'A:\\tSo, What kind of experience do you, do you have, then with child care?',\n",
       " 'B:\\tI guess, I think, uh, I wonder if that worked.',\n",
       " 'A:\\tDoes it say something?',\n",
       " 'B:\\tI think it usually does.',\n",
       " 'B:\\tYou might try, uh,',\n",
       " \"B:\\tI don't know,\",\n",
       " 'B:\\thold it down a little longer,',\n",
       " 'B:\\tand see if it, uh,',\n",
       " 'A:\\tOkay']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "258922f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_100M/train_100M\n",
      "files:['switchboard.train', 'simple_wiki.train', 'open_subtitles.train', 'gutenberg.train', 'childes.train', 'bnc_spoken.train']\n",
      "the file:switchboard.train added 161740 rows to the list\n",
      "the file:simple_wiki.train added 646969 rows to the list\n",
      "the file:open_subtitles.train added 3495000 rows to the list\n",
      "the file:gutenberg.train added 676014 rows to the list\n",
      "the file:childes.train added 5790000 rows to the list\n",
      "the file:bnc_spoken.train added 818961 rows to the list\n",
      "directory :./data/unzip_text_100M/dev\n",
      "files:['switchboard.dev', 'simple_wiki.dev', 'open_subtitles.dev', 'gutenberg.dev', 'childes.dev', 'bnc_spoken.dev']\n",
      "the file:switchboard.dev added 18000 rows to the list\n",
      "the file:simple_wiki.dev added 60000 rows to the list\n",
      "the file:open_subtitles.dev added 375000 rows to the list\n",
      "the file:gutenberg.dev added 65000 rows to the list\n",
      "the file:childes.dev added 520153 rows to the list\n",
      "the file:bnc_spoken.dev added 130000 rows to the list\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame(read_text(\"train_100M\"), columns=['text'])\n",
    "df_val = pd.DataFrame(read_text(\"dev\"), columns=['text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "246987c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A:\\tOkay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A:\\tSo, What kind of experience do you, do you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B:\\tI guess, I think, uh, I wonder if that wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A:\\tDoes it say something?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B:\\tI think it usually does.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                          A:\\tOkay.\n",
       "1  A:\\tSo, What kind of experience do you, do you...\n",
       "2  B:\\tI guess, I think, uh, I wonder if that wor...\n",
       "3                         A:\\tDoes it say something?\n",
       "4                       B:\\tI think it usually does."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31843b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb7fe85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11588684\n",
      "1168153\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e32f06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A:\\tOkay.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A:\\tSo, What kind of experience do you, do you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B:\\tI guess, I think, uh, I wonder if that wor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A:\\tDoes it say something?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B:\\tI think it usually does.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                                          A:\\tOkay.\n",
       "1  A:\\tSo, What kind of experience do you, do you...\n",
       "2  B:\\tI guess, I think, uh, I wonder if that wor...\n",
       "3                         A:\\tDoes it say something?\n",
       "4                       B:\\tI think it usually does."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "449aed41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create a new column called 'length' on our dataframe to analyze the text\n",
    "\n",
    "df_train['length'] = df_train['text'].apply(lambda x: len(x))\n",
    "df_val['length'] = df_val['text'].apply(lambda x: len(x))\n",
    "#df_test['length'] = df_test['text'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83d746fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A:\\tOkay.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A:\\tSo, What kind of experience do you, do you...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B:\\tI guess, I think, uh, I wonder if that wor...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A:\\tDoes it say something?</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B:\\tI think it usually does.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length\n",
       "0                                          A:\\tOkay.       8\n",
       "1  A:\\tSo, What kind of experience do you, do you...      73\n",
       "2  B:\\tI guess, I think, uh, I wonder if that wor...      49\n",
       "3                         A:\\tDoes it say something?      25\n",
       "4                       B:\\tI think it usually does.      27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd8c32",
   "metadata": {},
   "source": [
    "## Analyzing the length of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67095a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the range of length in the train set is 20199 down to 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"the range of length in the train set is {max(df_train.length)} down to {min(df_train.length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4799625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Lets check the the distributions\n",
    "\n",
    "sns.histplot(df_train['length'], bins='auto')\n",
    "plt.title('Histogram of text lengths')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d1c09f",
   "metadata": {},
   "source": [
    "#### we see that majority of the text is between 0 and 2000. Since the maximum length of text the GPT model handles is 1024, let's see that distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02083cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0  100  200  300  400  500  600  700  800  900 1000 1100 1200 1300\n",
      " 1400 1500 1600 1700 1800 1900]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "array = np.arange(0, 2000, step=100)\n",
    "print(array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b707d219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(df_train['length'], bins= array)\n",
    "plt.title('Histogram with length of text from 0 to  Model max capacity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9769325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fewer than 0.11859845345683771% of rows have text more than the length of model\n"
     ]
    }
   ],
   "source": [
    "# Let us check the number of rows whose length > 1024(the defualt length that the tokenizer can process)\n",
    "exceed_tok_len = sum(df_train['length']> 1024)/len(df_train)*100\n",
    "print(f\"fewer than {exceed_tok_len}% of rows have text more than the length of model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b14953b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131035"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets check for the number of rows where length is 0\n",
    "sum(df_train['length'] == min_text_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3192746e",
   "metadata": {},
   "source": [
    "#### We notice that some of the rows in our dataframe have no text.\n",
    "Removing such rows and resetting the indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "466415bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[df_train['length'].astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27c313d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df_val[df_val['length'].astype(bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e0032",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dcaa2133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_train['length'] == min_text_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eaa443b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df_val['length'] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7c2717c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A:\\tOkay.</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A:\\tSo, What kind of experience do you, do you...</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B:\\tI guess, I think, uh, I wonder if that wor...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A:\\tDoes it say something?</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B:\\tI think it usually does.</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  length\n",
       "0                                          A:\\tOkay.       8\n",
       "1  A:\\tSo, What kind of experience do you, do you...      73\n",
       "2  B:\\tI guess, I think, uh, I wonder if that wor...      49\n",
       "3                         A:\\tDoes it say something?      25\n",
       "4                       B:\\tI think it usually does.      27"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6632a19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the index\n",
    "df_train.reset_index(drop=True, inplace=True)\n",
    "df_val.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44e02f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "6\n",
      "The context length is 64 \n"
     ]
    }
   ],
   "source": [
    "#calc the average len of the text:\n",
    "mean_len = int(df_train.length.mean())\n",
    "print(mean_len)\n",
    "import math\n",
    "power = math.ceil(math.log2(mean_len))\n",
    "print(power)\n",
    "context_length = 2**power\n",
    "context_length\n",
    "print(f\"The context length is {context_length} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "81a953dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003965139389038086,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer_config.json",
       "rate": null,
       "total": 26,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d52bd9bcac4eb897ae4c32df1f39bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0038552284240722656,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "config.json",
       "rate": null,
       "total": 762,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4457b3b80844a02933552c64960d598",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0034952163696289062,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "vocab.json",
       "rate": null,
       "total": 1042301,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2f3cb564a284344b82f9286986f70d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0031037330627441406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "merges.txt",
       "rate": null,
       "total": 456318,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f005bf1e6ef94c829a08966a7c6a2338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003481149673461914,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer.json",
       "rate": null,
       "total": 1355256,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fec00e08d8d84791aa6e9b3014bddcd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the tokenizer:\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\", padding = True ,return_tensors = \"pt\" , truncate = True, max_length  = context_length ,return_overflowing_tokens=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilgpt2\",return_tensors = \"pt\" , truncate = True, max_length  = context_length ,return_overflowing_tokens=True , padding = False)\n",
    "\n",
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
    "#model = AutoModelForCausalLM.from_pretrained('./model/model2024-05-2923:30:09_.pth', from_flax=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4cfb7028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model/tokenizer_config.json',\n",
       " './model/special_tokens_map.json',\n",
       " './model/vocab.json',\n",
       " './model/merges.txt',\n",
       " './model/added_tokens.json',\n",
       " './model/tokenizer.json')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"./model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1cb8796",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2f1eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt(Dataset):\n",
    "    def __init__(self, df, tokenizer, max_length = context_length ):\n",
    "        self.df = df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "                                \n",
    "    def __getitem__(self, idx):\n",
    "        #print(f\"inside loader...idx ->{idx}\")\n",
    "        text = self.df.iloc[idx]['text']\n",
    "        #print(f\"length of text ->{len(text)}\")\n",
    "        #print(f\"text ->{text}\")\n",
    "        #encodings = tokenizer(text, truncation=True, max_length= self.max_length, return_overflowing_tokens=True, padding = 'max_length',return_tensors='pt')\n",
    "        encodings = tokenizer(text, truncation=True, max_length= self.max_length, return_overflowing_tokens=True, padding = False)\n",
    "        # check the length of the encoded list\n",
    "        \n",
    "        #x_dict['input_id'] = input_ids_list\n",
    "        #x_dict['attention_mask'] = input_ids_list\n",
    "                \n",
    "        #print(f\"x_dict = {x_dict}\")             \n",
    "#       print(f\"inside the loader and input_id = {input_ids} and its shape is {input_ids.shape}\")\n",
    "        #labels = input_id_list\n",
    "        #input_ids = torch.tensor(input_id_list)\n",
    "        #attention_mask = torch.tensor(attention_mask_list)\n",
    "        #labels = torch.tensor(labels)\n",
    "        #print(f\"inside the loader and input_id shape= {input_ids.shape} attention_mask_shape is {attention_mask.shape} and label shape is {labels.shape}\")\n",
    "        #print(f\"encoding = {encodings}\")\n",
    "               \n",
    "        return encodings\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89a8450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch, ):\n",
    "    x_dict = {}\n",
    "    #print(\"CUSTOM COllate\")\n",
    "    #print(f\"bacth = {batch}\")\n",
    "    input_ids_list = []\n",
    "    att_mask_list = [] \n",
    "    for elem,item in enumerate(batch):\n",
    "        #print(f\"element {elem}\")\n",
    "        #print(f\"item = {item}\")\n",
    "        #check whether there are any nested lists :\n",
    "        if len(item['input_ids']) > 1:\n",
    "            #print(f\"flattening the list\")\n",
    "            input_id_tensor = torch.tensor(list(itertools.chain(*item['input_ids'])))\n",
    "            #print(f\"shape of the flattended tensor = {input_id_tensor.shape}\")\n",
    "            input_ids_list.append(input_id_tensor[:1024])\n",
    "            att_mask_tensor = torch.tensor(list(itertools.chain(*item['attention_mask'])))\n",
    "            att_mask_list.append(att_mask_tensor[:1024])\n",
    "        else:\n",
    "            input_id_tensor = torch.tensor(item['input_ids']).squeeze(0)\n",
    "            input_ids_list.append(input_id_tensor)\n",
    "            att_mask_tensor = torch.tensor(item['attention_mask']).squeeze(0)\n",
    "            #print(f\"shape of att_mask_tensor tensor = {att_mask_tensor.shape}\")\n",
    "            att_mask_list.append(att_mask_tensor)\n",
    "    #attention_mask = [item['attention_mask'].squeeze(0) for item in batch]\n",
    "\n",
    "    # Pad sequences to the same length\n",
    "    #print(f\"len of input_id_list = {len(input_ids_list)}\")\n",
    "    #print(f\"len of attmask_list = {len(att_mask_list)}\")\n",
    "    #input_id_tensor = torch.tensor(input_ids_list).squeeze()\n",
    "    #att_mask_tensor = torch.tensor(att_mask_list).squeeze()\n",
    "    #print(\"*********************\")\n",
    "    #print(f\"input_ids_list = {input_ids_list}\")\n",
    "    \n",
    "        \n",
    "    \n",
    "    input_ids = torch.nn.utils.rnn.pad_sequence(input_ids_list, batch_first=True, padding_value=tokenizer.eos_token_id)\n",
    "    attention_mask = torch.nn.utils.rnn.pad_sequence(att_mask_list, batch_first=True, padding_value=0)\n",
    "    #print(f\"shape of input_id tensor post padding -{input_ids.shape}\")\n",
    "    #print(f\"shape of attention_masks tensor post padding -{attention_mask.shape}\")\n",
    "    x_dict['input_ids'] = input_ids\n",
    "    x_dict['attention_mask'] = attention_mask\n",
    "    \n",
    "    return x_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7f0e1e26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1968"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f55ba2cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11457649"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = list(df_train['text'])\n",
    "len(all_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58ea4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = dataset_pyt(filtered_df,tokenizer = tokenizer)\n",
    "train_dataset = dataset_pyt(df_train,tokenizer = tokenizer)\n",
    "val_dataset = dataset_pyt(df_val,tokenizer = tokenizer)\n",
    "#test_dataset = dataset_pyt(df_test,tokenizer = tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = batch_size, shuffle = True , num_workers = 4, pin_memory = True, collate_fn = custom_collate_fn)\n",
    "val_loader = DataLoader(val_dataset,batch_size = batch_size*3, shuffle = True , collate_fn = custom_collate_fn, num_workers = 4, pin_memory = True)\n",
    "#test_loader = DataLoader(test_dataset,batch_size = batch_size, shuffle = False, collate_fn = custom_collate_fn)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d08eec3",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2dcb979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of train loader is 358052\n"
     ]
    }
   ],
   "source": [
    "print(f\"The length of train loader is {len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a96a93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b65a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/73948214/how-to-convert-a-pytorch-nn-module-into-a-huggingface-pretrainedmodel-object/74109727#74109727\n",
    "# this code is needed to save the HF model as pre-trained and use this model as inference\n",
    "# class MyConfig(PretrainedConfig):\n",
    "#     model_type = 'mymodel'\n",
    "#     def __init__(self, important_param=42, **kwargs):\n",
    "#         super().__init__(**kwargs)\n",
    "#         self.important_param = important_param\n",
    "\n",
    "# class MyModel(PreTrainedModel):\n",
    "#     config_class = MyConfig\n",
    "#     def __init__(self, config):\n",
    "#         super().__init__(config)\n",
    "#         self.config = config\n",
    "#         self.model = clf_model_drp()\n",
    "#     def forward(self, ids ,token_type,att_mask):\n",
    "#         return self.model(ids ,token_type,att_mask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4acbb45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ind , batch in enumerate(train_loader):\n",
    "#     print(f\"batch ind ={ind}\")\n",
    "#     print(batch['input_ids'].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8476ea7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def eval_model(val_loader, model, epoch , device = device,):\n",
    "    global global_val_loss\n",
    "    #m = nn.Softmax()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    e = epoch+1\n",
    "    val_loss_list = []\n",
    "    #criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    print(f\"inside validation data for epoch {e}\")\n",
    "    #y_hat_val_list = []\n",
    "    #y_val_list = []\n",
    "    \n",
    "    for ind,x_dict  in enumerate(val_loader):\n",
    "        ids = x_dict['input_ids'].to(device=device, non_blocking=True)\n",
    "        att_mask = x_dict['attention_mask'].to(device=device, non_blocking=True)\n",
    "        labels = ids\n",
    "        with autocast():\n",
    "            model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "            act_loss = model_output.loss\n",
    "        \n",
    "        val_loss_list.append(act_loss)\n",
    "        del ids,att_mask,labels\n",
    "                    \n",
    "    mean_val_loss = torch.mean(torch.tensor(val_loss_list))\n",
    "    if mean_val_loss < global_val_loss:\n",
    "        print(f\"Val loss has decreased -->reducing the global validation loss from {global_val_loss:.2f} to {mean_val_loss:.2f}\")\n",
    "        global_val_loss = mean_val_loss\n",
    "        print(f\" validation loss for epoch = {e} is {torch.mean(torch.tensor(val_loss_list)):.4f}\")\n",
    "        #print metrics and save the model\n",
    "        #y_hat_val = torch.cat(y_hat_val_list)\n",
    "        #y_val = torch.cat(y_val_list)\n",
    "        #acc_val = accuracy_score(y_val.cpu().numpy(), y_hat_val.cpu().numpy())\n",
    "        #f1_val = f1_score(y_val.cpu().numpy(), y_hat_val.cpu().numpy(), average='micro')\n",
    "        print(f\" epoch= {e} : mean val loss is {torch.mean(torch.tensor(mean_val_loss)):.4f} \")\n",
    "        #save the model\n",
    "        \n",
    "        # Get the current date and time\n",
    "        current_datetime = datetime.datetime.now()\n",
    "        # Extract date and time components\n",
    "        current_date = str(current_datetime.date())\n",
    "        current_time = str(current_datetime.time()).split('.')[0]\n",
    "        file_name = 'model'+ current_date+current_time+'_'+'.pth'\n",
    "        path = os.path.join(\"model\",file_name)\n",
    "        print(f\"saving the model {file_name}\")\n",
    "        #torch.save(model.state_dict(), path)\n",
    "        model.save_pretrained(path)\n",
    "        \n",
    "        #plot_confusion_matrix(y_val.cpu().numpy(), y_hat_val.cpu().numpy(), labels)\n",
    "    else:\n",
    "        print(f\"No improvement in validation loss-->epoch= {e} and global val loss is {global_val_loss:.2f}\")\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ac23107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,val_loader,model,num_epoch = 30,device = device):\n",
    "    global global_tr_loss\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    device = device\n",
    "    print(f\"inside train model. Device = {device}\")\n",
    "    optimizer = torch.optim.AdamW(params =  model.parameters(), lr= 5e-5)\n",
    "    model.to(device)\n",
    "    #m = nn.Softmax()\n",
    "    import time\n",
    "    scheduler = transformers.get_cosine_schedule_with_warmup( optimizer= optimizer, num_warmup_steps =len(train_loader)*num_epoch*.1 ,num_training_steps= len(train_loader)*num_epoch,last_epoch = -1 )\n",
    "    accumulation_steps = 4 \n",
    "    for i in range (num_epoch):\n",
    "        epoch_train_loss = []\n",
    "        epoch_start_time = time.time()\n",
    "        \n",
    "        for ind,x_dict in enumerate(train_loader):\n",
    "            \n",
    "            #print(f\"x_dict = {x_dict}\")\n",
    "            id_list = x_dict['input_ids']\n",
    "            #print(f\"id_list{id_list}\")\n",
    "            if ind%10000 == 0:\n",
    "                batch_time = time.time()\n",
    "                duration = batch_time - epoch_start_time\n",
    "                print(f\"executing epoch:{i+1}, it took {duration/60} mins from beginning of epoch till batch#{ind}\")\n",
    "            \n",
    "            ids = x_dict['input_ids'].to(device=device, non_blocking=True)\n",
    "            att_mask = x_dict['attention_mask'].to(device=device, non_blocking=True)\n",
    "            labels = ids\n",
    "            \n",
    "            with autocast():\n",
    "                model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "                act_loss = model_output.loss\n",
    "                      \n",
    "            epoch_train_loss.append(act_loss)\n",
    "            \n",
    "            if i % accumulation_steps == 0:\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            \n",
    "            scaler.scale(act_loss).backward()\n",
    "            scheduler.step()\n",
    "            \n",
    "            if (i + 1) % accumulation_steps == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            \n",
    "            #print(f\"current LR->{scheduler.get_last_lr()}\")\n",
    "            \n",
    "            del ids,att_mask,labels\n",
    "            \n",
    "        #batch processing complete    \n",
    "        mean_loss = torch.mean(torch.tensor(epoch_train_loss))\n",
    "        \n",
    "        if mean_loss < global_tr_loss:\n",
    "            print(f\"training loss has decreased---> reducing the global loss from {global_tr_loss:.2f} to {mean_loss:.2f}\")\n",
    "            global_tr_loss = mean_loss\n",
    "            print(f\" epoch= {i+1} and mean train loss is {torch.mean(torch.tensor(epoch_train_loss)):.2f}\")\n",
    "            #printing training metrices\n",
    "            #y_hat = torch.cat(y_hat_list)\n",
    "            #y = torch.cat(label_list)\n",
    "            #acc = accuracy_score(y.cpu().numpy(), y_hat.cpu().numpy())\n",
    "            #f1 = f1_score(y.cpu().numpy(), y_hat.cpu().numpy(), average='micro')\n",
    "            print(f\" epoch= {i+1} : mean train loss is {torch.mean(torch.tensor(epoch_train_loss)):.4f} \")\n",
    "            #checking validation metrices\n",
    "            eval_model(val_loader, model, epoch = i , device = device)\n",
    "            \n",
    "        else:\n",
    "            print(f\"No improvement in training loss..the global training loss is -->{global_tr_loss:.2f} \")\n",
    "            print(f\" epoch= {i+1} and mean train loss is {torch.mean(torch.tensor(epoch_train_loss)):.2f}\")\n",
    "        \n",
    "        \n",
    "    \n",
    "    return model\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "159e695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-09 20:27:47,889] [INFO] [logging.py:96:log_dist] [Rank -1] DeepSpeed info: version=0.14.2, git-hash=unknown, git-branch=unknown\n",
      "[2024-06-09 20:27:47,890] [INFO] [comm.py:637:init_distributed] cdb=None\n",
      "[2024-06-09 20:27:47,891] [INFO] [comm.py:652:init_distributed] Not using the DeepSpeed or dist launchers, attempting to detect MPI environment...\n",
      "[2024-06-09 20:27:48,262] [INFO] [comm.py:702:mpi_discovery] Discovered MPI settings of world_rank=0, local_rank=0, world_size=1, master_addr=172.18.0.3, master_port=29500\n",
      "[2024-06-09 20:27:48,262] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use).\n",
      "[W socket.cpp:464] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).\n",
      "[E socket.cpp:500] [c10d] The server socket has failed to listen on any local network address.\n"
     ]
    },
    {
     "ename": "DistNetworkError",
     "evalue": "The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDistNetworkError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_681/330912376.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mds_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_deepspeed_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel_engine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/deepspeed/__init__.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(args, model, optimizer, model_parameters, training_data, lr_scheduler, distributed_port, mpu, dist_init_required, collate_fn, config, config_params)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mdeepspeed\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcomm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mdist_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accelerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunication_backend_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     dist.init_distributed(dist_backend=dist_backend,\n\u001b[0m\u001b[1;32m    144\u001b[0m                           \u001b[0mdistributed_port\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdistributed_port\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m                           dist_init_required=dist_init_required)\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/deepspeed/comm/comm.py\u001b[0m in \u001b[0;36minit_distributed\u001b[0;34m(dist_backend, auto_mpi_discovery, distributed_port, verbose, timeout, init_method, dist_init_required, config, rank, world_size)\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initializing TorchBackend in DeepSpeed with backend {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0;31m# Create a torch backend object, initialize torch distributed, and assign to cdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mcdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTorchBackend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/deepspeed/comm/torch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backend, timeout, init_method, rank, world_size, name)\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# it is not so we can run on a single GPU without doing any init_process_group\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshm_comm_op\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshm_comm_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_world_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/deepspeed/comm/torch.py\u001b[0m in \u001b[0;36minit_process_group\u001b[0;34m(self, backend, timeout, init_method, rank, world_size)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_process_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             torch.distributed.init_process_group(backend,\n\u001b[0m\u001b[1;32m    143\u001b[0m                                                  \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                                                  \u001b[0minit_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit_method\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/c10d_logger.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mmsg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_msg_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/c10d_logger.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mfunc_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mtime_spent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_ns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36minit_process_group\u001b[0;34m(backend, init_method, timeout, world_size, rank, store, group_name, pg_options, device_id)\u001b[0m\n\u001b[1;32m   1303\u001b[0m                 \u001b[0mnot_none\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minit_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             )\n\u001b[0;32m-> 1305\u001b[0;31m             \u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrendezvous_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m             \u001b[0mstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/rendezvous.py\u001b[0m in \u001b[0;36m_env_rendezvous_handler\u001b[0;34m(url, timeout, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0muse_libuv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"use_libuv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"USE_LIBUV\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m     \u001b[0mstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_c10d_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaster_addr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaster_port\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_libuv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/distributed/rendezvous.py\u001b[0m in \u001b[0;36m_create_c10d_store\u001b[0;34m(hostname, port, rank, world_size, timeout, use_libuv)\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mstart_daemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         return TCPStore(\n\u001b[0m\u001b[1;32m    175\u001b[0m             \u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworld_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_daemon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_tenant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_libuv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_libuv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         )\n",
      "\u001b[0;31mDistNetworkError\u001b[0m: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:29500 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use)."
     ]
    }
   ],
   "source": [
    "#get DS config \"\n",
    "\n",
    "ds_config = get_deepspeed_config(train_loader)\n",
    "model_engine, optimizer, _, _ = deepspeed.initialize(model=model, config=ds_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5254ff31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train model. Device = cuda:0\n",
      "executing epoch:1, it took 0.01314107577006022 mins from beginning of epoch till batch#0\n",
      "executing epoch:1, it took 5.694445371627808 mins from beginning of epoch till batch#10000\n",
      "executing epoch:1, it took 11.273993798096974 mins from beginning of epoch till batch#20000\n",
      "executing epoch:1, it took 16.77186909914017 mins from beginning of epoch till batch#30000\n",
      "executing epoch:1, it took 22.434137884775797 mins from beginning of epoch till batch#40000\n",
      "executing epoch:1, it took 27.98102770249049 mins from beginning of epoch till batch#50000\n",
      "executing epoch:1, it took 33.55566846529643 mins from beginning of epoch till batch#60000\n",
      "executing epoch:1, it took 39.175751356283826 mins from beginning of epoch till batch#70000\n",
      "executing epoch:1, it took 44.81544378598531 mins from beginning of epoch till batch#80000\n",
      "executing epoch:1, it took 50.498451066017154 mins from beginning of epoch till batch#90000\n",
      "executing epoch:1, it took 56.03616183201472 mins from beginning of epoch till batch#100000\n",
      "executing epoch:1, it took 61.582841690381365 mins from beginning of epoch till batch#110000\n",
      "executing epoch:1, it took 67.17964954376221 mins from beginning of epoch till batch#120000\n",
      "executing epoch:1, it took 72.75468461116155 mins from beginning of epoch till batch#130000\n",
      "executing epoch:1, it took 78.27845369577408 mins from beginning of epoch till batch#140000\n",
      "executing epoch:1, it took 83.91836626927058 mins from beginning of epoch till batch#150000\n",
      "executing epoch:1, it took 89.56817535956701 mins from beginning of epoch till batch#160000\n",
      "executing epoch:1, it took 95.18420365254084 mins from beginning of epoch till batch#170000\n",
      "executing epoch:1, it took 100.72133987347284 mins from beginning of epoch till batch#180000\n",
      "executing epoch:1, it took 106.26306132475536 mins from beginning of epoch till batch#190000\n",
      "executing epoch:1, it took 111.84904932975769 mins from beginning of epoch till batch#200000\n",
      "executing epoch:1, it took 117.41391886870066 mins from beginning of epoch till batch#210000\n",
      "executing epoch:1, it took 123.03660399913788 mins from beginning of epoch till batch#220000\n",
      "executing epoch:1, it took 128.5862808863322 mins from beginning of epoch till batch#230000\n",
      "executing epoch:1, it took 134.16216199000675 mins from beginning of epoch till batch#240000\n",
      "executing epoch:1, it took 139.77152571280797 mins from beginning of epoch till batch#250000\n",
      "executing epoch:1, it took 145.2926940282186 mins from beginning of epoch till batch#260000\n",
      "executing epoch:1, it took 150.91142939329148 mins from beginning of epoch till batch#270000\n",
      "executing epoch:1, it took 156.53101109663646 mins from beginning of epoch till batch#280000\n",
      "executing epoch:1, it took 162.10435740550358 mins from beginning of epoch till batch#290000\n",
      "executing epoch:1, it took 167.70033065080642 mins from beginning of epoch till batch#300000\n",
      "executing epoch:1, it took 173.28322136799494 mins from beginning of epoch till batch#310000\n",
      "executing epoch:1, it took 178.93082517385483 mins from beginning of epoch till batch#320000\n",
      "executing epoch:1, it took 184.481918434302 mins from beginning of epoch till batch#330000\n"
     ]
    }
   ],
   "source": [
    "# config = MyConfig(42)\n",
    "# model = MyModel(config)\n",
    "\n",
    "#train_loader,optimizer,val_loader ,num_epoch = 100, model = clf_model()\n",
    "tr_model = train_model(train_loader, val_loader, model =  model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c000e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "12a6725c",
   "metadata": {},
   "source": [
    "### Evaluating the models on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37390637",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(element):\n",
    "    outputs = tokenizer(\n",
    "        element[\"content\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    input_batch = []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "    return {\"input_ids\": input_batch}\n",
    "\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize, batched=True, remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506f7376",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df_train.iloc[400327]['text']\n",
    "print (t)\n",
    "print(len(t))\n",
    "encoded = tokenizer(t, truncation=True, max_length=context_length, return_overflowing_tokens=True, padding = 'max_length',return_length= True)\n",
    "print(encoded)\n",
    "input_ids = torch.tensor(encoded['input_ids'])\n",
    "print(f\"inside the loader and input_id = {input_ids} and its shape is {input_ids.shape}\")\n",
    "\n",
    "attention_mask = torch.tensor(encoded['attention_mask'])\n",
    "#       print(f\"inside the loader and input_id = {input_ids} and its shape is {input_ids.shape}\")\n",
    "labels = input_ids.clone()\n",
    "print(f\"inside the loader and input_id shape= {input_ids.shape} attention_mask_shape is {attention_mask.shape} and label shape is {labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479e8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pred(loader, model, device = device,):\n",
    "    m = nn.Softmax()\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    test_loss_list = []\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    y_hat_test_list = []\n",
    "    y_test_list = []\n",
    "    for ind,(x_dict, label_vec) in enumerate(loader):\n",
    "        model.to(device)\n",
    "        id_list = x_dict['id']\n",
    "        ids = torch.squeeze(torch.tensor(id_list, device = device),dim = 1).clone().detach()\n",
    "        tok_type_list = x_dict['token_type']\n",
    "        token_type = torch.squeeze(torch.tensor(tok_type_list, device = device),dim = 1).clone().detach()\n",
    "        att_list = x_dict['attention_mask']\n",
    "        att_mask = torch.squeeze(torch.tensor(att_list, device = device),dim = 1).clone().detach()\n",
    "        lab = label_vec.to(torch.device('cuda:0'))\n",
    "        logits = model(ids ,token_type,att_mask)\n",
    "        \n",
    "        probs = m(logits)\n",
    "        y_hat_test_list.append(torch.argmax(probs , dim = 1))\n",
    "        y_test_list.append(torch.argmax(lab , dim = 1))\n",
    "        \n",
    "        act_loss = criterion(logits, lab)\n",
    "        test_loss_list.append(act_loss.item())\n",
    "            \n",
    "    mean_test_loss = torch.mean(torch.tensor(test_loss_list))\n",
    "    print(f\" Test loss is {torch.mean(torch.tensor(test_loss_list)):.4f}\")\n",
    "    #print metrics and save the model\n",
    "    y_hat_test = torch.cat(y_hat_test_list)\n",
    "    y_test = torch.cat(y_test_list)\n",
    "    acc_test = accuracy_score(y_test.cpu().numpy(), y_hat_test.cpu().numpy())\n",
    "    f1_test = f1_score(y_test.cpu().numpy(), y_hat_test.cpu().numpy(), average='micro')\n",
    "    print(f\"mean loss is {torch.mean(torch.tensor(mean_test_loss)):.4f} -> the accuracy is {acc_test:.2f} ->the f1 is {f1_test:.2f} \")\n",
    "    #save the model\n",
    "    plot_confusion_matrix(y_test.cpu().numpy(), y_hat_test.cpu().numpy(), labels)\n",
    "\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06038f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c040bd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = MyModel.from_pretrained('./model/model2024-05-1712:14:28_mrpc.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred(test_loader , saved_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9ba0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = AutoModelForCausalLM.from_pretrained('./model/model2024-05-2923:30:09_.pth', from_flax=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e336342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new.save_pretrained('./model', safe_serialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6850406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
