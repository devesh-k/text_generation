{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52c9e191",
   "metadata": {},
   "source": [
    "## In this notebook, we scale the Cosine with (1-lambda)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d11a2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6685df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.8/site-packages (2.18.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.8/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from datasets) (1.21.4)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.8/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from datasets) (1.3.4)\n",
      "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (2024.2.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.23.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.8/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from datasets) (3.4.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (6.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.8/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.8/site-packages (from datasets) (4.66.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (21.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub>=0.19.4->datasets) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->datasets) (3.0.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2.0.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.2)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing some libraries\n",
    "!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa1e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig,AutoModelForCausalLM, AutoConfig\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch import cuda\n",
    "import datetime\n",
    "import warnings,itertools\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import json,math\n",
    "pre_train = False\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pip install transformers bitsandbytes>=0.39.0 -q\n",
    "import zipfile,logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25288c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#global params for training\n",
    "\n",
    "B,T = 32,1024\n",
    "epoch = 30\n",
    "# this controls whether we are using pre-trained wts or not\n",
    "random_init_wts = False\n",
    "if cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "# these 2 global vars help track the training and val loss\n",
    "#directory to save wts\n",
    "model_path = os.path.join(\"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbfe138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/unzip_text_10M'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join('.','data','unzip_text_10M')  # Replace with your directory path\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36d85a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(directory):\n",
    "    \"\"\"This function loads the dataset,provided in the zipped format and stores all the text files in list\n",
    "    each file has its contents stored as an item in list and at the end we concatenate all the sub-lists to create a flattened list and return it\"\"\"\n",
    "    directory = os.path.join('.','data','unzip_text_10M',str(directory))  # Replace with your directory path\n",
    "    print(f\"directory :{directory}\")\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    print(f\"files:{files}\")\n",
    "    text_content = []\n",
    "    # Read each file\n",
    "    total_lines = 0\n",
    "    for filenum,filename in enumerate(files):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            text_content.append(text)\n",
    "            print(f\"the file:{filename} has been appeneded to the uber list and its length is {len(text_content)} \")\n",
    "            \n",
    "    \n",
    "    flattened_list = ''.join(text_content)\n",
    "    assert (len(flattened_list) == total_lines , f\"Expected {len(flattened_list)} to be equal to {total_lines}\" )\n",
    "    \n",
    "    return flattened_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abd4378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/train_10M\n",
      "files:['switchboard.train', 'simple_wiki.train', 'open_subtitles.train', 'gutenberg.train', 'childes.train', 'bnc_spoken.train']\n",
      "the file:switchboard.train has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.train has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.train has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.train has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.train has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.train has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "#read the dataset and get a list\n",
    "train_list = read_text(\"train_10M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbb8fb35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54215049"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e796451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1654\n"
     ]
    }
   ],
   "source": [
    "chunks = len(train_list)//(B*T)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81426dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (17191971 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "#tokeinze the training data\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\",return_tensors = \"pt\" , truncate = True, return_overflowing_tokens=True , padding = False,)\n",
    "enc_train = tokenizer(train_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "458dcbb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1535097982657136"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_ratio = len(train_list)/len(enc_train['input_ids'])\n",
    "comp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9d4de63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/dev\n",
      "files:['switchboard.dev', 'simple_wiki.dev', 'open_subtitles.dev', 'gutenberg.dev', 'childes.dev', 'bnc_spoken.dev']\n",
      "the file:switchboard.dev has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.dev has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.dev has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.dev has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.dev has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.dev has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "#read validation data and tokenize\n",
    "val_list = read_text(\"dev\")\n",
    "enc_val = tokenizer(val_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e38c62",
   "metadata": {},
   "source": [
    "### we read the tokenize data and store the input_ids and attention mask as a single long list at run time we reshape the single [1,B*T] tensor into a batched tensor of dimension [B,T].\n",
    "This approach turns out to be more efficient as it removes the need for any extra tokens in the form of padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "acc3cf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_from_list(enc , B= B, T = T, val= False):\n",
    "    \"\"\"This function takes the tokenized list and reated a dataframe where each row contains the input_ids and attention_mask from the tokenizer.\n",
    "    each row of the dataframe is a list with items B*T\"\"\"\n",
    "    chunk_size = B*T\n",
    "    if val:\n",
    "        chunk_size = 2*B*T\n",
    "        \n",
    "    long_list_inp = enc['input_ids']\n",
    "    long_list_attention = enc['attention_mask']\n",
    "\n",
    "    # Step 3: Split the list into chunks and pad the last chunk if necessary\n",
    "    chunks_inp = [long_list_inp[i:i + chunk_size] for i in range(0, len(long_list_inp), chunk_size)]\n",
    "    chunks_att = [long_list_attention[i:i + chunk_size] for i in range(0, len(long_list_attention), chunk_size)]\n",
    "    df = pd.DataFrame({'input_ids': chunks_inp,'attention_mask':chunks_att})\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95f66286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataframe is = 525\n"
     ]
    }
   ],
   "source": [
    "df_train_temp = get_df_from_list(enc_train)\n",
    "# Display the DataFrame\n",
    "df_train_temp.head()\n",
    "print(f\"Length of the dataframe is = {len(df_train_temp)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04b13b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the VALDATION dataframe is = 532\n"
     ]
    }
   ],
   "source": [
    "df_val_temp = get_df_from_list(enc_val)\n",
    "# Display the DataFrame\n",
    "df_val_temp.head()\n",
    "print(f\"Length of the VALDATION dataframe is = {len(df_val_temp)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b444b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_df(df,eos_char = tokenizer.eos_token_id,B = B, T = T,val = False):\n",
    "    \"\"\"The 2 functions below makes sure that each row of the dataframe is of equal length and if not it adds the eos token to make it B*T\"\"\"\n",
    "    if val:\n",
    "        B = 2*B\n",
    "    for ind,row in df.iterrows():\n",
    "        if len(row['input_ids']) != B*T :\n",
    "            print(f\"row = {ind} and input_id length = {len(row['input_ids'])}\")\n",
    "            print(f\"row = {ind} and attention length = {len(row['attention_mask'])}\")\n",
    "            pad_len = B*T - len(row['input_ids'])\n",
    "            print(f\"padding the row index {ind} with {pad_len} character\")\n",
    "            row['input_ids'] = row['input_ids']+ [eos_char] * pad_len\n",
    "            #attention mask should be padded to 0\n",
    "            row['attention_mask'] = row['attention_mask']+ [0] * pad_len\n",
    "            print(\"#### POST CONCAT####\")\n",
    "            print(f\"row = {ind} and input_id length = {len(row['input_ids'])}\")\n",
    "            print(f\"row = {ind} and attention length ={len(row['attention_mask'])}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def verify_len(df,val = False, B= B):\n",
    "    row_ind = []\n",
    "    if val:\n",
    "        B = 2*B\n",
    "    for ind,row in df.iterrows():\n",
    "        if len(row['input_ids']) != B*T :\n",
    "            row_ind.append(ind)\n",
    "        else:\n",
    "            continue\n",
    "    if len(row_ind) !=0:\n",
    "        print(\"CONCATENATION Did not work\")\n",
    "    else:\n",
    "        print(\"CONCATENATION worked\")\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "483083d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = 524 and input_id length = 21539\n",
      "row = 524 and attention length = 21539\n",
      "padding the row index 524 with 11229 character\n",
      "#### POST CONCAT####\n",
      "row = 524 and input_id length = 32768\n",
      "row = 524 and attention length =32768\n",
      "CONCATENATION worked\n"
     ]
    }
   ],
   "source": [
    "df_train  = pad_df(df_train_temp)\n",
    "verify_len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc65651b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row = 531 and input_id length = 13588\n",
      "row = 531 and attention length = 13588\n",
      "padding the row index 531 with 19180 character\n",
      "#### POST CONCAT####\n",
      "row = 531 and input_id length = 32768\n",
      "row = 531 and attention length =32768\n",
      "CONCATENATION worked\n"
     ]
    }
   ],
   "source": [
    "df_val  = pad_df(df_val_temp)\n",
    "verify_len(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c799b02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[32, 25, 197, 40, 1101, 1654, 484, 389, 13, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[6510, 11, 14104, 290, 27913, 13, 198, 32, 25,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[314, 1612, 11, 340, 338, 1611, 286, 43244, 11...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[318, 407, 922, 329, 262, 1200, 2035, 13, 198,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[198, 32, 25, 197, 1870, 11, 21480, 11, 314, 4...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           input_ids  \\\n",
       "0  [32, 25, 197, 40, 1101, 1654, 484, 389, 13, 19...   \n",
       "1  [6510, 11, 14104, 290, 27913, 13, 198, 32, 25,...   \n",
       "2  [314, 1612, 11, 340, 338, 1611, 286, 43244, 11...   \n",
       "3  [318, 407, 922, 329, 262, 1200, 2035, 13, 198,...   \n",
       "4  [198, 32, 25, 197, 1870, 11, 21480, 11, 314, 4...   \n",
       "\n",
       "                                      attention_mask  \n",
       "0  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  \n",
       "4  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705e1f25",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d78528c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the tokenizer:\n",
    "model_name = \"gpt2\"\n",
    "if random_init_wts:\n",
    "    config = AutoConfig.from_pretrained(model_name, vocab_size = 50304)\n",
    "    # Initialize the model with random weights\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "else:\n",
    "    #model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "#model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37f8e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b729995a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "525"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87989ff7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# device = \"cuda\"\n",
    "# inp = torch.tensor(df_train.iloc[5]['input_ids']).view(B,T).to(device)\n",
    "# att = torch.tensor(df_train.iloc[5]['attention_mask']).view(B,T).to(device)\n",
    "# lab = inp.clone()\n",
    "# # lab = F.pad(lab[:, 1:], (0, 1), value=-100)  # Shift labels to the left and pad with -100\n",
    "# # lab[:, -1] = -100\n",
    "# model.to(device)\n",
    "# model_out = model(input_ids = inp, attention_mask = att , labels = lab)\n",
    "# assert not torch.isnan(inp).any(), \"Input contains NaN\"\n",
    "# assert not torch.isinf(inp).any(), \"Input contains inf\"\n",
    "# model_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bfd5376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Input shape: {inp.shape}\")\n",
    "# print(f\"Attention mask shape: {att.shape}\")\n",
    "# print(f\"Labels shape: {lab.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db1c25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d6535df",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab969c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_val(Dataset):\n",
    "    \"\"\"Dataset for validation data\"\"\"\n",
    "    def __init__(self, df, B = B, T = T ):\n",
    "        self.df = df\n",
    "        print(f\"Value of B {B}\")\n",
    "                                        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(f\"inside loader...idx ->{idx}\")\n",
    "        input_id_temp = torch.tensor(self.df.iloc[idx]['input_ids'],dtype = torch.long)\n",
    "        att_mask = torch.tensor(self.df.iloc[idx]['attention_mask'],dtype = torch.long)\n",
    "        input_id =   input_id_temp.view(B,T)    \n",
    "        attention_mask = att_mask.view(B,T)\n",
    "        \n",
    "        \n",
    "        return input_id, attention_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec3c8dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_train(Dataset):\n",
    "    def __init__(self, df, B = B, T = T ):\n",
    "        self.df = df\n",
    "                                        \n",
    "    def __getitem__(self, idx):\n",
    "        #print(f\"************* idx for dataloader = {idx}\")\n",
    "        input_id_temp = torch.tensor(self.df.iloc[idx]['input_ids'],dtype = torch.long)\n",
    "        att_mask = torch.tensor(self.df.iloc[idx]['attention_mask'],dtype = torch.long)\n",
    "        input_id =   input_id_temp.view(B,T)    \n",
    "        attention_mask = att_mask.view(B,T)   \n",
    "        \n",
    "        return input_id, attention_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        return len(self.df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e874332",
   "metadata": {},
   "source": [
    "### Note - batch_size is 1 here because we reshape our input data in the shape [B,T] for a batched training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9be42430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of B 32\n"
     ]
    }
   ],
   "source": [
    "#train_dataset = dataset_pyt(filtered_df,tokenizer = tokenizer)\n",
    "train_dataset = dataset_pyt_train(df_train)\n",
    "val_dataset = dataset_pyt_val(df_val)\n",
    "#test_dataset = dataset_pyt(df_test,tokenizer = tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = 1, shuffle = True , num_workers = 0, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = 1, shuffle = True , num_workers = 0, pin_memory = True)\n",
    "#test_loader = DataLoader(test_dataset,batch_size = batch_size, shuffle = False, collate_fn = custom_collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f3898",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8e63393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train loader is 525\n",
      "Length of the val loader is 532\n",
      "num_tokens= 17203200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the train loader is {len(train_loader)}\")\n",
    "print(f\"Length of the val loader is {len(val_loader)}\")\n",
    "print(f\"num_tokens= {B*T*len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f010bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(log_message, model_name = model_name ,random_init_wts = random_init_wts ):\n",
    "    \"\"\"This function logs the training performance for future reference\"\"\"\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    # Extract date and time components\n",
    "    current_date = str(current_datetime.date())\n",
    "    log_file = model_name +'_COS_SIM*lambda_'+'random_init_wts'+ '_'+str(random_init_wts)+'_' +current_date+'.log'\n",
    "    print(f\"*****LOGGING INFO IN {log_file}*********\")\n",
    "    filepath = os.path.join(\"model\",log_file)\n",
    "    logging.basicConfig(filename=filepath, \n",
    "                    filemode='a',  # Overwrite the log file each time\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    level=logging.DEBUG)\n",
    "    logger = logging.getLogger()\n",
    "    logger.info(log_message)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "49218b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_train_metrics:\n",
    "    def __init__(self, patience=10, min_delta=0 , B = T, T = T,best_loss = torch.inf,early_stop = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = best_loss\n",
    "        self.early_stop = early_stop\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.improvement = None\n",
    "\n",
    "    def __call__(self, loss, epoch , epoch_durn, norm , current_lr, num_token):\n",
    "        if self.best_loss - loss > self.min_delta:\n",
    "            \n",
    "            print(f\"training loss has decreased---> reducing the best loss from {self.best_loss:.2f} to {loss:.2f} | throughput = {int(num_token/epoch_durn)} tokens/second | norm = {norm:.4f} | learning rate = {current_lr:.5e}\")\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            self.improvement = True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.improvement = False\n",
    "            print(f\"No improvement in training  loss-->epoch= {epoch} and best loss is {self.best_loss:.2f}|current_loss = {loss}|counter = {self.counter}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b26d4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_val_metrics:\n",
    "    def __init__(self, patience=5, min_delta=0, best_loss = torch.inf,early_stop = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = best_loss\n",
    "        self.early_stop = early_stop\n",
    "        \n",
    "\n",
    "    def __call__(self, loss, epoch , model, tokenizer):\n",
    "        if self.best_loss - loss > self.min_delta:\n",
    "            print(f\"Val loss has decreased -->reducing the global validation loss from {self.best_loss:.2f} to {loss:.2f}\")\n",
    "            s1 = (f\"Val loss has decreased -->reducing the global validation loss from {self.best_loss:.2f} to {loss:.2f}\")\n",
    "            print(f\" validation loss for epoch = {epoch} is {loss:.4f}\")\n",
    "            self.best_loss = loss\n",
    "            s2 = f\" validation loss for epoch = {epoch} is {loss:.4f}\"\n",
    "            print(f\" epoch= {epoch} :  val loss is {loss:.4f} \")\n",
    "            s3 = f\" epoch= {epoch} :  val loss is {loss:.4f} \"\n",
    "            #save the model\n",
    "            # Get the current date and time\n",
    "            current_datetime = datetime.datetime.now()\n",
    "            # Extract date and time components\n",
    "            current_date = str(current_datetime.date())\n",
    "            current_time = str(current_datetime.time()).split('.')[0]\n",
    "            file_name = 'model'+ current_date+current_time+'.pth'\n",
    "            path = os.path.join(\"model\",file_name)\n",
    "            print(f\"saving the model {file_name}\")\n",
    "            s4 = f\"saving the model {file_name}\"\n",
    "            #torch.save(model.state_dict(), path)\n",
    "            model.save_pretrained(path)\n",
    "            tokenizer.save_pretrained(path)\n",
    "            log_message = s1+s2+s3+s4\n",
    "            write_file(log_message)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"No improvement in validation loss-->epoch= {epoch} and best val loss is {self.best_loss:.2f}|current_Val loss = {loss}|counter = {self.counter}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a40b10e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "\n",
    "def eval_model(val_loader, model, epoch , device = device,tokenizer = tokenizer):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    e = epoch+1\n",
    "    embedding_layer = model.transformer.wte\n",
    "    val_loss_accum = 0.0\n",
    "    print(f\"inside validation data for epoch {e}\")\n",
    "    for ind,(input_id,attention_mask) in enumerate(val_loader):\n",
    "        ids = input_id.to(device=device, non_blocking=True)\n",
    "        att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "        labels = ids.clone()\n",
    "        \n",
    "        with autocast(dtype = torch.bfloat16):\n",
    "            model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "            total_loss = model_output.loss\n",
    "        \n",
    "        val_loss_accum+=total_loss.detach().item()\n",
    "        del ids,att_mask,labels,model_output\n",
    "    return val_loss_accum\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fce249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_loader,val_loader,model,num_epoch = 30,device = device,tokenizer = tokenizer):\n",
    "    model.train()\n",
    "    device = device\n",
    "    lr_custom = 3e-5\n",
    "    print(f\"inside train model. Device = {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(params =  model.parameters(), lr= lr_custom,fused = True ,weight_decay = .1)\n",
    "    total_batch_size = 2**19\n",
    "    grad_accum_step = total_batch_size//(B*T)\n",
    "    \n",
    "    extra_train = .1*num_epoch\n",
    "    max_train_steps = int(num_epoch +extra_train )\n",
    "    import time\n",
    "    from transformers import get_linear_schedule_with_warmup\n",
    "    total_steps = len(train_loader) * num_epoch\n",
    "    scheduler_cos = transformers.get_cosine_schedule_with_warmup( optimizer= optimizer, num_warmup_steps =int(total_steps * 0.1) ,num_training_steps= total_steps )\n",
    "        \n",
    "    epoch_train_log = []\n",
    "    epoch_val_log = []\n",
    "    validate_val_metric = check_val_metrics()\n",
    "    validate_train_metric = check_train_metrics(patience=5, min_delta=0 , B = T, T = T)\n",
    "    for i in range (max_train_steps):\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # we use 2 schedulers - the first LR scheduler uses a cosine decay for 100 epochs the second scheduler takes the last LR from cosine scheduler and then maintains that LR for the next 10 epochs\n",
    "        if i >= num_epoch:\n",
    "            optimizer_reduced_lr = torch.optim.AdamW(params =  model.parameters(), lr= current_lr ,fused = True , weight_decay=.1)\n",
    "            scheduler_constant = transformers.get_constant_schedule_with_warmup( optimizer = optimizer_reduced_lr ,num_warmup_steps = 0, last_epoch = -1 )\n",
    "        \n",
    "        epoch_train_loss = 0       \n",
    "        for ind,(input_id,attention_mask) in enumerate(train_loader):\n",
    "            if ind == int(len(train_loader)/2):\n",
    "                batch_time = time.time()\n",
    "                duration = batch_time - epoch_start_time\n",
    "                print(f\"executing epoch:{i+1}, it took {duration/60} mins from beginning of epoch till batch#{ind}\")\n",
    "            \n",
    "            ids = input_id.to(device=device, non_blocking=True)\n",
    "            att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "            labels = ids.clone()\n",
    "            assert not torch.isnan(ids).any(), \"Input contains NaN values\"\n",
    "            assert not torch.isinf(ids).any(), \"Input contains infinite values\"\n",
    "            \n",
    "            with autocast(dtype = torch.bfloat16):\n",
    "                model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "                if np.isnan(model_output.loss.item()):\n",
    "                    print(\"f nan values encountered..\")\n",
    "                    decoded_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in ids]\n",
    "                    print(f\"*********$$$$$$$$$ decoded_texts = {decoded_texts}*************\")\n",
    "                total_loss =model_output.loss \n",
    "                                \n",
    "            assert not np.isnan(model_output.loss.item()), \"NaN value found\"\n",
    "                       \n",
    "                     \n",
    "            total_loss.backward()\n",
    "            epoch_train_loss += total_loss.detach().item()\n",
    "            norm = torch.nn.utils.clip_grad_norm(model.parameters() , 1.0)\n",
    "            if i <= num_epoch:\n",
    "                optimizer.step()\n",
    "                scheduler_cos.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            else:\n",
    "                optimizer_reduced_lr.step()\n",
    "                optimizer_reduced_lr.zero_grad(set_to_none=True)\n",
    "                scheduler_constant.step()\n",
    "                \n",
    "                         \n",
    "            del ids,att_mask,labels,model_output\n",
    "            \n",
    "        #batch processing complete \n",
    "        #print(f\"batch processing complete , lambda = {lambda_val} |total_loss for batch= {total_loss}\")\n",
    "        \n",
    "        if i <= num_epoch:\n",
    "            current_lr = scheduler_cos.get_last_lr()[0]\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_durn = (epoch_end_time - epoch_start_time)\n",
    "        num_token = B*T*len(train_loader)\n",
    "        epoch_train_log.append(epoch_train_loss)\n",
    "        validate_train_metric(epoch_train_loss, i , epoch_durn, norm , current_lr, num_token)\n",
    "        \n",
    "        if validate_train_metric.improvement:\n",
    "            val_loss= eval_model(val_loader, model, epoch = i, device = device,tokenizer = tokenizer)\n",
    "            epoch_val_log.append(val_loss)\n",
    "            validate_val_metric(val_loss, i , model, tokenizer)\n",
    "            if validate_train_metric.early_stop :\n",
    "                print(f\"early stopping trigerred from training data\")\n",
    "                break\n",
    "        else:\n",
    "            if validate_val_metric.early_stop:\n",
    "                print(f\"early stopping trigerred from validation data\")\n",
    "                break\n",
    "              \n",
    "    \n",
    "    return model,epoch_train_log,epoch_val_log\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7e99e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train model. Device = cuda:0\n",
      "executing epoch:1, it took 2.851871407032013 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from inf to 1530.71 | throughput = 49755 tokens/second | norm = 2.8830 | learning rate = 1.00000e-05\n",
      "inside validation data for epoch 1\n",
      "Val loss has decreased -->reducing the global validation loss from inf to 1422.32\n",
      " validation loss for epoch = 0 is 1422.3232\n",
      " epoch= 0 :  val loss is 1422.3232 \n",
      "saving the model model2024-07-1722:04:16.pth\n",
      "[2024-07-17 22:04:16,718] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/compiler_compat/ld: cannot find -laio\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m [WARNING] \u001b[0m async_io requires the dev libaio .so object and headers but these were not found.\n",
      "\u001b[93m [WARNING] \u001b[0m async_io: please install the libaio-dev package with apt\n",
      "\u001b[93m [WARNING] \u001b[0m If libaio is already installed (perhaps from source), try setting the CFLAGS and LDFLAGS environment variables to where it can be found.\n",
      "\u001b[93m [WARNING] \u001b[0m Please specify the CUTLASS repo directory as environment variable $CUTLASS_PATH\n",
      "\u001b[93m [WARNING] \u001b[0m sparse_attn requires a torch version >= 1.5 and < 2.0 but detected 2.3\n",
      "\u001b[93m [WARNING] \u001b[0m using untested triton version (2.3.1), only 1.0.0 is known to be compatible\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:2, it took 2.8514960050582885 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1530.71 to 1312.04 | throughput = 51914 tokens/second | norm = 1.6521 | learning rate = 2.00000e-05\n",
      "inside validation data for epoch 2\n",
      "Val loss has decreased -->reducing the global validation loss from 1422.32 to 1371.64\n",
      " validation loss for epoch = 1 is 1371.6434\n",
      " epoch= 1 :  val loss is 1371.6434 \n",
      "saving the model model2024-07-1722:11:27.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:3, it took 2.020982090632121 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1312.04 to 1281.09 | throughput = 70745 tokens/second | norm = 3.7766 | learning rate = 3.00000e-05\n",
      "inside validation data for epoch 3\n",
      "Val loss has decreased -->reducing the global validation loss from 1371.64 to 1361.24\n",
      " validation loss for epoch = 2 is 1361.2447\n",
      " epoch= 2 :  val loss is 1361.2447 \n",
      "saving the model model2024-07-1722:17:06.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:4, it took 2.021634403864543 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1281.09 to 1257.29 | throughput = 70728 tokens/second | norm = 1.5866 | learning rate = 2.98986e-05\n",
      "inside validation data for epoch 4\n",
      "Val loss has decreased -->reducing the global validation loss from 1361.24 to 1350.18\n",
      " validation loss for epoch = 3 is 1350.1763\n",
      " epoch= 3 :  val loss is 1350.1763 \n",
      "saving the model model2024-07-1722:22:45.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:5, it took 2.0230449040730796 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1257.29 to 1236.06 | throughput = 70718 tokens/second | norm = 1.9813 | learning rate = 2.95957e-05\n",
      "inside validation data for epoch 5\n",
      "Val loss has decreased -->reducing the global validation loss from 1350.18 to 1343.11\n",
      " validation loss for epoch = 4 is 1343.1068\n",
      " epoch= 4 :  val loss is 1343.1068 \n",
      "saving the model model2024-07-1722:28:24.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:6, it took 2.0228215138117474 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1236.06 to 1219.05 | throughput = 70729 tokens/second | norm = 1.9901 | learning rate = 2.90954e-05\n",
      "inside validation data for epoch 6\n",
      "Val loss has decreased -->reducing the global validation loss from 1343.11 to 1340.32\n",
      " validation loss for epoch = 5 is 1340.3195\n",
      " epoch= 5 :  val loss is 1340.3195 \n",
      "saving the model model2024-07-1722:34:02.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:7, it took 2.0181419491767882 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1219.05 to 1205.05 | throughput = 70842 tokens/second | norm = 4.1276 | learning rate = 2.84045e-05\n",
      "inside validation data for epoch 7\n",
      "Val loss has decreased -->reducing the global validation loss from 1340.32 to 1338.47\n",
      " validation loss for epoch = 6 is 1338.4738\n",
      " epoch= 6 :  val loss is 1338.4738 \n",
      "saving the model model2024-07-1722:39:41.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:8, it took 2.02330687046051 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1205.05 to 1191.68 | throughput = 70712 tokens/second | norm = 1.0357 | learning rate = 2.75323e-05\n",
      "inside validation data for epoch 8\n",
      "No improvement in validation loss-->epoch= 7 and best val loss is 1338.47|current_Val loss = 1338.8610612154007|counter = 1\n",
      "executing epoch:9, it took 2.0249671657880146 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1191.68 to 1179.94 | throughput = 70666 tokens/second | norm = 1.0838 | learning rate = 2.64907e-05\n",
      "inside validation data for epoch 9\n",
      "Val loss has decreased -->reducing the global validation loss from 1338.47 to 1338.17\n",
      " validation loss for epoch = 8 is 1338.1658\n",
      " epoch= 8 :  val loss is 1338.1658 \n",
      "saving the model model2024-07-1722:50:57.pth\n",
      "*****LOGGING INFO IN gpt2_COS_SIM*lambda_random_init_wts_False_2024-07-17.log*********\n",
      "executing epoch:10, it took 2.0231231649716697 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1179.94 to 1169.21 | throughput = 70680 tokens/second | norm = 1.3367 | learning rate = 2.52936e-05\n",
      "inside validation data for epoch 10\n",
      "No improvement in validation loss-->epoch= 9 and best val loss is 1338.17|current_Val loss = 1339.7810286283493|counter = 1\n",
      "executing epoch:11, it took 2.0239137172698975 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1169.21 to 1158.39 | throughput = 70722 tokens/second | norm = 1.4361 | learning rate = 2.39574e-05\n",
      "inside validation data for epoch 11\n",
      "No improvement in validation loss-->epoch= 10 and best val loss is 1338.17|current_Val loss = 1340.035896897316|counter = 2\n",
      "executing epoch:12, it took 2.022251907984416 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1158.39 to 1148.50 | throughput = 70703 tokens/second | norm = 0.6957 | learning rate = 2.25000e-05\n",
      "inside validation data for epoch 12\n",
      "No improvement in validation loss-->epoch= 11 and best val loss is 1338.17|current_Val loss = 1341.7571561336517|counter = 3\n",
      "executing epoch:13, it took 2.019650761286418 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1148.50 to 1138.79 | throughput = 70914 tokens/second | norm = 1.1779 | learning rate = 2.09412e-05\n",
      "inside validation data for epoch 13\n",
      "No improvement in validation loss-->epoch= 12 and best val loss is 1338.17|current_Val loss = 1344.4605746269226|counter = 4\n",
      "executing epoch:14, it took 2.01213827530543 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1138.79 to 1129.64 | throughput = 71070 tokens/second | norm = 1.3570 | learning rate = 1.93020e-05\n",
      "inside validation data for epoch 14\n",
      "No improvement in validation loss-->epoch= 13 and best val loss is 1338.17|current_Val loss = 1348.3375535011292|counter = 5\n",
      "executing epoch:15, it took 2.020048439502716 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1129.64 to 1121.15 | throughput = 70846 tokens/second | norm = 0.9506 | learning rate = 1.76047e-05\n",
      "inside validation data for epoch 15\n",
      "No improvement in validation loss-->epoch= 14 and best val loss is 1338.17|current_Val loss = 1351.3136920332909|counter = 6\n",
      "executing epoch:16, it took 2.023617406686147 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1121.15 to 1113.25 | throughput = 70531 tokens/second | norm = 0.6841 | learning rate = 1.58722e-05\n",
      "inside validation data for epoch 16\n",
      "No improvement in validation loss-->epoch= 15 and best val loss is 1338.17|current_Val loss = 1356.5987824201584|counter = 7\n",
      "executing epoch:17, it took 2.026169812679291 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1113.25 to 1105.83 | throughput = 70643 tokens/second | norm = 0.8904 | learning rate = 1.41278e-05\n",
      "inside validation data for epoch 17\n",
      "No improvement in validation loss-->epoch= 16 and best val loss is 1338.17|current_Val loss = 1361.6746320724487|counter = 8\n",
      "executing epoch:18, it took 2.025815689563751 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1105.83 to 1099.01 | throughput = 65327 tokens/second | norm = 1.0010 | learning rate = 1.23953e-05\n",
      "inside validation data for epoch 18\n",
      "No improvement in validation loss-->epoch= 17 and best val loss is 1338.17|current_Val loss = 1363.7606009840965|counter = 9\n",
      "executing epoch:19, it took 2.827063675721486 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1099.01 to 1092.80 | throughput = 50621 tokens/second | norm = 1.5660 | learning rate = 1.06980e-05\n",
      "inside validation data for epoch 19\n",
      "No improvement in validation loss-->epoch= 18 and best val loss is 1338.17|current_Val loss = 1368.0285052657127|counter = 10\n",
      "executing epoch:20, it took 2.8037840604782103 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1092.80 to 1087.12 | throughput = 50731 tokens/second | norm = 0.7487 | learning rate = 9.05880e-06\n",
      "inside validation data for epoch 20\n",
      "No improvement in validation loss-->epoch= 19 and best val loss is 1338.17|current_Val loss = 1370.648227572441|counter = 11\n",
      "executing epoch:21, it took 2.8326228817303973 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1087.12 to 1082.02 | throughput = 50281 tokens/second | norm = 0.8863 | learning rate = 7.50000e-06\n",
      "inside validation data for epoch 21\n",
      "No improvement in validation loss-->epoch= 20 and best val loss is 1338.17|current_Val loss = 1373.9992879629135|counter = 12\n",
      "executing epoch:22, it took 2.0194207588831583 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1082.02 to 1077.61 | throughput = 70839 tokens/second | norm = 1.0621 | learning rate = 6.04262e-06\n",
      "inside validation data for epoch 22\n",
      "No improvement in validation loss-->epoch= 21 and best val loss is 1338.17|current_Val loss = 1375.8113803863525|counter = 13\n",
      "executing epoch:23, it took 2.0190893093744915 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1077.61 to 1073.95 | throughput = 70844 tokens/second | norm = 1.1904 | learning rate = 4.70638e-06\n",
      "inside validation data for epoch 23\n",
      "No improvement in validation loss-->epoch= 22 and best val loss is 1338.17|current_Val loss = 1379.739920437336|counter = 14\n",
      "executing epoch:24, it took 2.0141395926475525 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1073.95 to 1070.94 | throughput = 71018 tokens/second | norm = 1.1345 | learning rate = 3.50933e-06\n",
      "inside validation data for epoch 24\n",
      "No improvement in validation loss-->epoch= 23 and best val loss is 1338.17|current_Val loss = 1383.1716866493225|counter = 15\n",
      "executing epoch:25, it took 2.015276789665222 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1070.94 to 1068.59 | throughput = 70989 tokens/second | norm = 1.0613 | learning rate = 2.46768e-06\n",
      "inside validation data for epoch 25\n",
      "No improvement in validation loss-->epoch= 24 and best val loss is 1338.17|current_Val loss = 1382.7863242030144|counter = 16\n",
      "executing epoch:26, it took 2.0163093328475954 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1068.59 to 1066.78 | throughput = 71026 tokens/second | norm = 0.7988 | learning rate = 1.59551e-06\n",
      "inside validation data for epoch 26\n",
      "No improvement in validation loss-->epoch= 25 and best val loss is 1338.17|current_Val loss = 1384.2706910967827|counter = 17\n",
      "executing epoch:27, it took 2.0127458254496258 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1066.78 to 1065.50 | throughput = 71072 tokens/second | norm = 0.8593 | learning rate = 9.04611e-07\n",
      "inside validation data for epoch 27\n",
      "No improvement in validation loss-->epoch= 26 and best val loss is 1338.17|current_Val loss = 1385.451142013073|counter = 18\n",
      "executing epoch:28, it took 2.010279107093811 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1065.50 to 1064.64 | throughput = 71141 tokens/second | norm = 0.7155 | learning rate = 4.04327e-07\n",
      "inside validation data for epoch 28\n",
      "No improvement in validation loss-->epoch= 27 and best val loss is 1338.17|current_Val loss = 1385.8749395012856|counter = 19\n",
      "executing epoch:29, it took 2.012602424621582 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1064.64 to 1064.16 | throughput = 71132 tokens/second | norm = 0.7187 | learning rate = 1.01425e-07\n",
      "inside validation data for epoch 29\n",
      "No improvement in validation loss-->epoch= 28 and best val loss is 1338.17|current_Val loss = 1386.2270267009735|counter = 20\n",
      "executing epoch:30, it took 2.011185797055562 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1064.16 to 1063.91 | throughput = 71160 tokens/second | norm = 0.7963 | learning rate = 0.00000e+00\n",
      "inside validation data for epoch 30\n",
      "No improvement in validation loss-->epoch= 29 and best val loss is 1338.17|current_Val loss = 1386.2948011755943|counter = 21\n",
      "executing epoch:31, it took 2.013105789820353 mins from beginning of epoch till batch#262\n",
      "training loss has decreased---> reducing the best loss from 1063.91 to 1063.86 | throughput = 71102 tokens/second | norm = 1.1504 | learning rate = 1.01425e-07\n",
      "inside validation data for epoch 31\n",
      "No improvement in validation loss-->epoch= 30 and best val loss is 1338.17|current_Val loss = 1386.488322377205|counter = 22\n",
      "executing epoch:32, it took 2.0152631878852842 mins from beginning of epoch till batch#262\n",
      "No improvement in training  loss-->epoch= 31 and best loss is 1063.86|current_loss = 1063.9281514286995|counter = 1\n",
      "early stopping trigerred from validation data\n"
     ]
    }
   ],
   "source": [
    "tr_model,epoch_train_log,epoch_val_log = train_model(train_loader, val_loader, model =  model,tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e993b3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json , os\n",
    "path_var_train_log = os.path.join(\".\",\"Tokenizers_and_loss_vals\",\"epoch_train_plain_loss.json\")\n",
    "path_var_val_log = os.path.join(\".\",\"Tokenizers_and_loss_vals\",\"epoch_val_val_loss_.json\")\n",
    "\n",
    "#print(path_var)\n",
    "#Write the list to a JSON file\n",
    "with open(path_var_train_log, \"w\") as file:\n",
    "    json.dump(epoch_train_log, file)\n",
    "\n",
    "with open(path_var_val_log, \"w\") as file:\n",
    "    json.dump(epoch_val_log, file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "666467ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_var_train_log, \"r\") as file:\n",
    "    train_loss = json.load(file)\n",
    "with open(path_var_val_log, \"r\") as file:\n",
    "    val_loss = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5afedad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "31\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loss))\n",
    "print(len(val_loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6de4a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa695efb0d0>]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_values = range(len(train_loss))\n",
    "plt.plot(x_values, train_loss, label='Train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "502523cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa695dbcfd0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_values_val = range(len(val_loss))\n",
    "plt.plot(x_values_val, val_loss, label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6f17d41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa695d8efa0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_length = min(len(train_loss), len(val_loss))\n",
    "list1 = train_loss[:min_length]\n",
    "list2 = val_loss[:min_length]\n",
    "\n",
    "# Create x-axis values\n",
    "x_values = range(min_length)\n",
    "\n",
    "# Plot the lists\n",
    "plt.plot(x_values, list1, label='Train_loss')\n",
    "plt.plot(x_values, list2, label='Val_loss')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Train Loss and Val_Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484a0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab68645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faba819",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d83321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a08140f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
