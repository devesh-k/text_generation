{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "161a02d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reference https://huggingface.co/learn/nlp-course/en/chapter7/6?fw=pt#training-a-causal-language-model-from-scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de19c469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a9aa7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: jupyter in /opt/conda/lib/python3.8/site-packages (1.0.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (8.1.3)\n",
      "Requirement already satisfied: jupyter-console in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.6.3)\n",
      "Requirement already satisfied: qtconsole in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.2)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.29.5)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.4.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.30.0)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.0.11)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.11 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.0.11)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (59.4.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.47)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.3)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (21.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.8.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (7.1.0)\n",
      "Requirement already satisfied: pyzmq>=24 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (26.0.3)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.4)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.7.2)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (5.8.0)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter) (4.2.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel->jupyter) (1.16.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: jinja2>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.9)\n",
      "Requirement already satisfied: nbformat>=4.4 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (5.1.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.4->nbconvert->jupyter) (2.0.1)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.4->nbconvert->jupyter) (4.2.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (21.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (0.18.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /opt/conda/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema!=2.5.0,>=2.4->nbformat>=4.4->nbconvert->jupyter) (3.6.0)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.0)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (0.12.1)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook->jupyter) (21.1.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook->jupyter) (2.21)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (3.0.6)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in /opt/conda/lib/python3.8/site-packages (from qtconsole->jupyter) (2.4.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#installing some libraries\n",
    "#!pip install datasets\n",
    "!pip install --upgrade jupyter ipywidgets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacf4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch, transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "from transformers import AutoModel, AutoConfig,AutoModelForCausalLM, AutoConfig,GPT2Config,GPT2Tokenizer\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "#from datasets import load_dataset\n",
    "import pandas as pd, numpy as np\n",
    "from torch.cuda.amp import autocast\n",
    "from torch import cuda\n",
    "import datetime\n",
    "import warnings,itertools\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "import json\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pip install transformers bitsandbytes>=0.39.0 -q\n",
    "import zipfile,logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e93b4473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "import random\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea91d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95f1f089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "model\n"
     ]
    }
   ],
   "source": [
    "#global params for training\n",
    "\n",
    "B,T = 64,1024\n",
    "epoch = 100\n",
    "random_init_wts = True\n",
    "min_text_len = 0\n",
    "# hard coded com\n",
    "comp_ratio = 3\n",
    "# train_loss_list = []\n",
    "# val_loss_list =[]\n",
    "if cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print(device)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "#print(device)\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "#os.environ[\"MKL_DEBUG_CPU_TYPE\"] = \"5\"\n",
    "\n",
    "#print(global_tr_loss)\n",
    "model_path = os.path.join(\"model\")\n",
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192ed03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/unzip_text_10M'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory = os.path.join('.','data','unzip_text_10M')  # Replace with your directory path\n",
    "directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1878baca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text(directory):\n",
    "    directory = os.path.join('.','data','unzip_text_10M',str(directory))  # Replace with your directory path\n",
    "    print(f\"directory :{directory}\")\n",
    "    # List all files in the directory\n",
    "    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n",
    "    print(f\"files:{files}\")\n",
    "    text_content = []\n",
    "    # Read each file\n",
    "    total_lines = 0\n",
    "    for filenum,filename in enumerate(files):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            #first_line = file.read()\n",
    "            #print(f\"filename :{filename}->first few lines {first_line}\")\n",
    "            #continue\n",
    "            #lines_list = [line.strip() for line in open(file_path, 'r')]\n",
    "            text = file.read()\n",
    "            text_content.append(text)\n",
    "            print(f\"the file:{filename} has been appeneded to the uber list and its length is {len(text_content)} \")\n",
    "            #total_lines+=len(lines_list)\n",
    "            #text_content.append(lines_list)\n",
    "    \n",
    "    flattened_list = ''.join(text_content)\n",
    "    assert (len(flattened_list) == total_lines , f\"Expected {len(flattened_list)} to be equal to {total_lines}\" )\n",
    "    \n",
    "    return flattened_list\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4d78ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/train_10M\n",
      "files:['switchboard.train', 'simple_wiki.train', 'open_subtitles.train', 'gutenberg.train', 'childes.train', 'bnc_spoken.train']\n",
      "the file:switchboard.train has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.train has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.train has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.train has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.train has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.train has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "train_list = read_text(\"train_10M\")\n",
    "#print(train_dict)\n",
    "#val_list = read_text(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c7583c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54215049"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f4f2406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "827\n"
     ]
    }
   ],
   "source": [
    "chunks = len(train_list)//(B*T)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d9aa77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"distilgpt2\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5f4100f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50257\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ad6c6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory :./data/unzip_text_10M/dev\n",
      "files:['switchboard.dev', 'simple_wiki.dev', 'open_subtitles.dev', 'gutenberg.dev', 'childes.dev', 'bnc_spoken.dev']\n",
      "the file:switchboard.dev has been appeneded to the uber list and its length is 1 \n",
      "the file:simple_wiki.dev has been appeneded to the uber list and its length is 2 \n",
      "the file:open_subtitles.dev has been appeneded to the uber list and its length is 3 \n",
      "the file:gutenberg.dev has been appeneded to the uber list and its length is 4 \n",
      "the file:childes.dev has been appeneded to the uber list and its length is 5 \n",
      "the file:bnc_spoken.dev has been appeneded to the uber list and its length is 6 \n"
     ]
    }
   ],
   "source": [
    "val_list = read_text(\"dev\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea82c69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50256\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6303cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028846996600952357"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e287aa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ec89ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ranked_synonyms(word, pos):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word, pos=pos):\n",
    "        for lemma in syn.lemmas():\n",
    "            if lemma.name() != word:\n",
    "                synonyms.append((lemma.name(), syn.wup_similarity(syn)))\n",
    "    \n",
    "    # Sort synonyms by similarity score in descending order\n",
    "    ranked_synonyms = sorted(set(synonyms), key=lambda x: x[1] if x[1] is not None else 0, reverse=True)\n",
    "    return [syn for syn, _ in ranked_synonyms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "724d90ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def replace_verbs_with_synonyms(text):\n",
    "    words = word_tokenize(text)\n",
    "    tagged = pos_tag(words)\n",
    "    result = []\n",
    "    for word, pos in tagged:\n",
    "        if pos =='VB':\n",
    "            wordnet_pos = get_wordnet_pos(pos)\n",
    "            lemma = lemmatizer.lemmatize(word, wordnet_pos)\n",
    "            synonyms = get_ranked_synonyms(lemma, wordnet_pos)\n",
    "            if synonyms:\n",
    "                replacement = random.choice(synonyms)  # Choose from top 3 synonyms\n",
    "                #print(f\"word = {word}|replacement = {replacement}\")\n",
    "                result.append(replacement)\n",
    "            else:\n",
    "                result.append(word)\n",
    "        else:\n",
    "            result.append(word)\n",
    "    return \" \".join(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad3c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = train_list[584:1000]\n",
    "repl = replace_verbs_with_synonyms(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3890e5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like Thumper that , boy , I could just live out and mother all kinds of game B : Did it puzzle_out ? A : Yeah , A : except we live in Plano , Texas now B : No , B : right . A : so B : I , um , I had a , for many years I had a dog that was part Springer Spaniel . B : I just jazz them . B : Her name was Molly , B : but she is n't alive any more B : We had her for , um , fifteen years , I think , my family did , and just loved her . B : She was the greatest ,\n"
     ]
    }
   ],
   "source": [
    "print(repl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86517794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "like Thumper that, boy, I could just go out and get all kinds of game\n",
      "B:\tDid it work?\n",
      "A:\tYeah,\n",
      "A:\texcept we live in Plano, Texas now\n",
      "B:\tNo,\n",
      "B:\tright.\n",
      "A:\tso\n",
      "B:\tI, um, I had a, for many years I had a dog that was part Springer Spaniel.\n",
      "B:\tI just love them.\n",
      "B:\tHer name was Molly,\n",
      "B:\tbut she isn't alive any more\n",
      "B:\tWe had her for, um, fifteen years, I think, my family did, and just loved her.\n",
      "B:\tShe was the greatest,\n"
     ]
    }
   ],
   "source": [
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff00fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dac7595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d18ae105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(token_ids_list, max_length = B*T, tokenizer = tokenizer):\n",
    "    padded_sequences = tokenizer.pad(\n",
    "        {\"input_ids\": token_ids_list},\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9258134b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text (text,tokenizer = tokenizer,max_length = B*T):\n",
    "    #print(f\"inside tokenize_text\")\n",
    "    enc = tokenizer(text,padding='max_length',truncation=True,max_length=max_length,return_tensors=\"pt\",return_attention_mask=True)\n",
    "    input_id = enc['input_ids']\n",
    "    att_mask = enc['attention_mask']\n",
    "    \n",
    "    # now concatenate these lists to B*T\n",
    "    input_id = torch.squeeze(input_id, dim = 0).to(dtype = torch.long)\n",
    "    att_mask = torch.squeeze(att_mask, dim = 0).to(dtype = torch.bool)\n",
    "#     if len(input_id_list) < B*T:\n",
    "#         print(f\"len of input_id_list = {len(input_id_list)}\")\n",
    "#         #pad_len = B*T - len(input_id_list)\n",
    "#         #print(f\"len of input_id = {len(input_id_list)}|concatenating with {pad_len}\")\n",
    "# #         enc_padded = pad_sequences(input_id_list)\n",
    "# #         #input_id_temp = (enc_padded['input_ids']).to(dtype =torch.long)\n",
    "# #         att_mask_padded = enc_padded['attention_mask']\n",
    "# #         input_it_padded = enc_padded['input_ids']\n",
    "        \n",
    "# #         att_mask_temp = torch.tensor(att_mask_padded,dtype = torch.bool)\n",
    "# #         input_id_temp = torch.tensor(input_it_padded,dtype = torch.long)\n",
    "        \n",
    "            \n",
    "#     else:\n",
    "#         #print(\"truncating...\")\n",
    "#         input_id_list = input_id_list[:B*T]\n",
    "#         att_mask_list = att_mask_list[:B*T]\n",
    "#     input_id_temp = torch.tensor(input_id_list,dtype = torch.long)\n",
    "#     att_mask_temp = torch.tensor(att_mask_list,dtype = torch.bool)\n",
    "\n",
    "    #print(f\"input id shape post tensor = {input_id_temp.shape}\")\n",
    "    #print(f\"attention shape post tensor = {att_mask_temp.shape}\")\n",
    "    return input_id,att_mask\n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f26d61a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([65536])\n"
     ]
    }
   ],
   "source": [
    "inp,att = tokenize_text(repl)\n",
    "#a = inp['input_ids']\n",
    "print(inp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8be287a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Test the tokenizer:\n",
    "model_name = 'distilgpt2'\n",
    "if random_init_wts:\n",
    "    config = AutoConfig.from_pretrained(model_name, vocab_size = 50304)\n",
    "    # Initialize the model with random weights\n",
    "    model = AutoModelForCausalLM.from_config(config)\n",
    "else:\n",
    "    #model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "    \n",
    "#model = torch.compile(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3437d772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_text = train_list[584:1000]\n",
    "\n",
    "# sample_text[:50]\n",
    "# enc_samp = tokenizer(sample_text)\n",
    "# input_id_samp = torch.tensor(enc_samp['input_ids']).to(device)\n",
    "# att = torch.tensor(enc_samp['attention_mask']).to(device)\n",
    "# label = input_id_samp.clone()\n",
    "# label = label.to(device)\n",
    "# model.to(device)\n",
    "\n",
    "# out_samp = model(input_ids = input_id_samp, attention_mask = att, labels = label )\n",
    "# print(out_samp.loss)\n",
    "# del input_id_samp,att,label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d73f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaced_text = replace_verbs_with_synonyms(sample_text)\n",
    "# enc_replaced = tokenizer(replaced_text)\n",
    "# enc_replaced\n",
    "# input_id_repl = torch.tensor(enc_replaced['input_ids']).to(device)\n",
    "# att_repl = torch.tensor(enc_replaced['attention_mask']).to(device)\n",
    "# label = input_id_repl.clone()\n",
    "# label = label.to(device)\n",
    "# model.to(device)\n",
    "\n",
    "# out_samp = model(input_ids = input_id_repl, attention_mask = att_repl, labels = label )\n",
    "# print(out_samp.loss)\n",
    "# del input_id_repl,att_repl,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87b8dbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb3c0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #now add padding and run thru the model\n",
    "# model.to(device)\n",
    "# inp_orig, att_orig = tokenize_text(sample_text)\n",
    "# inp_v = inp_orig.view(B,T).to(device)\n",
    "# att_v = att_orig.view(B,T).to(device)\n",
    "# print(f\"shapes| inp_v= {inp_v.shape}| att_v = {att_v.shape}\")\n",
    "# out_orig = model(input_ids = inp_v, attention_mask = att_v, labels = inp_v)\n",
    "# print(out_orig.loss)\n",
    "\n",
    "# del inp_v,att_v,out_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b08113d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now add padding and run thru the model\n",
    "# model.to(device)\n",
    "# inp_orig_r, att_orig_r = tokenize_text(replaced_text)\n",
    "# inp_v_r = inp_orig_r.view(B,T).to(device)\n",
    "# att_v_r = att_orig_r.view(B,T).to(device)\n",
    "# print(f\"shapes| inp_v= {inp_v_r.shape}| att_v = {att_v_r.shape}\")\n",
    "# out_orig_r = model(input_ids = inp_v_r, attention_mask = att_v_r, labels = inp_v_r)\n",
    "# print(out_orig_r.loss)\n",
    "\n",
    "# del inp_v_r,att_v_r,out_orig_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aef8daee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(64,1024).\n",
    "# att = torch.ones(64,1024)\n",
    "# mo = model(input_ids = x, attention_mask = att, labels = x )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5889ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b538184b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print((replaced_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba3533e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 577466\n",
    "# chunk = get_chunk(train_list, i = i)\n",
    "\n",
    "# print(train_list[i:i + 200])\n",
    "# print(chunk)\n",
    "# print(len(chunk))\n",
    "# print(len(train_list[258:258 + 200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f5d3005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_chunk(text_list, i ,tokenizer = tokenizer,prob = .30 ):\n",
    "#     #get an index i\n",
    "#     #words_list[start_index:start_index + n]\n",
    "#     chunk = text_list[i:i + 200]\n",
    "    \n",
    "#     random_num = random.random()\n",
    "#     if random_num > prob:\n",
    "#         chunk = replace_verbs_with_synonyms(chunk)\n",
    "#     #now tokenize\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "914c966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t = pad_sequences(enc_replaced['input_ids'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df9e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd602ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged  =[('uch', 'JJ'), ('.', '.'), ('B', 'NN'), (':', ':'), ('Uh-huh', 'JJ'), ('.', '.'), ('A', 'DT'), (':', ':'), ('Bye-bye', 'NN'), ('.', '.'), ('B', 'NN'), (':', ':'), ('Bye', 'NNP'), ('.', '.'), ('B', 'NN'), (':', ':'), ('Do', 'VBP'), ('you', 'PRP'), ('have', 'VB'), ('any', 'DT'), ('?', '.'), ('A', 'DT'), (':', ':'), ('Sure', 'NN'), ('.', '.'), ('A', 'DT'), (':', ':'), ('I', 'PRP'), ('have', 'VBP'), ('a', 'DT'), ('Springer', 'NNP'), ('Spaniel', 'NNP'), (',', ','), ('A', 'NNP'), (':', ':'), ('and', 'CC'), ('her', 'PRP$'), ('name', 'NN'), ('is', 'VBZ'), ('Thumper', 'NNP'), ('.', '.'), ('A', 'NN'), (':', ':'), ('She', 'PRP'), (\"'s\", 'VBZ'), ('about', 'RB'), ('seven', 'CD'), ('or', 'CC'), ('eight', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('.', '.'), ('A', 'DT'), (':', ':'), ('I', 'PRP'), ('got', 'VBD'), ('her', 'PRP'), ('for', 'IN'), ('Christmas', 'NNP'), ('from', 'IN'), ('my', 'PRP$'), ('f', 'NN')]\n",
    "# len(tagged)\n",
    "# tagged[0]\n",
    "# count = 0\n",
    "# for word,pos in tagged:\n",
    "#     if pos.startswith('VB'):\n",
    "#         count+=1\n",
    "        \n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0b90d5",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa79c306",
   "metadata": {},
   "source": [
    "### Data loaders and Dataset for batched training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fdb9bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_train(Dataset):\n",
    "    def __init__(self, text_list, B = B, T = T, tokenizer = tokenizer, comp_ratio = comp_ratio,prob = .20):\n",
    "        self.text_list = text_list\n",
    "        #print(f\"Value of B {B}\")\n",
    "        self.prob = prob\n",
    "                                        \n",
    "    def __getitem__(self, idx):\n",
    "        #words_list[start_index:start_index + n]\n",
    "        chunk = self.text_list[idx:idx + B*T*comp_ratio]\n",
    "        #print(f\"length of chunk = {len(chunk)}\")\n",
    "        random_num = random.random()\n",
    "        #print(f\"The random number generated = {random_num}\")\n",
    "        if random_num > self.prob:\n",
    "            chunk = replace_verbs_with_synonyms(chunk)\n",
    "        inp,att = tokenize_text(chunk, tokenizer)\n",
    "        input_id = inp.view(B,T)\n",
    "        attention_mask = att.view(B,T)\n",
    "        #print(f\"shape of input_id = {input_id.shape}| shape of attention = {attention_mask.shape}\")\n",
    "        \n",
    "        return input_id,attention_mask\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        num_chunks = comp_ratio*B*T\n",
    "        return len(self.text_list)//num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3d2cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset_pyt_val(Dataset):\n",
    "    def __init__(self, text_list, B = B, T = T, tokenizer = tokenizer, comp_ratio = comp_ratio):\n",
    "        self.text_list = text_list\n",
    "        #print(f\"Value of B {B}\")\n",
    "                                                \n",
    "    def __getitem__(self, idx):\n",
    "        #words_list[start_index:start_index + n]\n",
    "        chunk = self.text_list[idx:idx + B*T*comp_ratio]\n",
    "        #print(f\"length of chunk = {len()}\")\n",
    "        inp,att = tokenize_text(chunk, tokenizer)\n",
    "        input_id = inp.view(B,T)\n",
    "        attention_mask = att.view(B,T)\n",
    "        #print(f\"shape of input_id = {input_id.shape}| shape of attention = {attention_mask.shape}\")\n",
    "        \n",
    "        return input_id,attention_mask\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        #return the length of the dataframe\n",
    "        num_chunks = comp_ratio*B*T\n",
    "        return len(self.text_list)//num_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5c2884bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = dataset_pyt(filtered_df,tokenizer = tokenizer)\n",
    "train_dataset = dataset_pyt_train(train_list)\n",
    "val_dataset = dataset_pyt_val(val_list)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,batch_size = 1, shuffle = True , num_workers = 4, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset,batch_size = 1, shuffle = True , num_workers = 4, pin_memory = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b476577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get a text with len \n",
    "# text = train_list[:3*B*T]\n",
    "# len(text)\n",
    "# #enc = tokenizer(text)\n",
    "# print(f\"orig text len = {len(text)}| compress ratio = {len(text)/len(enc['input_ids'])}\")\n",
    "# input_id_list = enc['input_ids']\n",
    "# att_list = enc['attention_mask']\n",
    "\n",
    "# input_id = torch.tensor(enc['input_ids'], dtype = torch.long)\n",
    "# attention_mask = torch.tensor(enc['attention_mask'], dtype = torch.long)\n",
    "# inp_v = input_id.view(B,T) \n",
    "# att_v = attention_mask.view(B,T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e13d7db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer vocabulary size: 50258\n",
      "EOS token ID: 50256\n",
      "PAD token ID: 50257\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "print(f\"EOS token ID: {tokenizer.eos_token_id}\")\n",
    "print(f\"PAD token ID: {tokenizer.pad_token_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbc76d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add PAD token if it doesn't exist\n",
    "# if tokenizer.pad_token is None:\n",
    "#     tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "#     print(f\"New tokenizer vocabulary size: {len(tokenizer)}\")\n",
    "#     print(f\"New PAD token ID: {tokenizer.pad_token_id}\")\n",
    "\n",
    "# # Resize model embeddings if you're using a model\n",
    "# # model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c1deb692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range (len(train_dataset)):\n",
    "#     model.to(device)\n",
    "#     input_id,attention_mask = train_dataset[i]\n",
    "#     ids = input_id.to(device=device, non_blocking=True)\n",
    "#     ids = torch.squeeze(ids, dim = 0)\n",
    "#     att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "#     att_mask =  torch.squeeze(att_mask, dim = 0).to(dtype=torch.bool)\n",
    "#     labels = input_id.clone()\n",
    "#     with autocast(dtype = torch.bfloat16):\n",
    "#         model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "#         print(f\"i = {i}| loss = {model_output.loss}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96a5129c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_list)//(3*B*T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "36380b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(log_message, model_name = \"GPT2\" ,random_init_wts = random_init_wts ):\n",
    "    current_datetime = datetime.datetime.now()\n",
    "    # Extract date and time components\n",
    "    current_date = str(current_datetime.date())\n",
    "    log_file = model_name +'_COS_SIM_'+'random_init_wts'+ '_'+str(random_init_wts)+'_' +current_date+'.log'\n",
    "    print(f\"*****LOGGING INFO IN {log_file}*********\")\n",
    "    filepath = os.path.join(\"model\",log_file)\n",
    "    logging.basicConfig(filename=filepath, \n",
    "                    filemode='a',  # Overwrite the log file each time\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    level=logging.DEBUG)\n",
    "    logger = logging.getLogger()\n",
    "    logger.info(log_message)\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d1eacbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class dataset_pyt_train(Dataset):\n",
    "#     def __init__(self, df, B = B, T = T, model = model, tokenizer = tokenizer, token_pos_map = create_token_pos_mapping(tokenizer)):\n",
    "#         self.df = df\n",
    "#         print(f\"Value of B {B}\")\n",
    "                                        \n",
    "#     def __getitem__(self, idx):\n",
    "#         #print(f\"inside loader...idx ->{idx}\")\n",
    "#         input_id_temp = torch.tensor(self.df.iloc[idx]['input_ids'],dtype = torch.long).to(device)\n",
    "#         att_mask = torch.tensor(self.df.iloc[idx]['attention_mask'],dtype = torch.long).to(device)\n",
    "#         #if the input index is even get the replacement embedding\n",
    "        \n",
    "#         if idx %2 == 0:\n",
    "#             inp_emb= prepare_input_with_synonym_embeddings(input_id_temp, model = model, tokenizer = tokenizer, token_pos_map = create_token_pos_mapping(tokenizer), replacement_prob=0.1)\n",
    "#         else:\n",
    "#             inp_emb = model.transformer.wte(input_id_temp)\n",
    "            \n",
    "                \n",
    "#         inp_emb =   inp_emb.view(-1,T,768)    \n",
    "#         attention_mask = att_mask.view(B,T)   \n",
    "#         labels = input_id_temp.view(B,T)\n",
    "#         return inp_emb, attention_mask,labels\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         #return the length of the dataframe\n",
    "#         return len(self.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "71535d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train loader is 275\n",
      "Length of the val loader is 287\n",
      "num_tokens= 18022400\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of the train loader is {len(train_loader)}\")\n",
    "print(f\"Length of the val loader is {len(val_loader)}\")\n",
    "print(f\"num_tokens= {B*T*len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d054b8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#emb,att,inp = train_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b63fa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_train_metrics:\n",
    "    def __init__(self, patience=25, min_delta=0 , B = T, T = T,best_loss = torch.inf,early_stop = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = best_loss\n",
    "        self.early_stop = early_stop\n",
    "        self.B = B\n",
    "        self.T = T\n",
    "        self.improvement = None\n",
    "\n",
    "    def __call__(self, loss, epoch , epoch_durn, norm , current_lr, num_token):\n",
    "        if self.best_loss - loss > self.min_delta:\n",
    "            \n",
    "            print(f\"training loss has decreased---> reducing the best loss from {self.best_loss:.2f} to {loss:.2f} | throughput = {int(num_token/epoch_durn)} tokens/second | norm = {norm:.4f} | learning rate = {current_lr:.5e}\")\n",
    "            self.best_loss = loss\n",
    "            self.counter = 0\n",
    "            self.improvement = True\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            self.improvement = False\n",
    "            print(f\"No improvement in training  loss-->epoch= {epoch} and best loss is {self.best_loss:.2f}|current_loss = {loss}|counter = {self.counter}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c527db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_val_metrics:\n",
    "    def __init__(self, patience=25, min_delta=0, best_loss = torch.inf,early_stop = False):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = best_loss\n",
    "        self.early_stop = early_stop\n",
    "        \n",
    "\n",
    "    def __call__(self, loss, epoch , model, tokenizer):\n",
    "        if self.best_loss - loss > self.min_delta:\n",
    "            print(f\"Val loss has decreased -->reducing the global validation loss from {self.best_loss:.2f} to {loss:.2f}\")\n",
    "            s1 = (f\"Val loss has decreased -->reducing the global validation loss from {self.best_loss:.2f} to {loss:.2f}\")\n",
    "            print(f\" validation loss for epoch = {epoch} is {loss:.4f}\")\n",
    "            self.best_loss = loss\n",
    "            s2 = f\" validation loss for epoch = {epoch} is {loss:.4f}\"\n",
    "            print(f\" epoch= {epoch} :  val loss is {loss:.4f} \")\n",
    "            s3 = f\" epoch= {epoch} :  val loss is {loss:.4f} \"\n",
    "            #save the model\n",
    "            # Get the current date and time\n",
    "            current_datetime = datetime.datetime.now()\n",
    "            # Extract date and time components\n",
    "            current_date = str(current_datetime.date())\n",
    "            current_time = str(current_datetime.time()).split('.')[0]\n",
    "            file_name = 'model'+ current_date+current_time+'.pth'\n",
    "            path = os.path.join(\"model\",file_name)\n",
    "            print(f\"saving the model {file_name}\")\n",
    "            s4 = f\"saving the model {file_name}\"\n",
    "            #torch.save(model.state_dict(), path)\n",
    "            model.save_pretrained(path)\n",
    "            tokenizer.save_pretrained(path)\n",
    "            log_message = s1+s2+s3+s4\n",
    "            write_file(log_message)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"No improvement in validation loss-->epoch= {epoch} and best val loss is {self.best_loss:.2f}|current_Val loss = {loss}|counter = {self.counter}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e0a18672",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_output = model(input_ids = inp ,attention_mask = att, labels = inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "38f24f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "\n",
    "def eval_model(val_loader, model, epoch , device = device,tokenizer = tokenizer):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    e = epoch+1\n",
    "    val_loss_accum = 0.0\n",
    "    print(f\"inside validation data for epoch {e}\")\n",
    "    for ind,(input_id,attention_mask) in enumerate(val_loader):\n",
    "        ids = input_id.to(device=device, non_blocking=True)\n",
    "        ids = torch.squeeze(ids, dim = 0)\n",
    "        att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "        att_mask =  torch.squeeze(att_mask, dim = 0)\n",
    "        labels = ids.clone().to(device)\n",
    "        with autocast(dtype = torch.bfloat16):\n",
    "            model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "            #print(f\"model_output loss = {model_output.loss}\")\n",
    "            total_loss = model_output.loss  \n",
    "    \n",
    "    \n",
    "    \n",
    "        val_loss_accum+= total_loss.detach().item()\n",
    "        del att_mask,labels,model_output,total_loss,ids\n",
    "    return val_loss_accum        \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "96ea0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_model(train_loader,val_loader,model,num_epoch = 100,device = device,tokenizer = tokenizer):\n",
    "    #model.train()\n",
    "    device = device\n",
    "    lr_custom = 1e-5\n",
    "    print(f\"inside train model. Device = {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(params =  model.parameters(), lr= lr_custom,fused = True ,weight_decay = .1)\n",
    "      \n",
    "    extra_train = .1*num_epoch\n",
    "    max_train_steps = int(num_epoch +extra_train )\n",
    "    import time\n",
    "    from transformers import get_linear_schedule_with_warmup\n",
    "    total_steps = len(train_loader) * num_epoch\n",
    "    scheduler_cos = transformers.get_cosine_schedule_with_warmup( optimizer= optimizer, num_warmup_steps =int(total_steps * 0.1) ,num_training_steps= total_steps )\n",
    "        \n",
    "    epoch_train_log = []\n",
    "    epoch_val_log = []\n",
    "    validate_val_metric = check_val_metrics()\n",
    "    validate_train_metric = check_train_metrics()\n",
    "    for i in range (max_train_steps):\n",
    "        \n",
    "        epoch_start_time = time.time()\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        # we use 2 schedulers - the first LR scheduler uses a cosine decay for 100 epochs the second scheduler takes the last LR from cosine scheduler and then maintains that LR for the next 10 epochs\n",
    "        if i >= num_epoch:\n",
    "            optimizer_reduced_lr = torch.optim.AdamW(params =  model.parameters(), lr= current_lr ,fused = True , weight_decay=.1)\n",
    "            scheduler_constant = transformers.get_constant_schedule_with_warmup( optimizer = optimizer_reduced_lr ,num_warmup_steps = 0, last_epoch = -1 )\n",
    "        \n",
    "        epoch_train_loss = 0       \n",
    "        for ind,(input_id,attention_mask) in enumerate(train_loader):\n",
    "            if ind == int(len(train_loader)/2):\n",
    "                batch_time = time.time()\n",
    "                duration = batch_time - epoch_start_time\n",
    "                print(f\"executing epoch:{i+1}, it took {duration/60} mins from beginning of epoch till batch#{ind}\")\n",
    "            \n",
    "            ids = input_id.to(device=device, non_blocking=True)\n",
    "            ids = torch.squeeze(ids, dim = 0)\n",
    "            att_mask = attention_mask.to(device=device, non_blocking=True)\n",
    "            att_mask =  torch.squeeze(att_mask, dim = 0)\n",
    "            labels = ids.clone().to(device)\n",
    "                        \n",
    "            with autocast(dtype = torch.bfloat16):\n",
    "                model_output = model(input_ids = ids ,attention_mask = att_mask, labels = labels)\n",
    "                total_loss = model_output.loss\n",
    "                if np.isnan(model_output.loss.item()):\n",
    "                    print(\"f nan values encountered..\")\n",
    "                    decoded_texts = [tokenizer.decode(ids, skip_special_tokens=True) for ids in ids]\n",
    "                    print(f\"*********$$$$$$$$$ decoded_texts = {decoded_texts}*************\")\n",
    "            assert not np.isnan(model_output.loss.item()), \"NaN value found\"\n",
    "                               \n",
    "            total_loss.backward()\n",
    "            epoch_train_loss += total_loss.detach().item()\n",
    "            norm = torch.nn.utils.clip_grad_norm(model.parameters() , 1.0)\n",
    "            if i <= num_epoch:\n",
    "                optimizer.step()\n",
    "                scheduler_cos.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "            else:\n",
    "                optimizer_reduced_lr.step()\n",
    "                optimizer_reduced_lr.zero_grad(set_to_none=True)\n",
    "                scheduler_constant.step()\n",
    "                \n",
    "                         \n",
    "            del att_mask,labels,model_output,ids\n",
    "            \n",
    "        #batch processing complete \n",
    "        #print(f\"batch processing complete , lambda = {lambda_val} |total_loss for batch= {total_loss}\")\n",
    "        \n",
    "        if i <= num_epoch:\n",
    "            current_lr = scheduler_cos.get_last_lr()[0]\n",
    "        epoch_end_time = time.time()\n",
    "        epoch_durn = (epoch_end_time - epoch_start_time)\n",
    "        num_token = B*T*len(train_loader)\n",
    "        epoch_train_log.append(epoch_train_loss)\n",
    "        validate_train_metric(epoch_train_loss, i , epoch_durn, norm , current_lr, num_token)\n",
    "        \n",
    "        if validate_train_metric.improvement:\n",
    "            val_loss= eval_model(val_loader, model, epoch = i, device = device,tokenizer = tokenizer)\n",
    "            epoch_val_log.append(val_loss)\n",
    "            validate_val_metric(val_loss, i , model, tokenizer)\n",
    "            if validate_train_metric.early_stop or validate_val_metric.early_stop :\n",
    "                print(f\"early stopping trigerred either from training data or val data | train_counter = {validate_train_metric.counter}|val_counter = {validate_val_metric.counter}\")\n",
    "                break\n",
    "        else:\n",
    "            if validate_val_metric.early_stop:\n",
    "                print(f\"early stopping trigerred from validation data\")\n",
    "                break\n",
    "              \n",
    "    \n",
    "    return model,epoch_train_log,epoch_val_log\n",
    "        \n",
    "            \n",
    "            \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "867f5a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside train model. Device = cuda:0\n",
      "executing epoch:1, it took 1.4449185808499654 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from inf to 2624.53 | throughput = 105425 tokens/second | norm = 4.0060 | learning rate = 1.00000e-06\n",
      "inside validation data for epoch 1\n",
      "Val loss has decreased -->reducing the global validation loss from inf to 2664.92\n",
      " validation loss for epoch = 0 is 2664.9218\n",
      " epoch= 0 :  val loss is 2664.9218 \n",
      "saving the model model2024-07-2602:31:09.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:2, it took 1.4156872034072876 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 2624.53 to 1808.58 | throughput = 108156 tokens/second | norm = 4.2635 | learning rate = 2.00000e-06\n",
      "inside validation data for epoch 2\n",
      "Val loss has decreased -->reducing the global validation loss from 2664.92 to 1831.07\n",
      " validation loss for epoch = 1 is 1831.0735\n",
      " epoch= 1 :  val loss is 1831.0735 \n",
      "saving the model model2024-07-2602:34:54.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:3, it took 1.4352652748425803 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 1808.58 to 1451.68 | throughput = 106256 tokens/second | norm = 2.1902 | learning rate = 3.00000e-06\n",
      "inside validation data for epoch 3\n",
      "Val loss has decreased -->reducing the global validation loss from 1831.07 to 1543.06\n",
      " validation loss for epoch = 2 is 1543.0647\n",
      " epoch= 2 :  val loss is 1543.0647 \n",
      "saving the model model2024-07-2602:38:41.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:4, it took 1.4423599203427633 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 1451.68 to 1271.11 | throughput = 107516 tokens/second | norm = 2.7052 | learning rate = 4.00000e-06\n",
      "inside validation data for epoch 4\n",
      "Val loss has decreased -->reducing the global validation loss from 1543.06 to 1398.25\n",
      " validation loss for epoch = 3 is 1398.2491\n",
      " epoch= 3 :  val loss is 1398.2491 \n",
      "saving the model model2024-07-2602:42:26.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:5, it took 1.3739086389541626 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 1271.11 to 1159.03 | throughput = 110413 tokens/second | norm = 4.7289 | learning rate = 5.00000e-06\n",
      "inside validation data for epoch 5\n",
      "Val loss has decreased -->reducing the global validation loss from 1398.25 to 1288.51\n",
      " validation loss for epoch = 4 is 1288.5124\n",
      " epoch= 4 :  val loss is 1288.5124 \n",
      "saving the model model2024-07-2602:46:07.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:6, it took 1.367246643702189 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 1159.03 to 1048.82 | throughput = 110814 tokens/second | norm = 4.1313 | learning rate = 6.00000e-06\n",
      "inside validation data for epoch 6\n",
      "Val loss has decreased -->reducing the global validation loss from 1288.51 to 1199.07\n",
      " validation loss for epoch = 5 is 1199.0690\n",
      " epoch= 5 :  val loss is 1199.0690 \n",
      "saving the model model2024-07-2602:49:48.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:7, it took 1.3856601277987162 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 1048.82 to 953.41 | throughput = 108702 tokens/second | norm = 9.2856 | learning rate = 7.00000e-06\n",
      "inside validation data for epoch 7\n",
      "Val loss has decreased -->reducing the global validation loss from 1199.07 to 1140.16\n",
      " validation loss for epoch = 6 is 1140.1572\n",
      " epoch= 6 :  val loss is 1140.1572 \n",
      "saving the model model2024-07-2602:53:32.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:8, it took 1.4063665827115377 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 953.41 to 878.71 | throughput = 108231 tokens/second | norm = 5.7931 | learning rate = 8.00000e-06\n",
      "inside validation data for epoch 8\n",
      "Val loss has decreased -->reducing the global validation loss from 1140.16 to 1105.61\n",
      " validation loss for epoch = 7 is 1105.6085\n",
      " epoch= 7 :  val loss is 1105.6085 \n",
      "saving the model model2024-07-2602:57:16.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:9, it took 1.414764440059662 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 878.71 to 817.14 | throughput = 108949 tokens/second | norm = 5.0839 | learning rate = 9.00000e-06\n",
      "inside validation data for epoch 9\n",
      "Val loss has decreased -->reducing the global validation loss from 1105.61 to 1090.31\n",
      " validation loss for epoch = 8 is 1090.3059\n",
      " epoch= 8 :  val loss is 1090.3059 \n",
      "saving the model model2024-07-2603:00:59.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:10, it took 1.419564954439799 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 817.14 to 764.36 | throughput = 105743 tokens/second | norm = 6.3912 | learning rate = 1.00000e-05\n",
      "inside validation data for epoch 10\n",
      "Val loss has decreased -->reducing the global validation loss from 1090.31 to 1070.33\n",
      " validation loss for epoch = 9 is 1070.3312\n",
      " epoch= 9 :  val loss is 1070.3312 \n",
      "saving the model model2024-07-2603:04:48.pth\n",
      "*****LOGGING INFO IN GPT2_COS_SIM_random_init_wts_True_2024-07-26.log*********\n",
      "executing epoch:11, it took 1.3973329265912373 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 764.36 to 704.90 | throughput = 108990 tokens/second | norm = 11.1445 | learning rate = 9.99695e-06\n",
      "inside validation data for epoch 11\n",
      "No improvement in validation loss-->epoch= 10 and best val loss is 1070.33|current_Val loss = 1072.212381362915|counter = 1\n",
      "executing epoch:12, it took 1.4002977768580118 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 704.90 to 651.52 | throughput = 106406 tokens/second | norm = 11.2043 | learning rate = 9.98782e-06\n",
      "inside validation data for epoch 12\n",
      "No improvement in validation loss-->epoch= 11 and best val loss is 1070.33|current_Val loss = 1083.352264881134|counter = 2\n",
      "executing epoch:13, it took 1.430963385105133 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 651.52 to 602.42 | throughput = 108247 tokens/second | norm = 11.3695 | learning rate = 9.97261e-06\n",
      "inside validation data for epoch 13\n",
      "No improvement in validation loss-->epoch= 12 and best val loss is 1070.33|current_Val loss = 1087.823362827301|counter = 3\n",
      "executing epoch:14, it took 1.364056444168091 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 602.42 to 558.86 | throughput = 110089 tokens/second | norm = 10.1194 | learning rate = 9.95134e-06\n",
      "inside validation data for epoch 14\n",
      "No improvement in validation loss-->epoch= 13 and best val loss is 1070.33|current_Val loss = 1101.9857120513916|counter = 4\n",
      "executing epoch:15, it took 1.4211666504542033 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 558.86 to 512.35 | throughput = 107575 tokens/second | norm = 14.4300 | learning rate = 9.92404e-06\n",
      "inside validation data for epoch 15\n",
      "No improvement in validation loss-->epoch= 14 and best val loss is 1070.33|current_Val loss = 1120.8209345340729|counter = 5\n",
      "executing epoch:16, it took 1.379122785727183 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 512.35 to 466.00 | throughput = 108052 tokens/second | norm = 11.5414 | learning rate = 9.89074e-06\n",
      "inside validation data for epoch 16\n",
      "No improvement in validation loss-->epoch= 15 and best val loss is 1070.33|current_Val loss = 1127.1882493495941|counter = 6\n",
      "executing epoch:17, it took 1.4180421074231466 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 466.00 to 417.73 | throughput = 106834 tokens/second | norm = 10.5064 | learning rate = 9.85148e-06\n",
      "inside validation data for epoch 17\n",
      "No improvement in validation loss-->epoch= 16 and best val loss is 1070.33|current_Val loss = 1160.1073212623596|counter = 7\n",
      "executing epoch:18, it took 1.424354616800944 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 417.73 to 375.86 | throughput = 107961 tokens/second | norm = 22.6157 | learning rate = 9.80631e-06\n",
      "inside validation data for epoch 18\n",
      "No improvement in validation loss-->epoch= 17 and best val loss is 1070.33|current_Val loss = 1184.8816471099854|counter = 8\n",
      "executing epoch:19, it took 1.40963716506958 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 375.86 to 331.80 | throughput = 107893 tokens/second | norm = 12.1986 | learning rate = 9.75528e-06\n",
      "inside validation data for epoch 19\n",
      "No improvement in validation loss-->epoch= 18 and best val loss is 1070.33|current_Val loss = 1204.305594921112|counter = 9\n",
      "executing epoch:20, it took 1.3806277751922607 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 331.80 to 285.36 | throughput = 107176 tokens/second | norm = 11.8658 | learning rate = 9.69846e-06\n",
      "inside validation data for epoch 20\n",
      "No improvement in validation loss-->epoch= 19 and best val loss is 1070.33|current_Val loss = 1226.0889439582825|counter = 10\n",
      "executing epoch:21, it took 1.4364033540089924 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 285.36 to 247.28 | throughput = 107204 tokens/second | norm = 53.2563 | learning rate = 9.63592e-06\n",
      "inside validation data for epoch 21\n",
      "No improvement in validation loss-->epoch= 20 and best val loss is 1070.33|current_Val loss = 1247.05775308609|counter = 11\n",
      "executing epoch:22, it took 1.442244497934977 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 247.28 to 209.25 | throughput = 106805 tokens/second | norm = 8.9280 | learning rate = 9.56773e-06\n",
      "inside validation data for epoch 22\n",
      "No improvement in validation loss-->epoch= 21 and best val loss is 1070.33|current_Val loss = 1269.9137926101685|counter = 12\n",
      "executing epoch:23, it took 1.424239456653595 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 209.25 to 178.75 | throughput = 106781 tokens/second | norm = 20.4050 | learning rate = 9.49397e-06\n",
      "inside validation data for epoch 23\n",
      "No improvement in validation loss-->epoch= 22 and best val loss is 1070.33|current_Val loss = 1289.2258310317993|counter = 13\n",
      "executing epoch:24, it took 1.4008834719657899 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 178.75 to 154.62 | throughput = 107863 tokens/second | norm = 9.1156 | learning rate = 9.41474e-06\n",
      "inside validation data for epoch 24\n",
      "No improvement in validation loss-->epoch= 23 and best val loss is 1070.33|current_Val loss = 1321.6381344795227|counter = 14\n",
      "executing epoch:25, it took 1.4269017378489177 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 154.62 to 122.39 | throughput = 106724 tokens/second | norm = 6.1018 | learning rate = 9.33013e-06\n",
      "inside validation data for epoch 25\n",
      "No improvement in validation loss-->epoch= 24 and best val loss is 1070.33|current_Val loss = 1346.858033657074|counter = 15\n",
      "executing epoch:26, it took 1.379314657052358 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 122.39 to 110.30 | throughput = 109746 tokens/second | norm = 7.2572 | learning rate = 9.24024e-06\n",
      "inside validation data for epoch 26\n",
      "No improvement in validation loss-->epoch= 25 and best val loss is 1070.33|current_Val loss = 1366.9805240631104|counter = 16\n",
      "executing epoch:27, it took 1.4250797231992085 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 110.30 to 88.58 | throughput = 107738 tokens/second | norm = 6.9435 | learning rate = 9.14519e-06\n",
      "inside validation data for epoch 27\n",
      "No improvement in validation loss-->epoch= 26 and best val loss is 1070.33|current_Val loss = 1390.100914478302|counter = 17\n",
      "executing epoch:28, it took 1.402896801630656 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 88.58 to 78.43 | throughput = 108601 tokens/second | norm = 10.0094 | learning rate = 9.04508e-06\n",
      "inside validation data for epoch 28\n",
      "No improvement in validation loss-->epoch= 27 and best val loss is 1070.33|current_Val loss = 1412.5235495567322|counter = 18\n",
      "executing epoch:29, it took 1.4437914967536927 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 78.43 to 66.77 | throughput = 107204 tokens/second | norm = 14.6218 | learning rate = 8.94005e-06\n",
      "inside validation data for epoch 29\n",
      "No improvement in validation loss-->epoch= 28 and best val loss is 1070.33|current_Val loss = 1432.9263634681702|counter = 19\n",
      "executing epoch:30, it took 1.4127265294392903 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 66.77 to 60.23 | throughput = 106615 tokens/second | norm = 2.5297 | learning rate = 8.83022e-06\n",
      "inside validation data for epoch 30\n",
      "No improvement in validation loss-->epoch= 29 and best val loss is 1070.33|current_Val loss = 1455.1280822753906|counter = 20\n",
      "executing epoch:31, it took 1.3836324612299602 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 60.23 to 52.98 | throughput = 107221 tokens/second | norm = 2.1723 | learning rate = 8.71572e-06\n",
      "inside validation data for epoch 31\n",
      "No improvement in validation loss-->epoch= 30 and best val loss is 1070.33|current_Val loss = 1470.953197479248|counter = 21\n",
      "executing epoch:32, it took 1.6777037064234415 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 52.98 to 46.70 | throughput = 88667 tokens/second | norm = 2.2978 | learning rate = 8.59670e-06\n",
      "inside validation data for epoch 32\n",
      "No improvement in validation loss-->epoch= 31 and best val loss is 1070.33|current_Val loss = 1487.1177144050598|counter = 22\n",
      "executing epoch:33, it took 1.7384484211603801 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 46.70 to 44.60 | throughput = 87505 tokens/second | norm = 1.7119 | learning rate = 8.47329e-06\n",
      "inside validation data for epoch 33\n",
      "No improvement in validation loss-->epoch= 32 and best val loss is 1070.33|current_Val loss = 1500.5752515792847|counter = 23\n",
      "executing epoch:34, it took 1.7476621905962626 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 44.60 to 39.16 | throughput = 86693 tokens/second | norm = 1.4807 | learning rate = 8.34565e-06\n",
      "inside validation data for epoch 34\n",
      "No improvement in validation loss-->epoch= 33 and best val loss is 1070.33|current_Val loss = 1521.7144980430603|counter = 24\n",
      "executing epoch:35, it took 1.7343676606814067 mins from beginning of epoch till batch#137\n",
      "training loss has decreased---> reducing the best loss from 39.16 to 35.85 | throughput = 87370 tokens/second | norm = 1.5099 | learning rate = 8.21394e-06\n",
      "inside validation data for epoch 35\n",
      "No improvement in validation loss-->epoch= 34 and best val loss is 1070.33|current_Val loss = 1531.25688123703|counter = 25\n",
      "early stopping trigerred either from training data or val data | train_counter = 0|val_counter = 25\n"
     ]
    }
   ],
   "source": [
    "tr_model,epoch_train_log,epoch_val_log = train_model(train_loader, val_loader,model=model,tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "904c2943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2624.5281524658203, 1808.5846166610718, 1451.6766738891602, 1271.1053051948547, 1159.0322563648224, 1048.8235206604004, 953.4149024486542, 878.7147300243378, 817.1425602436066, 764.3566131591797, 704.9006762504578, 651.5179994106293, 602.4197084903717, 558.8622270822525, 512.3467551469803, 465.99674785137177, 417.7266254425049, 375.8563007116318, 331.7992571592331, 285.3649072647095, 247.28347223997116, 209.25073146820068, 178.75091433525085, 154.62063750624657, 122.39360243082047, 110.30261260271072, 88.57980489730835, 78.42990012466908, 66.77034239470959, 60.23264341056347, 52.98213003575802, 46.69533106684685, 44.59944436699152, 39.15776086598635, 35.84809774160385]\n"
     ]
    }
   ],
   "source": [
    "print(epoch_train_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "90c83783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json , os\n",
    "# path_var_train_log = os.path.join(\".\",\"Tokenizers_and_loss_vals\",\"epoch_train_plain_loss.json\")\n",
    "# path_var_val_log = os.path.join(\".\",\"Tokenizers_and_loss_vals\",\"epoch_val_val_loss_.json\")\n",
    "\n",
    "# #print(path_var)\n",
    "# #Write the list to a JSON file\n",
    "# with open(path_var_train_log, \"w\") as file:\n",
    "#     json.dump(epoch_train_log, file)\n",
    "\n",
    "# with open(path_var_val_log, \"w\") as file:\n",
    "#     json.dump(epoch_val_log, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "771b6ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(path_var_train_log, \"r\") as file:\n",
    "#     train_loss = json.load(file)\n",
    "# with open(path_var_val_log, \"r\") as file:\n",
    "#     val_loss = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33f451c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f033bd55f70>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAh3klEQVR4nO3deXhc9X3v8fd3ZrRYmy1LsiRLsiUvGIxNvAgvbAlJwUt4CgRwcVIgK6SF3uZJmxva3tzkps0t7W0gSUMTIKGQhAJuCMG31wYMcVgNtmyMV2zLqyRrtWwtlrWM9Lt/zLEjjGXJtqQZzfm8nmeeOfrNmdF3zmN/ztHv/M7vmHMOERHxh0C0CxARkeGj0BcR8RGFvoiIjyj0RUR8RKEvIuIjoWgXcDbZ2dmuuLg42mWIiIwoGzdubHDO5ZzptZgO/eLiYsrKyqJdhojIiGJmB/t6Td07IiI+otAXEfERhb6IiI8o9EVEfEShLyLiIwp9EREfUeiLiPhIXIZ+04kufvjKHt6vOBbtUkREYkpMX5x1vgIGD72ym8RQgI8VjYl2OSIiMSMuj/TTkxPITkvk4JHj0S5FRCSmxGXoA0zMSmV/g0JfRKS3uA394qxUDuhIX0TkQ+I29EuyU6ht7qCtMxztUkREYkbchn5xdioAB4+0RbkSEZHYEb+hnxUJ/QPq1xcROaXf0DezIjNba2Y7zGy7mf2l1/4dM6sys83eY2mv9/yNmZWb2S4zW9SrfbHXVm5m9w/NV4o4eaS/X/36IiKnDGScfhj4K+fcJjNLBzaa2RrvtYecc//Se2Uzmw7cDlwKjAdeMbOLvJcfBq4DKoENZrbSObdjML7I6dKSQmSnJelIX0Skl35D3zlXDVR7yy1mthMoOMtbbgSecc51APvNrByY571W7pzbB2Bmz3jrDknoQ+Rk7gH16YuInHJOffpmVgzMBt71mu4zsy1m9riZZXptBUBFr7dVem19tZ/+O+42szIzK6uvrz+X8j6iOCtVR/oiIr0MOPTNLA14Dviac64Z+AkwGZhF5C+B7w9GQc65R51zpc650pycM97Xd8CKs1Opa+ngeIeGbYqIwABD38wSiAT+U8653wA452qdc93OuR7gMf7QhVMFFPV6e6HX1lf7kDk1gkcnc0VEgIGN3jHg58BO59yDvdrze612M7DNW14J3G5mSWZWAkwF1gMbgKlmVmJmiURO9q4cnK9xZsXZKQAcaFC/vogIDGz0zpXAHcBWM9vstf0tsNzMZgEOOADcA+Cc225mK4icoA0D9zrnugHM7D7gJSAIPO6c2z5o3+QMdKQvIvJhAxm98yZgZ3hp1Vne8z3ge2doX3W29w221KQQ49I1bFNE5KS4vSL3JE28JiLyB/Ef+tkp7FefvogI4IvQT6WhtYNWDdsUEYn/0C/RxGsiIqfEfeifnHhN/foiIj4I/YlZJ8fqK/RFROI+9FMSQ+RmJGniNRERfBD6oInXRERO8kXol2RrrL6ICPgk9CdmpdLQ2klLe1e0SxERiSpfhH6JJl4TEQF8EvoatikiEuGL0J84VhdoiYiAT0J/VGKQ/NHJ7NeRvoj4nC9CHyIXaelIX0T8zjehX5KdykFdoCUiPueb0C/OSuXI8U6aNWxTRHzMP6GfrZO5IiL+CX1viuX9Cn0R8THfhP4fZttUv76I+JdvQj85Icj40ckc1LBNEfEx34Q+RPr1NVZfRPzMd6GvE7ki4mf+Cv2sFI62ddHUpmGbIuJPPgt9TbwmIv7mq9Av0WybIuJzvgr9orEpmGmsvoj4l69CPzJsc5RO5oqIb/kq9AGKs1M4oInXRMSn+g19Mysys7VmtsPMtpvZX3rtY81sjZnt8Z4zvXYzsx+ZWbmZbTGzOb0+6y5v/T1mdtfQfa2+FWfpJuki4l8DOdIPA3/lnJsOLADuNbPpwP3Aq865qcCr3s8AS4Cp3uNu4CcQ2UkA3wbmA/OAb5/cUQynkuxUjrV1caytc7h/tYhI1PUb+s65aufcJm+5BdgJFAA3Ak96qz0J3OQt3wj8wkW8A4wxs3xgEbDGOdfonDsKrAEWD+aXGQhNvCYifnZOffpmVgzMBt4Fcp1z1d5LNUCut1wAVPR6W6XX1lf76b/jbjMrM7Oy+vr6cylvQIqzvYnX1MUjIj404NA3szTgOeBrzrnm3q855xzgBqMg59yjzrlS51xpTk7OYHzkhxSNTSFgmm1TRPxpQKFvZglEAv8p59xvvOZar9sG77nOa68Cinq9vdBr66t9WCWFgowfM0pH+iLiSwMZvWPAz4GdzrkHe720Ejg5Aucu4IVe7Xd6o3gWAE1eN9BLwPVmlumdwL3eaxt2JZp4TUR8KjSAda4E7gC2mtlmr+1vgQeAFWb2JeAgsMx7bRWwFCgH2oAvADjnGs3s74EN3nrfdc41DsaXOFfFWam8sLkK5xyRfZqIiD/0G/rOuTeBvpLxU2dY3wH39vFZjwOPn0uBQ2FiVgrN7WGOtXWRmZoY7XJERIaN767IhT9MvKYbqoiI3/gy9ItPzrapfn0R8Rlfhn5R5slhmwp9EfEXX4Z+YihAQeYoTbwmIr7jy9AHTbwmIv7k29AvyU5lf8NxIoONRET8wbehX5yVSkt7mMbjmm1TRPzDt6Gv++WKiB/5PvR3VrdEuRIRkeHj29CfmJXCxKwUXt5RG+1SRESGjW9D38xYMiOft8sbdBctEfEN34Y+wNKZeYR7HGt0tC8iPuHr0J9ZMJqCMaNYva0m2qWIiAwLX4e+mbF0Zh5v7Kmnub0r2uWIiAw5X4c+wJKZ+XR1O17dqS4eEYl/vg/9WYVjyB+dzKqt6uIRkfjn+9APBIzFM/J4bXc9LeriEZE45/vQB1g6M5/OcA+/+6Cu/5VFREYwhT4wd0Im49KTWK0uHhGJcwp9Il08S2bksXZXHcc7wtEuR0RkyCj0PUtm5tMR7uH3u+qjXYqIyJBR6HsuLx5Ldloiq7ZVR7sUEZEho9D3BAPGokvzWPtBHSc6u6NdjojIkFDo97J0Zj5tnd28tltdPCISnxT6vcwvGUtmSgKr1cUjInFKod9LKBhg0aV5vLqzjvYudfGISPxR6J9mycx8WjvCvLGnIdqliIgMOoX+aa6YnMXoUQms3qouHhGJPwr90yQEA1w3PZc1O2vpCKuLR0TiS7+hb2aPm1mdmW3r1fYdM6sys83eY2mv1/7GzMrNbJeZLerVvthrKzez+wf/qwyeT8/Mp6U9zNvlR6JdiojIoBrIkf4TwOIztD/knJvlPVYBmNl04HbgUu89/2ZmQTMLAg8DS4DpwHJv3Zh0xZQs0pNDrFIXj4jEmX5D3zn3OtA4wM+7EXjGOdfhnNsPlAPzvEe5c26fc64TeMZbNyYlhYJcd0kuL++opau7J9rliIgMmgvp07/PzLZ43T+ZXlsBUNFrnUqvra/2jzCzu82szMzK6uujd5HUkpn5NJ3oYt1edfGISPw439D/CTAZmAVUA98frIKcc48650qdc6U5OTmD9bHn7Oqp2aQmBnWhlojElfMKfedcrXOu2znXAzxGpPsGoAoo6rVqodfWV3vMSk4I8qlLcnlpey1hdfGISJw4r9A3s/xeP94MnBzZsxK43cySzKwEmAqsBzYAU82sxMwSiZzsXXn+ZQ+PpTPzaDzeyVpNtywicSLU3wpm9jTwCSDbzCqBbwOfMLNZgAMOAPcAOOe2m9kKYAcQBu51znV7n3Mf8BIQBB53zm0f7C8z2K69eByTclL5zsrtXDE5i9SkfjeXiEhMM+dctGvoU2lpqSsrK4tqDWUHGrntkXXctbCY7/zxpVGtRURkIMxso3Ou9Eyv6YrcfpQWj+XOBRN5ct0BNh4c6MhVEZHYpNAfgG8svpjxo0fx33+9RbNvisiIptAfgLSkEP/7MzPZW3+cH/+uPNrliIicN4X+AH38ohxumVPIT1/by/bDTdEuR0TkvCj0z8G3briEMSkJfPO5LRq7LyIjkkL/HIxJSeS7N85gW1UzP3tzf7TLERE5Zwr9c7RkRh6LLs3loTW72VffGu1yRETOiUL/HJkZf3/jDJJCAe5/bis9PbF7nYOIyOkU+udhXEYy/+OG6aw/0MhT6w9FuxwRkQFT6J+n2+YWctWUbB5YtZOqYyeiXY6IyIAo9M+TmfGPn5lJj4O/e34rsTydhYjISQr9C1A0NoVvLJrG73fV8/2Xdyv4RSTmadrIC/T5K4rZXdvCj9eW09bZzbduuAQzi3ZZIiJnpNC/QIFApJtnVGKQx9/az4muMP9w00yCAQW/iMQehf4gMDP+5w3TSUkM8vDavZzo7OZfbvsYoaB6z0Qktij0B4mZ8Y1FF5OSGOL/vLSL9q4efrR8NokhBb+IxA4l0iC799opfOuG6by4vYa7f1mmqZhFJKYo9IfAl64q4R8/M5PXdtfz+X9fT2tHONoliYgACv0hs3zeBB5aNosNB45yx8/fpelEV7RLEhFR6A+lm2YX8PBn57CtqonPPvYOR1o7ol2SiPicQn+ILZ6Rx6N3llJe18qyR9ZR09Qe7ZJExMcU+sPg2mnj+MUX51Hb3MGtP32bAw3Ho12SiPiUQn+YzJ+UxX98ZT7HO8Lc9sg6dtW0RLskEfEhhf4wuqxwDCvuWUjA4E8eXcfmimPRLklEfEahP8ym5qbz669eQUZyAp977B3e3tsQ7ZJExEcU+lFQNDaF//zqQsaPGcXn/30Dr+yojXZJIuITCv0oyc1IZsU9C7k4L52v/mojL2yuinZJIuIDCv0oykxN5Kkvz2fuxEy+9uxmnnr3YLRLEpE4p9CPsvTkBJ784jyunTaOv3t+Gw+s/oBu3WxdRIZIv6FvZo+bWZ2ZbevVNtbM1pjZHu8502s3M/uRmZWb2RYzm9PrPXd56+8xs7uG5uuMTMkJQR65Yy6fmz+Bn762ly8/uYHmdk3bICKDbyBH+k8Ai09rux941Tk3FXjV+xlgCTDVe9wN/AQiOwng28B8YB7w7ZM7ColICAb43s0z+YebZvDGngZuevgt9ta3RrssEYkz/Ya+c+51oPG05huBJ73lJ4GberX/wkW8A4wxs3xgEbDGOdfonDsKrOGjOxIB/nTBRJ768nyOtXVx08NvsXZXXbRLEpE4cr59+rnOuWpvuQbI9ZYLgIpe61V6bX21f4SZ3W1mZWZWVl9ff57ljWzzJ2Wx8r4rKcpM4YtPbOCnr+3VTddFZFBc8IlcF0mjQUsk59yjzrlS51xpTk7OYH3siFOYmcKv/2whS2fm88DqD/jas5t1QxYRuWDnG/q1XrcN3vPJPogqoKjXeoVeW1/tchYpiSF+vHw231g0jZXvH+bWn77N4WMnol2WiIxg5xv6K4GTI3DuAl7o1X6nN4pnAdDkdQO9BFxvZpneCdzrvTbph5lx77VTeOyOUg40tPHHP36TVVur1d0jIudlIEM2nwbWAdPMrNLMvgQ8AFxnZnuAP/J+BlgF7APKgceAPwdwzjUCfw9s8B7f9dpkgP5oei6/vfcKcjOS+fOnNvGVX2ykuklH/SJybiyWjxhLS0tdWVlZtMuIKeHuHn7+5n4eemU3oUCAby6exufmTyQQsGiXJiIxwsw2OudKz/SarsgdYULBAPd8fDIvf+3jzCoaw7de2M5tj6xjT63m5xeR/in0R6gJWSn88kvz+P5tH2NvfStLf/QGD67ZTUdYI3xEpG8K/RHMzLhlbiGvfv3jfHpmPj96dQ9Lf/gG6/frdImInJlCPw5kpSXxg9tn88QXLqe9q4dlj6zjnl+WqctHRD5CoR9HPjFtHGu+fg1fv+4i3i4/wvU/eJ2vr9hMRWNbtEsTkRih0Ttx6ujxTn7y2l6efPsAPc6xfN4E7rt2CuMykqNdmogMsbON3lHox7mapnb+9Xd7eHZDBaGg8YUrS7jnmkmMSUmMdmkiMkQU+sKBhuP84JXdvPD+YdKSQtx99STuXFjM6JSEaJcmIoNMoS+n7Kxu5vsv7+KVnXWkJAZZVlrEF68sYUJWSrRLE5FBotCXj9hxuJmfvbmP//v+Ybp7HIsuzeMr10xizgTd20ZkpFPoS59qm9t54u0DPPXOQZrbw8ydmMlXri7huul5BDW1g8iIpNCXfh3vCLOirILH39pPReMJJmal8OWrSrittIjkhGC0yxORc6DQlwELd/fw8o5aHn19H5srjpE/Opl7r53CstIiEkO6rENkJFDoyzlzzvFW+REeXLOLTYeOUTBmFH/xySncMreQhKDCXySWKfTlvDnneH1PAw+u2c37FccoGjuKv/jkVD4zu4CQwl8kJin05YI551i7q46H1uxha1UTxVkp/LdPTeXGWQU64SsSYxT6Mmicc7yys44H1+xmZ3UzJdmpfPnqEm6ZU6gTviIxQqEvg66nx/Hyjhr+7fd72VLZRFZqInddUcyfLpjI2FRN8SASTQp9GTLOOd7Z18hjb+zjdx/UkZwQYFlpEV+6qoSJWanRLk/El84W+qHhLkbii5mxcHIWCydnsbu2hZ+9sY9n1lfwq3cOsnhGHl+5ehKzdZWvSMzQkb4MujrvKt9feVf5lk7M5M4rill8aZ7G+osMA3XvSFS0doR5dkMFT759gEONbeSkJ7F83gQ+O28CeaM1r7/IUFHoS1T19Dhe21PPL9cdZO2uOgJmLLo0lzsWFLNg0ljMNORTZDCpT1+iKhAwrp02jmunjePQkTZ+9e5Bnt1QwaqtNVyUm8YdCyZy85xC0pL0z1FkqOlIX6Kivauble8f5hfrDrCtqpmUxCCLZ+Rx65xCFkzKIqALvkTOm7p3JGY553iv4hgrNlTw/7ZU09IRpmDMKG6eXcAtcwspydawT5FzpdCXEeFEZzcv76jh1xsreau8gR4HcydmcsucQj59WT6jR+nWjiIDodCXEaemqZ3n36viuU2VlNe1khgKsPjSPG6fV8TCSVk6+StyFgp9GbGcc2ypbOK5TZX89r0qmtvDlGSn8ieXF3Hr3EKy05KiXaJIzBmy0DezA0AL0A2EnXOlZjYWeBYoBg4Ay5xzRy1yaPZDYCnQBnzeObfpbJ+v0Jfe2ru6WbW1mqfXH2LDgaMkBI3rpueyfN4ErpycrZO/Ip6hDv1S51xDr7Z/Bhqdcw+Y2f1ApnPum2a2FPgLIqE/H/ihc27+2T5foS99Ka9r4en1FfxmUyVH27ooGjuK2y+fwG1zCxmXoQu/xN+GO/R3AZ9wzlWbWT7we+fcNDN7xFt++vT1+vp8hb70p72rm5e21/DM+grW7TtCMGB86uJxLJ83gWsuytFc/+JLQ3lxlgNeNjMHPOKcexTI7RXkNUCut1wAVPR6b6XX9qHQN7O7gbsBJkyYcIHlSbxLTghy46wCbpxVwP6G4zyz4RDPbazk5R21jB+dzLLLi1hWWsT4MaOiXapITLjQI/0C51yVmY0D1hDpvlnpnBvTa52jzrlMM/sv4AHn3Jte+6vAN51zfR7K60hfzkdnuIdXdtby9PpDvFnegAEfvyiH2+dN4JMXj9M9fiXuDdmRvnOuynuuM7PngXlArZnl9+reqfNWrwKKer290GsTGVSJoQBLZ+azdGY+FY1tPLuhghVlFdzzy42MS09iWWkRy+dPoEBH/+JD533IY2apZpZ+chm4HtgGrATu8la7C3jBW14J3GkRC4Cms/XniwyGorEp/PWiabx9/yd57M5SZhSM5uHfl3P1P/2OLz9Zxu931dHTE7vDlkUG24Uc6ecCz3sXyYSA/3DOvWhmG4AVZvYl4CCwzFt/FZGRO+VEhmx+4QJ+t8g5CQUDXDc9l+um51LR2MbT6w+xoqyCV3bWMjErhc/Om8BtpUW61aPEPV2cJb7VGe7hxe01/GrdQdYfaCQxFOCGmfl8bsFE5kwYo6t+ZcTSFbki/dhV08Kv3jnI8+9V0doR5qLcNG9U0HgKM1OiXZ7IOVHoiwxQa0eYFzZX8fymKsoOHgVgXvFYbppdwNKZeYxJUfePxD6Fvsh5qGhsi+wA3qtib/1xEoKRm8HcNLuAT148juSEYLRLFDkjhb7IBXDOsf1wM799r4qV7x+mrqWD9OQQn56Zz61zC5k7MVP9/xJTFPoig6S7x7Fu7xGef6+K1duqaevspiQ7lVvnFnLz7AJd+SsxQaEvMgSOd4RZva2GX2+s4J19jZjBVVOyuXVuIYsuzVP3j0SNQl9kiB060sZzmyp5blMllUdPkJ4U4oaPjWdZaSGzijT8U4aXQl9kmPT0ON7d38h/bqxg9dYaTnR1c3FeOsvnTeCm2QW65aMMC4W+SBS0doRZufkwT68/xNaqJpJCAT59WT7L502gVCd/ZQgp9EWibFtVE0+vP8QLmw/T2hFmyrg0br+8iFvmFJKpqR9kkCn0RWJEW2eY/3q/mqc3HOK9Q8dIDAb4+LQclszI41OX5Kr7RwaFQl8kBn1Q08yzGyJ9/zXN7SQEjSunZLNkRh7XTc/T5G9y3hT6IjGsp8exufIYq7dWs3pbDZVHTxAMGPNLxrJkZj6LLs1lXLru+ysDp9AXGSFOXv27eltkB7Cv/jhmUDoxk8Uz8lk8I083f5F+KfRFRiDnHHvqWlm9tYbV26r5oKYFgI8VjmbxjHyWzMijODs1ylVKLFLoi8SB/Q3HWb2tmhe31bClsgmAi/PSWTIjnyUz85g6Lk3DQAVQ6IvEncqjbby4rYYXt9Ww8dBRnIPxo5NZODmbK6dkccXkbPJG6zyAXyn0ReJYXXM7a3bW8lZ5A+v2HuFoWxcAk3JSuXJyNldMzmLh5CzdC8BHFPoiPtHT49hZ08zb5Ud4a28D6/c30tbZjRlMz89gzoRMLisczWWFY5gyLo1gQN1B8UihL+JTXd09vF9xjLf3HmHd3iNsrWqitSMMQEpikBnjR3NZ4WhmFo7mY4VjmJiVovMCcUChLyJA5C+BfQ2tbKlsYktlE+9XHmP74WY6wz0AjB6VwMJJWVx9UTbXTM2haKzuDzwSnS30Q8NdjIhETyBgTBmXzpRx6XxmTiEQ+Wtgd20LWyqb2HTwKG+WN/Di9hoASrJTuXpqZAewYHIWaUmKjJFOR/oi8iHOOfbWt/L67gbe2FPPO/saOdHVTShgzJmYyVVTspmYlUJuRjJ5GcnkZiQzKlE3jIkl6t4RkfPWEe5m44GjvL6ngdd317Ojuvkj62QkhyI7gdHJjEtPJn90MhflpTM9P4OS7FSdMB5mCn0RGTQt7V3UNLVT29xBbXM7Nc3t1DVHfj613NJBd08kW5ITAkzLTWf6+Awuyc9gen4GF+dnqKtoCKlPX0QGTXpyAunJCUzNTe9znc5wD+V1reyobmZndTM7DjezelsNT6+vOLVOwZhR5GYkkZWWRHZaEtlpiWSlJpKVlkRWWiI5aZHXMlMSNKJoECn0RWTQJYYCTB+fwfTxGafanHNUN7Wf2gmU17fS0NpBRWMb7x06RuPxDnrO0PGQEDTGpSeTk55EbkYS49KTTz2Py4jsMDKSE0hPDpGWHCIhGBjGbzryKPRFZFiYGePHjGL8mFF86pLcj7ze3eNoOtFFQ2sHDa0dHGntpKG1g7qWSDdSXXMH+xuO886+RppOdPX5e5JCgcgOIClEenICaUmRnUFGcgIZo04+J5CRHCJjVGRnkZGcwOhRCaQmRd6XGIrfHYdCX0RiQjBgjE1NZGxqIhedpesIoL2rm/qWDupa2qlv6aS1I0xLexet7eHIckeYlvYwre1dtHaEOXSkjZb2LlraI6/1JzEUID0pdGonkJYcIj0pRHJikISAEQoGCAWMUNAIBU4uR56TQgFGJQZJTQqRkhgkNTFESpL3nBgkJSnEqIQgiaEAicEACUEb1u6rYQ99M1sM/BAIAj9zzj0w3DWIyMiWnBCkaGzKeV081t3jaG0P09zeFXmc8JZPdHG8I8zxzu7IDqPj5E6km9aOLmpb2mnr7Ka7xxHudoR7erxnR7i7J/Lc406dwB4oM0gMBkgMBUjydgRJCUFmFIzmX5fPPufv159hDX0zCwIPA9cBlcAGM1vpnNsxnHWIiH8FA8bolARGpwzN/YjD3T20dXXT1tHN8c7wH547wxzv6KatM8yJzm46u3vo6Oqhs7uHznAPHeGeD7UVZQ7NzXKG+0h/HlDunNsHYGbPADcCCn0RiQuhYICMYICM5Ni8yf1wn60oACp6/VzptYmIyDCIuVPUZna3mZWZWVl9fX20yxERiSvDHfpVQFGvnwu9tlOcc48650qdc6U5OTnDWpyISLwb7tDfAEw1sxIzSwRuB1YOcw0iIr41rCdynXNhM7sPeInIkM3HnXPbh7MGERE/G/Zx+s65VcCq4f69IiISgydyRURk6Cj0RUR8JKbn0zezeuDgBXxENtAwSOUMh5FWL6jm4TLSah5p9UJ81TzROXfG4Y8xHfoXyszK+rqRQCwaafWCah4uI63mkVYv+Kdmde+IiPiIQl9ExEfiPfQfjXYB52ik1QuqebiMtJpHWr3gk5rjuk9fREQ+LN6P9EVEpBeFvoiIj8Rl6JvZYjPbZWblZnZ/tOsZCDM7YGZbzWyzmZVFu54zMbPHzazOzLb1ahtrZmvMbI/3nBnNGk/XR83fMbMqb1tvNrOl0ayxNzMrMrO1ZrbDzLab2V967TG7nc9Scyxv52QzW29m73s1/y+vvcTM3vWy41lvYsioO0u9T5jZ/l7beFa/H+aci6sHkYnc9gKTgETgfWB6tOsaQN0HgOxo19FPjdcAc4Btvdr+GbjfW74f+Kdo1zmAmr8D/HW0a+uj3nxgjrecDuwGpsfydj5LzbG8nQ1I85YTgHeBBcAK4Hav/afAn0W71n7qfQK49Vw+Kx6P9E/dktE51wmcvCWjXCDn3OtA42nNNwJPestPAjcNZ0396aPmmOWcq3bObfKWW4CdRO4uF7Pb+Sw1xywX0er9mOA9HPBJ4Ndee8xs57PUe87iMfRH6i0ZHfCymW00s7ujXcw5yHXOVXvLNUBuNIs5B/eZ2Rav+ydmukp6M7NiYDaRo7oRsZ1PqxlieDubWdDMNgN1wBoiPQTHnHNhb5WYyo7T63XOndzG3/O28UNmltTf58Rj6I9UVznn5gBLgHvN7JpoF3SuXORvz5EwBvgnwGRgFlANfD+q1ZyBmaUBzwFfc841934tVrfzGWqO6e3snOt2zs0icge/ecDF0a3o7E6v18xmAH9DpO7LgbHAN/v7nHgM/X5vyRiLnHNV3nMd8DyRf4QjQa2Z5QN4z3VRrqdfzrla7z9QD/AYMbatzSyBSHg+5Zz7jdcc09v5TDXH+nY+yTl3DFgLLATGmNnJ+4zEZHb0qnex17XmnHMdwL8zgG0cj6E/4m7JaGapZpZ+chm4Hth29nfFjJXAXd7yXcALUaxlQE6Gp+dmYmhbm5kBPwd2Ouce7PVSzG7nvmqO8e2cY2ZjvOVRwHVEzkWsBW71VouZ7dxHvR/0OhAwIucf+t3GcXlFrjc07Af84ZaM34tuRWdnZpOIHN1D5G5m/xGLNZvZ08AniEznWgt8G/gtkREPE4hMg73MORczJ077qPkTRLocHJFRU/f06i+PKjO7CngD2Ar0eM1/S6SPPCa381lqXk7sbufLiJyoDRI5+F3hnPuu93/xGSJdJe8Bf+odRUfVWer9HZBDZHTPZuCrvU74nvmz4jH0RUTkzOKxe0dERPqg0BcR8RGFvoiIjyj0RUR8RKEvIuIjCn0RER9R6IuI+Mj/BxPEovkFxdmdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_values = range(len(epoch_train_log))\n",
    "plt.plot(x_values, epoch_train_log, label='Train_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cfcd96ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f033bf51070>]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#epoch_val_log= [t.detach().cpu().numpy() for t in epoch_val_log]\n",
    "x_values_val = range(len(epoch_val_log))\n",
    "plt.plot(x_values_val, epoch_val_log, label='val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8527fa9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f033be60eb0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_length = min(len(epoch_train_log), len(epoch_val_log))\n",
    "list1 = epoch_train_log[:min_length]\n",
    "list2 = epoch_val_log[:min_length]\n",
    "\n",
    "# Create x-axis values\n",
    "x_values = range(min_length)\n",
    "\n",
    "# Plot the lists\n",
    "plt.plot(x_values, list1, label='Train_loss')\n",
    "plt.plot(x_values, list2, label='Val_loss')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Train Loss and Val_Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbfbb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d58c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba678ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f57d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de173316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295e930",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
